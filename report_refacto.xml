<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="51" skipped="0" tests="400" time="63.393" timestamp="2025-07-27T11:19:17.948599" hostname="42c1f4d7cdf1"><testcase classname="tests.test_import" name="test_app_import" time="0.088" /><testcase classname="tests.test_import" name="test_models_import" time="0.008" /><testcase classname="tests.test_import" name="test_config_import" time="0.005" /><testcase classname="tests.test_import" name="test_core_import" time="0.008" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_user_crud_operations" time="0.198" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_role_scope_relationships" time="0.111" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_user_role_relationships" time="0.123" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_service_client_scope_relationships" time="0.124" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_refresh_token_relationships" time="0.116" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_cascade_deletions" time="0.121" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_unique_constraints" time="0.318" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_complex_queries" time="0.226" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_transaction_rollback" time="0.110" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_concurrent_access" time="0.115" /><testcase classname="tests.integration.test_database.TestDatabaseIntegration" name="test_large_dataset_performance" time="4.884" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_basic_operations" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_expiration" time="3.020" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_hash_operations" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_list_operations" time="0.011" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_set_operations" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_pipeline_operations" time="0.011" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_transaction_operations" time="0.011" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_manager_operations" time="0.013" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_manager_multiple_keys" time="0.015" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_health_check" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_connection_recovery" time="0.011" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_concurrent_operations" time="0.017" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_large_data_operations" time="0.018" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_pattern_operations" time="0.013" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_json_serialization" time="0.013" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_session_storage" time="0.013" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_cache_invalidation" time="0.016" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_rate_limiting" time="0.013" /><testcase classname="tests.integration.test_redis.TestRedisIntegration" name="test_redis_distributed_lock" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisManagerIntegration" name="test_redis_manager_singleton_behavior" time="0.009" /><testcase classname="tests.integration.test_redis.TestRedisManagerIntegration" name="test_redis_manager_context_manager_integration" time="0.012" /><testcase classname="tests.integration.test_redis.TestRedisManagerIntegration" name="test_redis_manager_error_recovery" time="0.011" /><testcase classname="tests.security.test_authentication.TestPasswordSecurity" name="test_password_hashing_security" time="0.454" /><testcase classname="tests.security.test_authentication.TestPasswordSecurity" name="test_password_timing_attack_resistance" time="0.298" /><testcase classname="tests.security.test_authentication.TestPasswordSecurity" name="test_password_hash_format_security" time="0.104" /><testcase classname="tests.security.test_authentication.TestPasswordSecurity" name="test_password_brute_force_resistance" time="1.567" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_signature_security" time="0.007" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_expiration_security" time="2.012" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_audience_security" time="0.007" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_type_security" time="0.006" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_jti_uniqueness" time="0.007" /><testcase classname="tests.security.test_authentication.TestTokenSecurity" name="test_token_revocation_security" time="0.011" /><testcase classname="tests.security.test_authentication.TestAccountSecurity" name="test_account_lockout_security" time="0.140" /><testcase classname="tests.security.test_authentication.TestAccountSecurity" name="test_account_lockout_duration" time="0.117" /><testcase classname="tests.security.test_authentication.TestAccountSecurity" name="test_successful_login_resets_attempts" time="0.109" /><testcase classname="tests.security.test_authentication.TestAccountSecurity" name="test_disabled_account_security" time="0.107" /><testcase classname="tests.security.test_authentication.TestSessionSecurity" name="test_concurrent_session_security" time="0.908" /><testcase classname="tests.security.test_authentication.TestSessionSecurity" name="test_session_hijacking_protection" time="0.348" /><testcase classname="tests.security.test_authentication.TestInputValidationSecurity" name="test_sql_injection_protection" time="0.073" /><testcase classname="tests.security.test_authentication.TestInputValidationSecurity" name="test_xss_protection" time="0.146" /><testcase classname="tests.security.test_authentication.TestInputValidationSecurity" name="test_command_injection_protection" time="0.020" /><testcase classname="tests.security.test_authentication.TestInputValidationSecurity" name="test_ldap_injection_protection" time="0.052" /><testcase classname="tests.security.test_authentication.TestRateLimitingSecurity" name="test_login_rate_limiting" time="4.392" /><testcase classname="tests.security.test_authentication.TestRateLimitingSecurity" name="test_registration_rate_limiting" time="0.655" /><testcase classname="tests.security.test_authentication.TestCryptographicSecurity" name="test_random_token_generation" time="0.010" /><testcase classname="tests.security.test_authentication.TestCryptographicSecurity" name="test_secure_random_generation" time="0.007" /><testcase classname="tests.security.test_authentication.TestCryptographicSecurity" name="test_key_derivation_security" time="0.068" /><testcase classname="tests.security.test_authentication.TestSecurityHeaders" name="test_security_headers_present" time="0.009" /><testcase classname="tests.security.test_authentication.TestSecurityHeaders" name="test_cors_security" time="0.007" /><testcase classname="tests.security.test_authentication.TestAuditLogging" name="test_failed_login_logging" time="0.015" /><testcase classname="tests.security.test_authentication.TestAuditLogging" name="test_successful_login_logging" time="0.338" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_requirement_enforcement" time="0.008" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_privilege_escalation_prevention" time="0.005" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_wildcard_security" time="0.006" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_case_sensitivity" time="0.005" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_injection_prevention" time="0.007" /><testcase classname="tests.security.test_authorization.TestScopeBasedAuthorization" name="test_scope_based_api_access" time="0.108" /><testcase classname="tests.security.test_authorization.TestRoleBasedAuthorization" name="test_role_requirement_enforcement" time="0.103" /><testcase classname="tests.security.test_authorization.TestRoleBasedAuthorization" name="test_role_privilege_escalation_prevention" time="0.103" /><testcase classname="tests.security.test_authorization.TestRoleBasedAuthorization" name="test_role_hierarchy_security" time="0.103" /><testcase classname="tests.security.test_authorization.TestRoleBasedAuthorization" name="test_role_injection_prevention" time="0.106" /><testcase classname="tests.security.test_authorization.TestRoleBasedAuthorization" name="test_disabled_user_role_bypass" time="0.103" /><testcase classname="tests.security.test_authorization.TestResourceBasedAuthorization" name="test_resource_ownership_enforcement" time="0.199" /><testcase classname="tests.security.test_authorization.TestResourceBasedAuthorization" name="test_resource_path_traversal_prevention" time="0.106" /><testcase classname="tests.security.test_authorization.TestResourceBasedAuthorization" name="test_resource_enumeration_prevention" time="0.101" /><testcase classname="tests.security.test_authorization.TestTokenBasedAuthorization" name="test_token_scope_tampering_prevention" time="0.005" /><testcase classname="tests.security.test_authorization.TestTokenBasedAuthorization" name="test_token_audience_bypass_prevention" time="0.006" /><testcase classname="tests.security.test_authorization.TestTokenBasedAuthorization" name="test_token_replay_attack_prevention" time="0.008" /><testcase classname="tests.security.test_authorization.TestTokenBasedAuthorization" name="test_service_token_user_endpoint_prevention" time="0.006" /><testcase classname="tests.security.test_authorization.TestPermissionEscalation" name="test_horizontal_privilege_escalation_prevention" time="0.197" /><testcase classname="tests.security.test_authorization.TestPermissionEscalation" name="test_vertical_privilege_escalation_prevention" time="0.103" /><testcase classname="tests.security.test_authorization.TestPermissionEscalation" name="test_role_assignment_privilege_escalation_prevention" time="0.105" /><testcase classname="tests.security.test_authorization.TestAccessControlBypass" name="test_parameter_pollution_prevention" time="0.005" /><testcase classname="tests.security.test_authorization.TestAccessControlBypass" name="test_method_override_prevention" time="0.006" /><testcase classname="tests.security.test_authorization.TestAccessControlBypass" name="test_header_injection_prevention" time="0.005" /><testcase classname="tests.security.test_authorization.TestAccessControlBypass" name="test_unicode_normalization_bypass_prevention" time="0.497" /><testcase classname="tests.security.test_authorization.TestSessionAuthorization" name="test_session_fixation_prevention" time="0.006" /><testcase classname="tests.security.test_authorization.TestSessionAuthorization" name="test_concurrent_session_authorization" time="0.103" /><testcase classname="tests.security.test_authorization.TestSessionAuthorization" name="test_session_timeout_authorization" time="2.013" /><testcase classname="tests.security.test_authorization.TestAuthorizationLogging" name="test_authorization_failure_logging" time="0.139" /><testcase classname="tests.security.test_authorization.TestAuthorizationLogging" name="test_privilege_escalation_attempt_logging" time="0.116" /><testcase classname="tests.security.test_authorization.TestAuthorizationLogging" name="test_suspicious_authorization_pattern_detection" time="0.006" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_success" time="0.346" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_invalid_credentials" time="0.251" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_nonexistent_user" time="0.017" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_disabled_account" time="0.220" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_locked_account" time="0.215" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_missing_parameters" time="0.015" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthTokenEndpoint" name="test_user_login_rate_limiting" time="0.065" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRefreshEndpoint" name="test_token_refresh_success" time="0.540" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRefreshEndpoint" name="test_token_refresh_invalid_token" time="0.008" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRefreshEndpoint" name="test_token_refresh_expired_token" time="0.009" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRefreshEndpoint" name="test_token_refresh_missing_token" time="0.009" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthServiceTokenEndpoint" name="test_service_token_success" time="0.236" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthServiceTokenEndpoint" name="test_service_token_invalid_credentials" time="0.230" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthServiceTokenEndpoint" name="test_service_token_nonexistent_client" time="0.011" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthServiceTokenEndpoint" name="test_service_token_disabled_client" time="0.213" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthServiceTokenEndpoint" name="test_service_token_invalid_scope" time="0.308" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRevokeEndpoint" name="test_token_revoke_success" time="0.125" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRevokeEndpoint" name="test_token_revoke_refresh_token" time="0.336" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthRevokeEndpoint" name="test_token_revoke_unauthorized" time="0.010" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthLogoutEndpoint" name="test_logout_success" time="0.133" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthLogoutEndpoint" name="test_logout_unauthorized" time="0.009" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthIntrospectEndpoint" name="test_token_introspect_active" time="0.126" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthIntrospectEndpoint" name="test_token_introspect_inactive" time="0.124" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthIntrospectEndpoint" name="test_token_introspect_unauthorized" time="0.009" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthEndpointSecurity" name="test_auth_endpoints_https_only" time="0.015" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthEndpointSecurity" name="test_auth_endpoints_rate_limiting" time="0.068" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthEndpointSecurity" name="test_auth_endpoints_input_validation" time="0.037" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthEndpointSecurity" name="test_auth_endpoints_timing_attacks" time="0.237" /><testcase classname="tests.test_app.test_api.test_auth.TestAuthEndpointSecurity" name="test_auth_endpoints_error_information_disclosure" time="0.026" /><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_success" time="0.637"><failure message="assert 422 == 200&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22b93490&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b2148dd50&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6ImYxNWYzMjliLWI4...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.1FDxbDi2IDMrK-ktvE4rqSkDiVHDqDGcCoEaEqrag94'
test_users = [&lt;User(id=cf308344-d73b-4fd1-8d16-9e881337dd9d, username='testuser_bulk', email='testuser_bulk@example.com')&gt;, &lt;User(i...il='user1@example.com')&gt;, &lt;User(id=c0cb81ab-51d3-48f2-ab37-09b544f203d9, username='user2', email='user2@example.com')&gt;]

    @pytest.mark.integration
    async def test_list_users_success(self, async_client: AsyncClient, admin_access_token: str, test_users: list[User]):
        """Test successful user listing by admin."""
        response = await async_client.get(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 200
E       assert 422 == 200
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:23: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_pagination" time="0.166"><failure message="assert 422 == 200&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22b938d0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21449b90&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6ImIyYTg2MTg0LTM0...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.FowrWSlpMNu8zc89hN-B3vLLwzcvqimc197juVneTH4'

    @pytest.mark.integration
    async def test_list_users_pagination(self, async_client: AsyncClient, admin_access_token: str):
        """Test user listing with pagination."""
        response = await async_client.get(
            "/api/v1/users?page=1&amp;per_page=5",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
        print(f"Response status: {response.status_code}")
        print(f"Response body: {response.text}")
        print(f"Response headers: {response.headers}")
    
&gt;       assert response.status_code == 200
E       assert 422 == 200
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:56: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_filtering" time="0.133"><failure message="assert 422 == 200&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22ba1510&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b212cdb10&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjhiN2YyZjcxLTlm...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.-ITwMgI0a7MYzerqAQv_ewq7sZ577bm1nJh8BHF00P0'

    @pytest.mark.integration
    async def test_list_users_filtering(self, async_client: AsyncClient, admin_access_token: str):
        """Test user listing with filters."""
        # Filter by active status
        response = await async_client.get(
            "/api/v1/users?is_active=true",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 200
E       assert 422 == 200
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:72: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_search" time="0.233"><failure message="assert 422 == 200&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22ba0210&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21282510&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjMyZjVjZDNiLWQ0...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.q88dz0cZ3O1ozzH1b-p7ik2RrirDVtekCLBodWPlgKk'
test_user = &lt;User(id=b36295a5-341a-4e06-b1ae-92b187e86f60, username='testuser', email='test@example.com')&gt;

    @pytest.mark.integration
    async def test_list_users_search(self, async_client: AsyncClient, admin_access_token: str, test_user: User):
        """Test user listing with search."""
        response = await async_client.get(
            f"/api/v1/users?search={test_user.username[:3]}",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 200
E       assert 422 == 200
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:86: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_unauthorized" time="0.008"><failure message="assert 422 == 401&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22ba0e50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b2121ea90&gt;

    @pytest.mark.integration
    async def test_list_users_unauthorized(self, async_client: AsyncClient):
        """Test user listing without authorization."""
        response = await async_client.get("/api/v1/users")
    
&gt;       assert response.status_code == 401
E       assert 422 == 401
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:98: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersListEndpoint" name="test_list_users_forbidden" time="0.123"><failure message="assert 422 == 403&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersListEndpoint object at 0x7e3b22ba1c10&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b2121d250&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjY1YTRkYjNjLTQx...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.2LjoMBpreRokSGPq3oOA9kMdEwqjf-5-4H_Swljnd50'

    @pytest.mark.integration
    async def test_list_users_forbidden(self, async_client: AsyncClient, user_access_token: str):
        """Test user listing with insufficient permissions."""
        response = await async_client.get(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {user_access_token}"}
        )
    
&gt;       assert response.status_code == 403
E       assert 422 == 403
E        +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:108: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_success" time="0.229" /><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_with_roles" time="0.127"><failure message="TypeError: Object of type UUID is not JSON serializable">self = &lt;test_users.TestUsersCreateEndpoint object at 0x7e3b22ba1e50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b211ef690&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjcxMzVlNDM0LWQ5...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.QykF1DsVuhnio7zlCi-IyPCwaT-DZk6MP1hwsiF35XU'
test_role = &lt;Role(name='test_role', description='Test role for testing')&gt;

    @pytest.mark.integration
    async def test_create_user_with_roles(self, async_client: AsyncClient, admin_access_token: str, test_role: Role):
        """Test user creation with roles."""
        user_data = {
            "username": "userroles123",
            "email": "userroles@example.com",
            "password": "UserRoles123!",
            "role_ids": [test_role.id]
        }
    
&gt;       response = await async_client.post(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {admin_access_token}"},
            json=user_data
        )

tests/test_app/test_api/test_users.py:152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b211ef690&gt;, url = '/api/v1/users'

    async def post(
        self,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        auth: typing.Union[AuthTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        follow_redirects: typing.Union[bool, UseClientDefault] = USE_CLIENT_DEFAULT,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Response:
        """
        Send a `POST` request.
    
        **Parameters**: See `httpx.request`.
        """
&gt;       return await self.request(
            "POST",
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:1848: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b211ef690&gt;, method = 'POST', url = '/api/v1/users'

    async def request(
        self,
        method: str,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        auth: typing.Union[AuthTypes, UseClientDefault, None] = USE_CLIENT_DEFAULT,
        follow_redirects: typing.Union[bool, UseClientDefault] = USE_CLIENT_DEFAULT,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Response:
        """
        Build and send a request.
    
        Equivalent to:
    
        ```python
        request = client.build_request(...)
        response = await client.send(request, ...)
        ```
    
        See `AsyncClient.build_request()`, `AsyncClient.send()`
        and [Merging of configuration][0] for how the various parameters
        are merged with client-level configuration.
    
        [0]: /advanced/#merging-of-configuration
        """
&gt;       request = self.build_request(
            method=method,
            url=url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            timeout=timeout,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:1517: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b211ef690&gt;, method = 'POST', url = URL('http://test/api/v1/users')

    def build_request(
        self,
        method: str,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Request:
        """
        Build and return a request instance.
    
        * The `params`, `headers` and `cookies` arguments
        are merged with any values set on the client.
        * The `url` argument is merged with any `base_url` set on the client.
    
        See also: [Request instances][0]
    
        [0]: /advanced/#request-instances
        """
        url = self._merge_url(url)
        headers = self._merge_headers(headers)
        cookies = self._merge_cookies(cookies)
        params = self._merge_queryparams(params)
        extensions = {} if extensions is None else extensions
        if "timeout" not in extensions:
            timeout = (
                self.timeout
                if isinstance(timeout, UseClientDefault)
                else Timeout(timeout)
            )
            extensions = dict(**extensions, timeout=timeout.as_dict())
&gt;       return Request(
            method,
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:358: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;Request('POST', 'http://test/api/v1/users')&gt;, method = 'POST', url = URL('http://test/api/v1/users')

    def __init__(
        self,
        method: typing.Union[str, bytes],
        url: typing.Union["URL", str],
        *,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        stream: typing.Union[SyncByteStream, AsyncByteStream, None] = None,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; None:
        self.method = (
            method.decode("ascii").upper()
            if isinstance(method, bytes)
            else method.upper()
        )
        self.url = URL(url)
        if params is not None:
            self.url = self.url.copy_merge_params(params=params)
        self.headers = Headers(headers)
        self.extensions = {} if extensions is None else extensions
    
        if cookies:
            Cookies(cookies).set_cookie_header(self)
    
        if stream is None:
            content_type: typing.Optional[str] = self.headers.get("content-type")
&gt;           headers, stream = encode_request(
                content=content,
                data=data,
                files=files,
                json=json,
                boundary=get_multipart_boundary_from_content_type(
                    content_type=content_type.encode(self.headers.encoding)
                    if content_type
                    else None
                ),
            )

.venv/lib/python3.11/site-packages/httpx/_models.py:338: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

content = None, data = None, files = None
json = {'email': 'userroles@example.com', 'password': 'UserRoles123!', 'role_ids': [UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')], 'username': 'userroles123'}, boundary = None

    def encode_request(
        content: Optional[RequestContent] = None,
        data: Optional[RequestData] = None,
        files: Optional[RequestFiles] = None,
        json: Optional[Any] = None,
        boundary: Optional[bytes] = None,
    ) -&gt; Tuple[Dict[str, str], Union[SyncByteStream, AsyncByteStream]]:
        """
        Handles encoding the given `content`, `data`, `files`, and `json`,
        returning a two-tuple of (&lt;headers&gt;, &lt;stream&gt;).
        """
        if data is not None and not isinstance(data, Mapping):
            # We prefer to separate `content=&lt;bytes|str|byte iterator|bytes aiterator&gt;`
            # for raw request content, and `data=&lt;form data&gt;` for url encoded or
            # multipart form content.
            #
            # However for compat with requests, we *do* still support
            # `data=&lt;bytes...&gt;` usages. We deal with that case here, treating it
            # as if `content=&lt;...&gt;` had been supplied instead.
            message = "Use 'content=&lt;...&gt;' to upload raw bytes/text content."
            warnings.warn(message, DeprecationWarning)
            return encode_content(data)
    
        if content is not None:
            return encode_content(content)
        elif files:
            return encode_multipart_data(data or {}, files, boundary)
        elif data:
            return encode_urlencoded_data(data)
        elif json is not None:
&gt;           return encode_json(json)

.venv/lib/python3.11/site-packages/httpx/_content.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

json = {'email': 'userroles@example.com', 'password': 'UserRoles123!', 'role_ids': [UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')], 'username': 'userroles123'}

    def encode_json(json: Any) -&gt; Tuple[Dict[str, str], ByteStream]:
&gt;       body = json_dumps(json).encode("utf-8")

.venv/lib/python3.11/site-packages/httpx/_content.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

obj = {'email': 'userroles@example.com', 'password': 'UserRoles123!', 'role_ids': [UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')], 'username': 'userroles123'}, skipkeys = False
ensure_ascii = True, check_circular = True, allow_nan = True, cls = None, indent = None, separators = None, default = None

    def dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True,
            allow_nan=True, cls=None, indent=None, separators=None,
            default=None, sort_keys=False, **kw):
        """Serialize ``obj`` to a JSON formatted ``str``.
    
        If ``skipkeys`` is true then ``dict`` keys that are not basic types
        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped
        instead of raising a ``TypeError``.
    
        If ``ensure_ascii`` is false, then the return value can contain non-ASCII
        characters if they appear in strings contained in ``obj``. Otherwise, all
        such characters are escaped in JSON strings.
    
        If ``check_circular`` is false, then the circular reference check
        for container types will be skipped and a circular reference will
        result in an ``RecursionError`` (or worse).
    
        If ``allow_nan`` is false, then it will be a ``ValueError`` to
        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in
        strict compliance of the JSON specification, instead of using the
        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).
    
        If ``indent`` is a non-negative integer, then JSON array elements and
        object members will be pretty-printed with that indent level. An indent
        level of 0 will only insert newlines. ``None`` is the most compact
        representation.
    
        If specified, ``separators`` should be an ``(item_separator, key_separator)``
        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
        you should specify ``(',', ':')`` to eliminate whitespace.
    
        ``default(obj)`` is a function that should return a serializable version
        of obj or raise TypeError. The default simply raises TypeError.
    
        If *sort_keys* is true (default: ``False``), then the output of
        dictionaries will be sorted by key.
    
        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
        ``.default()`` method to serialize additional types), specify it with
        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.
    
        """
        # cached encoder
        if (not skipkeys and ensure_ascii and
            check_circular and allow_nan and
            cls is None and indent is None and separators is None and
            default is None and not sort_keys and not kw):
&gt;           return _default_encoder.encode(obj)

/usr/local/lib/python3.11/json/__init__.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;
o = {'email': 'userroles@example.com', 'password': 'UserRoles123!', 'role_ids': [UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')], 'username': 'userroles123'}

    def encode(self, o):
        """Return a JSON string representation of a Python data structure.
    
        &gt;&gt;&gt; from json.encoder import JSONEncoder
        &gt;&gt;&gt; JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'
    
        """
        # This is for extremely simple cases and benchmarks.
        if isinstance(o, str):
            if self.ensure_ascii:
                return encode_basestring_ascii(o)
            else:
                return encode_basestring(o)
        # This doesn't pass the iterator directly to ''.join() because the
        # exceptions aren't as detailed.  The list call should be roughly
        # equivalent to the PySequence_Fast that ''.join() would do.
&gt;       chunks = self.iterencode(o, _one_shot=True)

/usr/local/lib/python3.11/json/encoder.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;
o = {'email': 'userroles@example.com', 'password': 'UserRoles123!', 'role_ids': [UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')], 'username': 'userroles123'}, _one_shot = True

    def iterencode(self, o, _one_shot=False):
        """Encode the given object and yield each string
        representation as available.
    
        For example::
    
            for chunk in JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)
    
        """
        if self.check_circular:
            markers = {}
        else:
            markers = None
        if self.ensure_ascii:
            _encoder = encode_basestring_ascii
        else:
            _encoder = encode_basestring
    
        def floatstr(o, allow_nan=self.allow_nan,
                _repr=float.__repr__, _inf=INFINITY, _neginf=-INFINITY):
            # Check for specials.  Note that this type of test is processor
            # and/or platform-specific, so do tests which don't depend on the
            # internals.
    
            if o != o:
                text = 'NaN'
            elif o == _inf:
                text = 'Infinity'
            elif o == _neginf:
                text = '-Infinity'
            else:
                return _repr(o)
    
            if not allow_nan:
                raise ValueError(
                    "Out of range float values are not JSON compliant: " +
                    repr(o))
    
            return text
    
    
        if (_one_shot and c_make_encoder is not None
                and self.indent is None):
            _iterencode = c_make_encoder(
                markers, self.default, _encoder, self.indent,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, self.allow_nan)
        else:
            _iterencode = _make_iterencode(
                markers, self.default, _encoder, self.indent, floatstr,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, _one_shot)
&gt;       return _iterencode(o, 0)

/usr/local/lib/python3.11/json/encoder.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;, o = UUID('9a4668b5-a02d-4793-b972-9e58c2898c8b')

    def default(self, o):
        """Implement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).
    
        For example, to support arbitrary iterators, you could
        implement default like this::
    
            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                # Let the base class default method raise the TypeError
                return super().default(o)
    
        """
&gt;       raise TypeError(f'Object of type {o.__class__.__name__} '
                        f'is not JSON serializable')
E       TypeError: Object of type UUID is not JSON serializable

/usr/local/lib/python3.11/json/encoder.py:180: TypeError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_duplicate_username" time="0.262"><failure message="KeyError: 'detail'">self = &lt;test_users.TestUsersCreateEndpoint object at 0x7e3b22ba2b50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b20f36410&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjU0Nzc4MTNjLWJl...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.XKmWXhFSzWYBREDGfu4sK0ktvp6JWoFUD13Fk0SGQHQ'
test_user = &lt;User(id=7e50c34e-99e0-4bbd-bd00-2eb8e1b73e45, username='testuser', email='test@example.com')&gt;

    @pytest.mark.integration
    async def test_create_user_duplicate_username(self, async_client: AsyncClient, admin_access_token: str, test_user: User):
        """Test user creation with duplicate username."""
        user_data = {
            "username": test_user.username,  # Duplicate
            "email": "different@example.com",
            "password": "DifferentPassword123!"
        }
    
        response = await async_client.post(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {admin_access_token}"},
            json=user_data
        )
    
        assert response.status_code == 409
    
        error_data = response.json()
&gt;       assert "username" in error_data["detail"].lower()
E       KeyError: 'detail'

tests/test_app/test_api/test_users.py:183: KeyError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_duplicate_email" time="0.234"><failure message="KeyError: 'detail'">self = &lt;test_users.TestUsersCreateEndpoint object at 0x7e3b22ba2fd0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b20f37ad0&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjA1NmQ3NDliLWFh...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.OTbmmgzaTJsx8uIG4pBWhkcsefye62YTZjsQFuPzwt4'
test_user = &lt;User(id=0cb0fd41-0b61-4857-a884-26de1bb10482, username='testuser', email='test@example.com')&gt;

    @pytest.mark.integration
    async def test_create_user_duplicate_email(self, async_client: AsyncClient, admin_access_token: str, test_user: User):
        """Test user creation with duplicate email."""
        user_data = {
            "username": "differentuser",
            "email": test_user.email,  # Duplicate
            "password": "DifferentPassword123!"
        }
    
        response = await async_client.post(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {admin_access_token}"},
            json=user_data
        )
    
        assert response.status_code == 409
    
        error_data = response.json()
&gt;       assert "email" in error_data["detail"].lower()
E       KeyError: 'detail'

tests/test_app/test_api/test_users.py:203: KeyError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_invalid_data" time="0.130" /><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_unauthorized" time="0.118"><failure message="assert 201 == 401&#10; +  where 201 = &lt;Response [201 Created]&gt;.status_code">self = &lt;test_users.TestUsersCreateEndpoint object at 0x7e3b22ba3cd0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21fc34d0&gt;

    @pytest.mark.integration
    async def test_create_user_unauthorized(self, async_client: AsyncClient):
        """Test user creation without authorization."""
        user_data = {
            "username": "unauthorized",
            "email": "unauthorized@example.com",
            "password": "UnauthorizedPassword123!"
        }
    
        response = await async_client.post("/api/v1/users", json=user_data)
    
&gt;       assert response.status_code == 401
E       assert 201 == 401
E        +  where 201 = &lt;Response [201 Created]&gt;.status_code

tests/test_app/test_api/test_users.py:247: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersCreateEndpoint" name="test_create_user_forbidden" time="0.230"><failure message="assert 201 == 403&#10; +  where 201 = &lt;Response [201 Created]&gt;.status_code">self = &lt;test_users.TestUsersCreateEndpoint object at 0x7e3b22ba0590&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21e6ae10&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6ImRjZTBjMmQxLTcz...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.gThuWvJcBF5l8F7L8PzcEY2i4MDzcKKk5GjZxF5pgNY'

    @pytest.mark.integration
    async def test_create_user_forbidden(self, async_client: AsyncClient, user_access_token: str):
        """Test user creation with insufficient permissions."""
        user_data = {
            "username": "forbidden",
            "email": "forbidden@example.com",
            "password": "ForbiddenPassword123!"
        }
    
        response = await async_client.post(
            "/api/v1/users",
            headers={"Authorization": f"Bearer {user_access_token}"},
            json=user_data
        )
    
&gt;       assert response.status_code == 403
E       assert 201 == 403
E        +  where 201 = &lt;Response [201 Created]&gt;.status_code

tests/test_app/test_api/test_users.py:264: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersGetEndpoint" name="test_get_user_success" time="0.241" /><testcase classname="tests.test_app.test_api.test_users.TestUsersGetEndpoint" name="test_get_user_self" time="0.127" /><testcase classname="tests.test_app.test_api.test_users.TestUsersGetEndpoint" name="test_get_user_not_found" time="0.187"><failure message="assert 500 == 404&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersGetEndpoint object at 0x7e3b22bb07d0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b20efe490&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjI5MjIzMDY2LTRj...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.r1AJ-20jKBi7wEEeV5-RS7UUXE79_wnsnjfPDT9WStE'

    @pytest.mark.integration
    async def test_get_user_not_found(self, async_client: AsyncClient, admin_access_token: str):
        """Test user retrieval with non-existent ID."""
        response = await async_client.get(
            "/api/v1/users/99999",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 404
E       assert 500 == 404
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:315: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersGetEndpoint" name="test_get_user_forbidden" time="0.263"><failure message="assert 500 == 403&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersGetEndpoint object at 0x7e3b22bb0f90&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21f88210&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjUwOTMyNGE5LTI1...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.tQAhpBVHZraN6Fwi1DqYYzG0yNbFrlxtW9cBMnRVtIs'
admin_user = &lt;User(id=bf406626-b18a-4a34-9b4a-c9b051dfe6cf, username='admin', email='admin@example.com')&gt;

    @pytest.mark.integration
    async def test_get_user_forbidden(self, async_client: AsyncClient, user_access_token: str, admin_user: User):
        """Test user trying to access another user's profile."""
        response = await async_client.get(
            f"/api/v1/users/{admin_user.id}",
            headers={"Authorization": f"Bearer {user_access_token}"}
        )
    
&gt;       assert response.status_code == 403
E       assert 500 == 403
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:325: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersGetEndpoint" name="test_get_user_unauthorized" time="0.123" /><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_success" time="0.238" /><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_self" time="0.132" /><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_password" time="0.153"><failure message="assert 500 == 200&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bb26d0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21ce32d0&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjdmOTU0OWVhLWYz...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.LIcb8nDKKPiGWIHeV5MjXwMFrgzwkPORdvG8UVEnIjM'
test_user = &lt;[MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?") raised in repr()] User object at 0x7e3b21f9e990&gt;

    @pytest.mark.integration
    async def test_update_user_password(self, async_client: AsyncClient, user_access_token: str, test_user: User):
        """Test user password update."""
        update_data = {
            "current_password": "TestPassword123!",
            "new_password": "NewPassword123!"
        }
    
        response = await async_client.put(
            f"/api/v1/users/{test_user.id}/password",
            headers={"Authorization": f"Bearer {user_access_token}"},
            json=update_data
        )
    
&gt;       assert response.status_code == 200
E       assert 500 == 200
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:392: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_password_wrong_current" time="0.159"><failure message="assert 500 == 400&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bb3190&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21d26290&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjZiY2ZiYjBkLTU0...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.dErsdVYpPos2071ITyI-Pik6m7yAvbE-QFjblJCQgvo'
test_user = &lt;[MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?") raised in repr()] User object at 0x7e3b21f89410&gt;

    @pytest.mark.integration
    async def test_update_user_password_wrong_current(self, async_client: AsyncClient, user_access_token: str, test_user: User):
        """Test user password update with wrong current password."""
        update_data = {
            "current_password": "WrongPassword123!",
            "new_password": "NewPassword123!"
        }
    
        response = await async_client.put(
            f"/api/v1/users/{test_user.id}/password",
            headers={"Authorization": f"Bearer {user_access_token}"},
            json=update_data
        )
    
&gt;       assert response.status_code == 400
E       assert 500 == 400
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:411: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_roles" time="0.235"><failure message="TypeError: Object of type UUID is not JSON serializable">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bb3fd0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b22ac6e90&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjM5NDZhM2ZmLTg1...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.PWuEh3xYbK-2h2kg2mxeKA0V2DQxwoAoQZ8efuWBuso'
test_user = &lt;User(id=6375dd18-c722-41eb-ad0d-05c42ec67d5a, username='testuser', email='test@example.com')&gt;
test_role = &lt;Role(name='test_role', description='Test role for testing')&gt;

    @pytest.mark.integration
    async def test_update_user_roles(self, async_client: AsyncClient, admin_access_token: str, test_user: User, test_role: Role):
        """Test user role update by admin."""
        update_data = {
            "role_ids": [test_role.id]
        }
    
&gt;       response = await async_client.put(
            f"/api/v1/users/{test_user.id}/roles",
            headers={"Authorization": f"Bearer {admin_access_token}"},
            json=update_data
        )

tests/test_app/test_api/test_users.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b22ac6e90&gt;, url = '/api/v1/users/6375dd18-c722-41eb-ad0d-05c42ec67d5a/roles'

    async def put(
        self,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        auth: typing.Union[AuthTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        follow_redirects: typing.Union[bool, UseClientDefault] = USE_CLIENT_DEFAULT,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Response:
        """
        Send a `PUT` request.
    
        **Parameters**: See `httpx.request`.
        """
&gt;       return await self.request(
            "PUT",
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:1885: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b22ac6e90&gt;, method = 'PUT', url = '/api/v1/users/6375dd18-c722-41eb-ad0d-05c42ec67d5a/roles'

    async def request(
        self,
        method: str,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        auth: typing.Union[AuthTypes, UseClientDefault, None] = USE_CLIENT_DEFAULT,
        follow_redirects: typing.Union[bool, UseClientDefault] = USE_CLIENT_DEFAULT,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Response:
        """
        Build and send a request.
    
        Equivalent to:
    
        ```python
        request = client.build_request(...)
        response = await client.send(request, ...)
        ```
    
        See `AsyncClient.build_request()`, `AsyncClient.send()`
        and [Merging of configuration][0] for how the various parameters
        are merged with client-level configuration.
    
        [0]: /advanced/#merging-of-configuration
        """
&gt;       request = self.build_request(
            method=method,
            url=url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            timeout=timeout,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:1517: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;httpx.AsyncClient object at 0x7e3b22ac6e90&gt;, method = 'PUT', url = URL('http://test/api/v1/users/6375dd18-c722-41eb-ad0d-05c42ec67d5a/roles')

    def build_request(
        self,
        method: str,
        url: URLTypes,
        *,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        timeout: typing.Union[TimeoutTypes, UseClientDefault] = USE_CLIENT_DEFAULT,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; Request:
        """
        Build and return a request instance.
    
        * The `params`, `headers` and `cookies` arguments
        are merged with any values set on the client.
        * The `url` argument is merged with any `base_url` set on the client.
    
        See also: [Request instances][0]
    
        [0]: /advanced/#request-instances
        """
        url = self._merge_url(url)
        headers = self._merge_headers(headers)
        cookies = self._merge_cookies(cookies)
        params = self._merge_queryparams(params)
        extensions = {} if extensions is None else extensions
        if "timeout" not in extensions:
            timeout = (
                self.timeout
                if isinstance(timeout, UseClientDefault)
                else Timeout(timeout)
            )
            extensions = dict(**extensions, timeout=timeout.as_dict())
&gt;       return Request(
            method,
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            extensions=extensions,
        )

.venv/lib/python3.11/site-packages/httpx/_client.py:358: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;Request('PUT', 'http://test/api/v1/users/6375dd18-c722-41eb-ad0d-05c42ec67d5a/roles')&gt;, method = 'PUT'
url = URL('http://test/api/v1/users/6375dd18-c722-41eb-ad0d-05c42ec67d5a/roles')

    def __init__(
        self,
        method: typing.Union[str, bytes],
        url: typing.Union["URL", str],
        *,
        params: typing.Optional[QueryParamTypes] = None,
        headers: typing.Optional[HeaderTypes] = None,
        cookies: typing.Optional[CookieTypes] = None,
        content: typing.Optional[RequestContent] = None,
        data: typing.Optional[RequestData] = None,
        files: typing.Optional[RequestFiles] = None,
        json: typing.Optional[typing.Any] = None,
        stream: typing.Union[SyncByteStream, AsyncByteStream, None] = None,
        extensions: typing.Optional[RequestExtensions] = None,
    ) -&gt; None:
        self.method = (
            method.decode("ascii").upper()
            if isinstance(method, bytes)
            else method.upper()
        )
        self.url = URL(url)
        if params is not None:
            self.url = self.url.copy_merge_params(params=params)
        self.headers = Headers(headers)
        self.extensions = {} if extensions is None else extensions
    
        if cookies:
            Cookies(cookies).set_cookie_header(self)
    
        if stream is None:
            content_type: typing.Optional[str] = self.headers.get("content-type")
&gt;           headers, stream = encode_request(
                content=content,
                data=data,
                files=files,
                json=json,
                boundary=get_multipart_boundary_from_content_type(
                    content_type=content_type.encode(self.headers.encoding)
                    if content_type
                    else None
                ),
            )

.venv/lib/python3.11/site-packages/httpx/_models.py:338: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

content = None, data = None, files = None, json = {'role_ids': [UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')]}, boundary = None

    def encode_request(
        content: Optional[RequestContent] = None,
        data: Optional[RequestData] = None,
        files: Optional[RequestFiles] = None,
        json: Optional[Any] = None,
        boundary: Optional[bytes] = None,
    ) -&gt; Tuple[Dict[str, str], Union[SyncByteStream, AsyncByteStream]]:
        """
        Handles encoding the given `content`, `data`, `files`, and `json`,
        returning a two-tuple of (&lt;headers&gt;, &lt;stream&gt;).
        """
        if data is not None and not isinstance(data, Mapping):
            # We prefer to separate `content=&lt;bytes|str|byte iterator|bytes aiterator&gt;`
            # for raw request content, and `data=&lt;form data&gt;` for url encoded or
            # multipart form content.
            #
            # However for compat with requests, we *do* still support
            # `data=&lt;bytes...&gt;` usages. We deal with that case here, treating it
            # as if `content=&lt;...&gt;` had been supplied instead.
            message = "Use 'content=&lt;...&gt;' to upload raw bytes/text content."
            warnings.warn(message, DeprecationWarning)
            return encode_content(data)
    
        if content is not None:
            return encode_content(content)
        elif files:
            return encode_multipart_data(data or {}, files, boundary)
        elif data:
            return encode_urlencoded_data(data)
        elif json is not None:
&gt;           return encode_json(json)

.venv/lib/python3.11/site-packages/httpx/_content.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

json = {'role_ids': [UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')]}

    def encode_json(json: Any) -&gt; Tuple[Dict[str, str], ByteStream]:
&gt;       body = json_dumps(json).encode("utf-8")

.venv/lib/python3.11/site-packages/httpx/_content.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

obj = {'role_ids': [UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')]}, skipkeys = False, ensure_ascii = True, check_circular = True, allow_nan = True, cls = None, indent = None
separators = None, default = None

    def dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True,
            allow_nan=True, cls=None, indent=None, separators=None,
            default=None, sort_keys=False, **kw):
        """Serialize ``obj`` to a JSON formatted ``str``.
    
        If ``skipkeys`` is true then ``dict`` keys that are not basic types
        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped
        instead of raising a ``TypeError``.
    
        If ``ensure_ascii`` is false, then the return value can contain non-ASCII
        characters if they appear in strings contained in ``obj``. Otherwise, all
        such characters are escaped in JSON strings.
    
        If ``check_circular`` is false, then the circular reference check
        for container types will be skipped and a circular reference will
        result in an ``RecursionError`` (or worse).
    
        If ``allow_nan`` is false, then it will be a ``ValueError`` to
        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in
        strict compliance of the JSON specification, instead of using the
        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).
    
        If ``indent`` is a non-negative integer, then JSON array elements and
        object members will be pretty-printed with that indent level. An indent
        level of 0 will only insert newlines. ``None`` is the most compact
        representation.
    
        If specified, ``separators`` should be an ``(item_separator, key_separator)``
        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
        you should specify ``(',', ':')`` to eliminate whitespace.
    
        ``default(obj)`` is a function that should return a serializable version
        of obj or raise TypeError. The default simply raises TypeError.
    
        If *sort_keys* is true (default: ``False``), then the output of
        dictionaries will be sorted by key.
    
        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
        ``.default()`` method to serialize additional types), specify it with
        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.
    
        """
        # cached encoder
        if (not skipkeys and ensure_ascii and
            check_circular and allow_nan and
            cls is None and indent is None and separators is None and
            default is None and not sort_keys and not kw):
&gt;           return _default_encoder.encode(obj)

/usr/local/lib/python3.11/json/__init__.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;, o = {'role_ids': [UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')]}

    def encode(self, o):
        """Return a JSON string representation of a Python data structure.
    
        &gt;&gt;&gt; from json.encoder import JSONEncoder
        &gt;&gt;&gt; JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'
    
        """
        # This is for extremely simple cases and benchmarks.
        if isinstance(o, str):
            if self.ensure_ascii:
                return encode_basestring_ascii(o)
            else:
                return encode_basestring(o)
        # This doesn't pass the iterator directly to ''.join() because the
        # exceptions aren't as detailed.  The list call should be roughly
        # equivalent to the PySequence_Fast that ''.join() would do.
&gt;       chunks = self.iterencode(o, _one_shot=True)

/usr/local/lib/python3.11/json/encoder.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;, o = {'role_ids': [UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')]}, _one_shot = True

    def iterencode(self, o, _one_shot=False):
        """Encode the given object and yield each string
        representation as available.
    
        For example::
    
            for chunk in JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)
    
        """
        if self.check_circular:
            markers = {}
        else:
            markers = None
        if self.ensure_ascii:
            _encoder = encode_basestring_ascii
        else:
            _encoder = encode_basestring
    
        def floatstr(o, allow_nan=self.allow_nan,
                _repr=float.__repr__, _inf=INFINITY, _neginf=-INFINITY):
            # Check for specials.  Note that this type of test is processor
            # and/or platform-specific, so do tests which don't depend on the
            # internals.
    
            if o != o:
                text = 'NaN'
            elif o == _inf:
                text = 'Infinity'
            elif o == _neginf:
                text = '-Infinity'
            else:
                return _repr(o)
    
            if not allow_nan:
                raise ValueError(
                    "Out of range float values are not JSON compliant: " +
                    repr(o))
    
            return text
    
    
        if (_one_shot and c_make_encoder is not None
                and self.indent is None):
            _iterencode = c_make_encoder(
                markers, self.default, _encoder, self.indent,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, self.allow_nan)
        else:
            _iterencode = _make_iterencode(
                markers, self.default, _encoder, self.indent, floatstr,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, _one_shot)
&gt;       return _iterencode(o, 0)

/usr/local/lib/python3.11/json/encoder.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.encoder.JSONEncoder object at 0x7e3b273f69d0&gt;, o = UUID('7ed14a35-73ac-4b85-b171-6afef850a0c3')

    def default(self, o):
        """Implement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).
    
        For example, to support arbitrary iterators, you could
        implement default like this::
    
            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                # Let the base class default method raise the TypeError
                return super().default(o)
    
        """
&gt;       raise TypeError(f'Object of type {o.__class__.__name__} '
                        f'is not JSON serializable')
E       TypeError: Object of type UUID is not JSON serializable

/usr/local/lib/python3.11/json/encoder.py:180: TypeError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_not_found" time="0.128"><failure message="assert 500 == 404&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bb3950&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b20ddcc10&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6ImI1OTJmMjM0LTg5...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.Ezuao8R4I3tivBRGh5fPZIfeVY_M1RTF05EMCqlfZzo'

    @pytest.mark.integration
    async def test_update_user_not_found(self, async_client: AsyncClient, admin_access_token: str):
        """Test user update with non-existent ID."""
        update_data = {"email": "notfound@example.com"}
    
        response = await async_client.put(
            "/api/v1/users/99999",
            headers={"Authorization": f"Bearer {admin_access_token}"},
            json=update_data
        )
    
&gt;       assert response.status_code == 404
E       assert 500 == 404
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:447: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_forbidden" time="0.245"><failure message="assert 200 == 403&#10; +  where 200 = &lt;Response [200 OK]&gt;.status_code">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bc02d0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21dbfc50&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjA3ZmExMjA3LTJk...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.MMWrXf5XEnE-8xa64WcnZ4rr4QdVxQXs6pI3P7aRZEA'
admin_user = &lt;User(id=34c587fd-a523-4080-9e91-4e8ff3d40698, username='admin', email='forbidden@example.com')&gt;

    @pytest.mark.integration
    async def test_update_user_forbidden(self, async_client: AsyncClient, user_access_token: str, admin_user: User):
        """Test user trying to update another user's profile."""
        update_data = {"email": "forbidden@example.com"}
    
        response = await async_client.put(
            f"/api/v1/users/{admin_user.id}",
            headers={"Authorization": f"Bearer {user_access_token}"},
            json=update_data
        )
    
&gt;       assert response.status_code == 403
E       assert 200 == 403
E        +  where 200 = &lt;Response [200 OK]&gt;.status_code

tests/test_app/test_api/test_users.py:460: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersUpdateEndpoint" name="test_update_user_invalid_data" time="0.239"><failure message="assert 200 in [400, 422]&#10; +  where 200 = &lt;Response [200 OK]&gt;.status_code">self = &lt;test_users.TestUsersUpdateEndpoint object at 0x7e3b22bc0b50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21ef6e50&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjdiN2QxZDJiLTVl...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.KJz76L7v3XKl57kYBCYzhp2ZFIIA-MlxTsEq4UGVCXM'
test_user = &lt;User(id=650eb269-aa71-42b4-9226-3471af49b8c8, username='testuser', email='test@example.com')&gt;

    @pytest.mark.integration
    async def test_update_user_invalid_data(self, async_client: AsyncClient, admin_access_token: str, test_user: User):
        """Test user update with invalid data."""
        invalid_data_cases = [
            # Invalid email format
            {"email": "invalid-email"},
    
            # Username change (should not be allowed)
            {"username": "newusername"},
    
            # Invalid role IDs
            {"role_ids": [99999]},
        ]
    
        for invalid_data in invalid_data_cases:
            response = await async_client.put(
                f"/api/v1/users/{test_user.id}",
                headers={"Authorization": f"Bearer {admin_access_token}"},
                json=invalid_data
            )
    
&gt;           assert response.status_code in [400, 422]
E           assert 200 in [400, 422]
E            +  where 200 = &lt;Response [200 OK]&gt;.status_code

tests/test_app/test_api/test_users.py:483: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersDeleteEndpoint" name="test_delete_user_success" time="0.226"><failure message="assert 500 == 204&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersDeleteEndpoint object at 0x7e3b22bc1090&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b2120f5d0&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjViMjRjMTk3LWI0...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.2JQUZnk0Mawxiq6QiX3KlNLVzHZ-D2Oz2qgwb5F3NcQ'
db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b2120e610&gt;

    @pytest.mark.integration
    async def test_delete_user_success(self, async_client: AsyncClient, admin_access_token: str, db_session):
        """Test successful user deletion by admin."""
        # Create user to delete
        user_to_delete = User(
            username="todelete",
            email="todelete@example.com",
            password_hash=hash_password("ToDelete123!")
        )
        db_session.add(user_to_delete)
        await db_session.commit()
        await db_session.refresh(user_to_delete)
    
        response = await async_client.delete(
            f"/api/v1/users/{user_to_delete.id}",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 204
E       assert 500 == 204
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:507: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersDeleteEndpoint" name="test_delete_user_not_found" time="0.124"><failure message="assert 500 == 404&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersDeleteEndpoint object at 0x7e3b22bc1f50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21d92a90&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjNjYzY3ZTQzLTYy...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.OIm4psRP69cERwPI39wqd7eJbpyJlgI0_1y1mzpOGvk'

    @pytest.mark.integration
    async def test_delete_user_not_found(self, async_client: AsyncClient, admin_access_token: str):
        """Test user deletion with non-existent ID."""
        response = await async_client.delete(
            "/api/v1/users/99999",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 404
E       assert 500 == 404
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:517: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersDeleteEndpoint" name="test_delete_user_self_forbidden" time="0.154"><failure message="assert 500 == 403&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersDeleteEndpoint object at 0x7e3b22bb2490&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21e70b50&gt;
admin_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjgyZDZhYjQyLTFm...YWRtaW4iXSwidXNlcm5hbWUiOiJhZG1pbiIsImVtYWlsIjoiYWRtaW5AZXhhbXBsZS5jb20ifQ.6P69LuXeEA66741t8JrqlXtifNzxYl7ufCHWTScdkd0'
admin_user = &lt;[MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?") raised in repr()] User object at 0x7e3b22b16290&gt;

    @pytest.mark.integration
    async def test_delete_user_self_forbidden(self, async_client: AsyncClient, admin_access_token: str, admin_user: User):
        """Test admin trying to delete their own account."""
        response = await async_client.delete(
            f"/api/v1/users/{admin_user.id}",
            headers={"Authorization": f"Bearer {admin_access_token}"}
        )
    
&gt;       assert response.status_code == 403
E       assert 500 == 403
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:527: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersDeleteEndpoint" name="test_delete_user_unauthorized" time="0.152"><failure message="assert 500 == 401&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersDeleteEndpoint object at 0x7e3b22bc0fd0&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21dbc810&gt;
test_user = &lt;[MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?") raised in repr()] User object at 0x7e3b2142df50&gt;

    @pytest.mark.integration
    async def test_delete_user_unauthorized(self, async_client: AsyncClient, test_user: User):
        """Test user deletion without authorization."""
        response = await async_client.delete(f"/api/v1/users/{test_user.id}")
    
&gt;       assert response.status_code == 401
E       assert 500 == 401
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:537: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersDeleteEndpoint" name="test_delete_user_forbidden" time="0.264"><failure message="assert 500 == 403&#10; +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code">self = &lt;test_users.TestUsersDeleteEndpoint object at 0x7e3b22bc1710&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21fa0450&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjI4YzY2OWE0LWUw...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.9jLJ3e8f0J9-enyS-XJ-uYeWximSQgPrT0oGO0M0_So'
admin_user = &lt;[MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?") raised in repr()] User object at 0x7e3b21fa1090&gt;

    @pytest.mark.integration
    async def test_delete_user_forbidden(self, async_client: AsyncClient, user_access_token: str, admin_user: User):
        """Test user trying to delete another user."""
        response = await async_client.delete(
            f"/api/v1/users/{admin_user.id}",
            headers={"Authorization": f"Bearer {user_access_token}"}
        )
    
&gt;       assert response.status_code == 403
E       assert 500 == 403
E        +  where 500 = &lt;Response [500 Internal Server Error]&gt;.status_code

tests/test_app/test_api/test_users.py:547: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersMeEndpoint" name="test_get_current_user_success" time="0.132" /><testcase classname="tests.test_app.test_api.test_users.TestUsersMeEndpoint" name="test_get_current_user_unauthorized" time="0.011" /><testcase classname="tests.test_app.test_api.test_users.TestUsersEndpointSecurity" name="test_users_endpoints_input_validation" time="0.128" /><testcase classname="tests.test_app.test_api.test_users.TestUsersEndpointSecurity" name="test_users_endpoints_authorization_bypass" time="0.128"><failure message="assert 422 == 403&#10; +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code">self = &lt;test_users.TestUsersEndpointSecurity object at 0x7e3b22bc3b50&gt;, async_client = &lt;httpx.AsyncClient object at 0x7e3b21d7b750&gt;
user_access_token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrZXlzdG9uZS1hdXRoIiwiYXVkIjpbInRlc3QtYXBpIl0sInN1YiI6IjA3NTgxMTRmLTc3...ZXN0Il0sInVzZXJuYW1lIjoidGVzdHVzZXIiLCJlbWFpbCI6InRlc3RAZXhhbXBsZS5jb20ifQ.U-xzUhIbGexYW_ZRt2wbX_7UlDba01IPkGd_TSlmbow'

    @pytest.mark.security
    async def test_users_endpoints_authorization_bypass(self, async_client: AsyncClient, user_access_token: str):
        """Test that users cannot bypass authorization."""
        # Try to access admin-only endpoints
        admin_endpoints = [
            ("GET", "/api/v1/users"),
            ("POST", "/api/v1/users"),
            ("DELETE", "/api/v1/users/1"),
        ]
    
        for method, endpoint in admin_endpoints:
            if method == "GET":
                response = await async_client.get(
                    endpoint,
                    headers={"Authorization": f"Bearer {user_access_token}"}
                )
            elif method == "POST":
                response = await async_client.post(
                    endpoint,
                    headers={"Authorization": f"Bearer {user_access_token}"},
                    json={"username": "test", "email": "test@example.com", "password": "Test123!"}
                )
            elif method == "DELETE":
                response = await async_client.delete(
                    endpoint,
                    headers={"Authorization": f"Bearer {user_access_token}"}
                )
    
&gt;           assert response.status_code == 403
E           assert 422 == 403
E            +  where 422 = &lt;Response [422 Unprocessable Entity]&gt;.status_code

tests/test_app/test_api/test_users.py:631: AssertionError</failure></testcase><testcase classname="tests.test_app.test_api.test_users.TestUsersEndpointSecurity" name="test_users_endpoints_data_exposure" time="0.246" /><testcase classname="tests.test_app.test_api.test_users.TestUsersEndpointSecurity" name="test_users_endpoints_rate_limiting" time="0.143" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_default_values" time="0.021" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_from_environment" time="0.008"><failure message="pydantic_settings.exceptions.SettingsError: error parsing value for field &quot;ALLOWED_HOSTS&quot; from source &quot;EnvSettingsSource&quot;">self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
&gt;               field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost,example.com', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
                    value = self.decode_complex_value(field_name, field, value)
                except ValueError as e:
                    if not allow_parse_failure:
&gt;                       raise e

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost,example.com', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
&gt;                   value = self.decode_complex_value(field_name, field, value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost,example.com'

    def decode_complex_value(self, field_name: str, field: FieldInfo, value: Any) -&gt; Any:
        """
        Decode the value for a complex field
    
        Args:
            field_name: The field name.
            field: The field.
            value: The value of the field that has to be prepared.
    
        Returns:
            The decoded value for further preparation
        """
        if field and (
            NoDecode in field.metadata
            or (self.config.get('enable_decoding') is False and ForceDecode not in field.metadata)
        ):
            return value
    
&gt;       return json.loads(value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

s = 'localhost,example.com', cls = None, object_hook = None, parse_float = None, parse_int = None, parse_constant = None, object_pairs_hook = None, kw = {}

    def loads(s, *, cls=None, object_hook=None, parse_float=None,
            parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):
        """Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance
        containing a JSON document) to a Python object.
    
        ``object_hook`` is an optional function that will be called with the
        result of any object literal decode (a ``dict``). The return value of
        ``object_hook`` will be used instead of the ``dict``. This feature
        can be used to implement custom decoders (e.g. JSON-RPC class hinting).
    
        ``object_pairs_hook`` is an optional function that will be called with the
        result of any object literal decoded with an ordered list of pairs.  The
        return value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.  If ``object_hook``
        is also defined, the ``object_pairs_hook`` takes priority.
    
        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).
    
        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).
    
        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.
    
        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
        kwarg; otherwise ``JSONDecoder`` is used.
        """
        if isinstance(s, str):
            if s.startswith('\ufeff'):
                raise JSONDecodeError("Unexpected UTF-8 BOM (decode using utf-8-sig)",
                                      s, 0)
        else:
            if not isinstance(s, (bytes, bytearray)):
                raise TypeError(f'the JSON object must be str, bytes or bytearray, '
                                f'not {s.__class__.__name__}')
            s = s.decode(detect_encoding(s), 'surrogatepass')
    
        if (cls is None and object_hook is None and
                parse_int is None and parse_float is None and
                parse_constant is None and object_pairs_hook is None and not kw):
&gt;           return _default_decoder.decode(s)

/usr/local/lib/python3.11/json/__init__.py:346: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'localhost,example.com', _w = &lt;built-in method match of re.Pattern object at 0x7e3b274c57d0&gt;

    def decode(self, s, _w=WHITESPACE.match):
        """Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).
    
        """
&gt;       obj, end = self.raw_decode(s, idx=_w(s, 0).end())

/usr/local/lib/python3.11/json/decoder.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'localhost,example.com', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
&gt;           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

/usr/local/lib/python3.11/json/decoder.py:355: JSONDecodeError

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_config.test_settings.TestSettingsValidation object at 0x7e3b22e5ccd0&gt;

    def test_settings_from_environment(self):
        """Test settings loaded from environment variables."""
        env_vars = {
            "APP_NAME": "Test Auth Service",
            "DEBUG": "true",
            "ENVIRONMENT": "development",
            "API_V1_PREFIX": "/api/test/v1",
            "DATABASE_URL": "postgresql://test:test@localhost/test",
            "REDIS_URL": "redis://localhost:6379/1",
            "JWT_SECRET_KEY": "test-jwt-secret",
            "JWT_ALGORITHM": "HS512",
            "ACCESS_TOKEN_EXPIRE_MINUTES": "60",
            "REFRESH_TOKEN_EXPIRE_DAYS": "14",
            "PASSWORD_MIN_LENGTH": "12",
            "MAX_LOGIN_ATTEMPTS": "3",
            "ACCOUNT_LOCKOUT_MINUTES": "60",
            "RATE_LIMIT_PER_MINUTE": "30",
            "CORS_ORIGINS": "http://localhost:3000,https://example.com",
            "ALLOWED_HOSTS": "localhost,example.com",
        }
    
        with patch.dict(os.environ, env_vars, clear=True):
&gt;           settings = Settings()

tests/test_app/test_config/test_settings.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), kwargs = {}

    def __init__(self, **kwargs):
        """Initialize settings with production overrides."""
&gt;       super().__init__(**kwargs)

app/config/settings.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

__pydantic_self__ = Settings(), _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.'), _env_file_encoding = None
_env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None, _cli_prog_name = None
_cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None, _cli_enforce_required = None
_cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None, _cli_ignore_unknown_args = None
_cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None, values = {}

    def __init__(
        __pydantic_self__,
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = ENV_FILE_SENTINEL,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
        **values: Any,
    ) -&gt; None:
        super().__init__(
&gt;           **__pydantic_self__._settings_build_values(
                values,
                _case_sensitive=_case_sensitive,
                _nested_model_default_partial_update=_nested_model_default_partial_update,
                _env_prefix=_env_prefix,
                _env_file=_env_file,
                _env_file_encoding=_env_file_encoding,
                _env_ignore_empty=_env_ignore_empty,
                _env_nested_delimiter=_env_nested_delimiter,
                _env_nested_max_split=_env_nested_max_split,
                _env_parse_none_str=_env_parse_none_str,
                _env_parse_enums=_env_parse_enums,
                _cli_prog_name=_cli_prog_name,
                _cli_parse_args=_cli_parse_args,
                _cli_settings_source=_cli_settings_source,
                _cli_parse_none_str=_cli_parse_none_str,
                _cli_hide_none_type=_cli_hide_none_type,
                _cli_avoid_json=_cli_avoid_json,
                _cli_enforce_required=_cli_enforce_required,
                _cli_use_class_docs_for_groups=_cli_use_class_docs_for_groups,
                _cli_exit_on_error=_cli_exit_on_error,
                _cli_prefix=_cli_prefix,
                _cli_flag_prefix_char=_cli_flag_prefix_char,
                _cli_implicit_flags=_cli_implicit_flags,
                _cli_ignore_unknown_args=_cli_ignore_unknown_args,
                _cli_kebab_case=_cli_kebab_case,
                _cli_shortcuts=_cli_shortcuts,
                _secrets_dir=_secrets_dir,
            )
        )

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), init_kwargs = {}, _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.')
_env_file_encoding = None, _env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None
_cli_prog_name = None, _cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None
_cli_enforce_required = None, _cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None
_cli_ignore_unknown_args = None, _cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None

    def _settings_build_values(
        self,
        init_kwargs: dict[str, Any],
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = None,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
    ) -&gt; dict[str, Any]:
        # Determine settings config values
        case_sensitive = _case_sensitive if _case_sensitive is not None else self.model_config.get('case_sensitive')
        env_prefix = _env_prefix if _env_prefix is not None else self.model_config.get('env_prefix')
        nested_model_default_partial_update = (
            _nested_model_default_partial_update
            if _nested_model_default_partial_update is not None
            else self.model_config.get('nested_model_default_partial_update')
        )
        env_file = _env_file if _env_file != ENV_FILE_SENTINEL else self.model_config.get('env_file')
        env_file_encoding = (
            _env_file_encoding if _env_file_encoding is not None else self.model_config.get('env_file_encoding')
        )
        env_ignore_empty = (
            _env_ignore_empty if _env_ignore_empty is not None else self.model_config.get('env_ignore_empty')
        )
        env_nested_delimiter = (
            _env_nested_delimiter
            if _env_nested_delimiter is not None
            else self.model_config.get('env_nested_delimiter')
        )
        env_nested_max_split = (
            _env_nested_max_split
            if _env_nested_max_split is not None
            else self.model_config.get('env_nested_max_split')
        )
        env_parse_none_str = (
            _env_parse_none_str if _env_parse_none_str is not None else self.model_config.get('env_parse_none_str')
        )
        env_parse_enums = _env_parse_enums if _env_parse_enums is not None else self.model_config.get('env_parse_enums')
    
        cli_prog_name = _cli_prog_name if _cli_prog_name is not None else self.model_config.get('cli_prog_name')
        cli_parse_args = _cli_parse_args if _cli_parse_args is not None else self.model_config.get('cli_parse_args')
        cli_settings_source = (
            _cli_settings_source if _cli_settings_source is not None else self.model_config.get('cli_settings_source')
        )
        cli_parse_none_str = (
            _cli_parse_none_str if _cli_parse_none_str is not None else self.model_config.get('cli_parse_none_str')
        )
        cli_parse_none_str = cli_parse_none_str if not env_parse_none_str else env_parse_none_str
        cli_hide_none_type = (
            _cli_hide_none_type if _cli_hide_none_type is not None else self.model_config.get('cli_hide_none_type')
        )
        cli_avoid_json = _cli_avoid_json if _cli_avoid_json is not None else self.model_config.get('cli_avoid_json')
        cli_enforce_required = (
            _cli_enforce_required
            if _cli_enforce_required is not None
            else self.model_config.get('cli_enforce_required')
        )
        cli_use_class_docs_for_groups = (
            _cli_use_class_docs_for_groups
            if _cli_use_class_docs_for_groups is not None
            else self.model_config.get('cli_use_class_docs_for_groups')
        )
        cli_exit_on_error = (
            _cli_exit_on_error if _cli_exit_on_error is not None else self.model_config.get('cli_exit_on_error')
        )
        cli_prefix = _cli_prefix if _cli_prefix is not None else self.model_config.get('cli_prefix')
        cli_flag_prefix_char = (
            _cli_flag_prefix_char
            if _cli_flag_prefix_char is not None
            else self.model_config.get('cli_flag_prefix_char')
        )
        cli_implicit_flags = (
            _cli_implicit_flags if _cli_implicit_flags is not None else self.model_config.get('cli_implicit_flags')
        )
        cli_ignore_unknown_args = (
            _cli_ignore_unknown_args
            if _cli_ignore_unknown_args is not None
            else self.model_config.get('cli_ignore_unknown_args')
        )
        cli_kebab_case = _cli_kebab_case if _cli_kebab_case is not None else self.model_config.get('cli_kebab_case')
        cli_shortcuts = _cli_shortcuts if _cli_shortcuts is not None else self.model_config.get('cli_shortcuts')
    
        secrets_dir = _secrets_dir if _secrets_dir is not None else self.model_config.get('secrets_dir')
    
        # Configure built-in sources
        default_settings = DefaultSettingsSource(
            self.__class__, nested_model_default_partial_update=nested_model_default_partial_update
        )
        init_settings = InitSettingsSource(
            self.__class__,
            init_kwargs=init_kwargs,
            nested_model_default_partial_update=nested_model_default_partial_update,
        )
        env_settings = EnvSettingsSource(
            self.__class__,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
        dotenv_settings = DotEnvSettingsSource(
            self.__class__,
            env_file=env_file,
            env_file_encoding=env_file_encoding,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
    
        file_secret_settings = SecretsSettingsSource(
            self.__class__, secrets_dir=secrets_dir, case_sensitive=case_sensitive, env_prefix=env_prefix
        )
        # Provide a hook to set built-in sources priority and add / remove sources
        sources = self.settings_customise_sources(
            self.__class__,
            init_settings=init_settings,
            env_settings=env_settings,
            dotenv_settings=dotenv_settings,
            file_secret_settings=file_secret_settings,
        ) + (default_settings,)
        if not any([source for source in sources if isinstance(source, CliSettingsSource)]):
            if isinstance(cli_settings_source, CliSettingsSource):
                sources = (cli_settings_source,) + sources
            elif cli_parse_args is not None:
                cli_settings = CliSettingsSource[Any](
                    self.__class__,
                    cli_prog_name=cli_prog_name,
                    cli_parse_args=cli_parse_args,
                    cli_parse_none_str=cli_parse_none_str,
                    cli_hide_none_type=cli_hide_none_type,
                    cli_avoid_json=cli_avoid_json,
                    cli_enforce_required=cli_enforce_required,
                    cli_use_class_docs_for_groups=cli_use_class_docs_for_groups,
                    cli_exit_on_error=cli_exit_on_error,
                    cli_prefix=cli_prefix,
                    cli_flag_prefix_char=cli_flag_prefix_char,
                    cli_implicit_flags=cli_implicit_flags,
                    cli_ignore_unknown_args=cli_ignore_unknown_args,
                    cli_kebab_case=cli_kebab_case,
                    cli_shortcuts=cli_shortcuts,
                    case_sensitive=case_sensitive,
                )
                sources = (cli_settings,) + sources
        if sources:
            state: dict[str, Any] = {}
            states: dict[str, dict[str, Any]] = {}
            for source in sources:
                if isinstance(source, PydanticBaseSettingsSource):
                    source._set_current_state(state)
                    source._set_settings_sources_data(states)
    
                source_name = source.__name__ if hasattr(source, '__name__') else type(source).__name__
&gt;               source_state = source()

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:424: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
                field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)
            except ValueError as e:
&gt;               raise SettingsError(
                    f'error parsing value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
E               pydantic_settings.exceptions.SettingsError: error parsing value for field "ALLOWED_HOSTS" from source "EnvSettingsSource"

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:492: SettingsError</failure></testcase><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_required_fields_missing" time="0.013" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_invalid_values" time="0.011" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_jwt_secret_key_validation" time="0.009" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_password_policy_validation" time="0.010" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_security_validation" time="0.012" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_cors_origins_parsing" time="0.007"><failure message="pydantic_settings.exceptions.SettingsError: error parsing value for field &quot;CORS_ORIGINS&quot; from source &quot;EnvSettingsSource&quot;">self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
&gt;               field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
                    value = self.decode_complex_value(field_name, field, value)
                except ValueError as e:
                    if not allow_parse_failure:
&gt;                       raise e

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
&gt;                   value = self.decode_complex_value(field_name, field, value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000'

    def decode_complex_value(self, field_name: str, field: FieldInfo, value: Any) -&gt; Any:
        """
        Decode the value for a complex field
    
        Args:
            field_name: The field name.
            field: The field.
            value: The value of the field that has to be prepared.
    
        Returns:
            The decoded value for further preparation
        """
        if field and (
            NoDecode in field.metadata
            or (self.config.get('enable_decoding') is False and ForceDecode not in field.metadata)
        ):
            return value
    
&gt;       return json.loads(value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

s = 'http://localhost:3000', cls = None, object_hook = None, parse_float = None, parse_int = None, parse_constant = None, object_pairs_hook = None, kw = {}

    def loads(s, *, cls=None, object_hook=None, parse_float=None,
            parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):
        """Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance
        containing a JSON document) to a Python object.
    
        ``object_hook`` is an optional function that will be called with the
        result of any object literal decode (a ``dict``). The return value of
        ``object_hook`` will be used instead of the ``dict``. This feature
        can be used to implement custom decoders (e.g. JSON-RPC class hinting).
    
        ``object_pairs_hook`` is an optional function that will be called with the
        result of any object literal decoded with an ordered list of pairs.  The
        return value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.  If ``object_hook``
        is also defined, the ``object_pairs_hook`` takes priority.
    
        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).
    
        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).
    
        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.
    
        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
        kwarg; otherwise ``JSONDecoder`` is used.
        """
        if isinstance(s, str):
            if s.startswith('\ufeff'):
                raise JSONDecodeError("Unexpected UTF-8 BOM (decode using utf-8-sig)",
                                      s, 0)
        else:
            if not isinstance(s, (bytes, bytearray)):
                raise TypeError(f'the JSON object must be str, bytes or bytearray, '
                                f'not {s.__class__.__name__}')
            s = s.decode(detect_encoding(s), 'surrogatepass')
    
        if (cls is None and object_hook is None and
                parse_int is None and parse_float is None and
                parse_constant is None and object_pairs_hook is None and not kw):
&gt;           return _default_decoder.decode(s)

/usr/local/lib/python3.11/json/__init__.py:346: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'http://localhost:3000', _w = &lt;built-in method match of re.Pattern object at 0x7e3b274c57d0&gt;

    def decode(self, s, _w=WHITESPACE.match):
        """Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).
    
        """
&gt;       obj, end = self.raw_decode(s, idx=_w(s, 0).end())

/usr/local/lib/python3.11/json/decoder.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'http://localhost:3000', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
&gt;           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

/usr/local/lib/python3.11/json/decoder.py:355: JSONDecodeError

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_config.test_settings.TestSettingsValidation object at 0x7e3b22fbfd90&gt;

    def test_settings_cors_origins_parsing(self):
        """Test CORS origins parsing."""
        base_env = {
            "DATABASE_URL": "postgresql://test:test@localhost/test",
            "REDIS_URL": "redis://localhost:6379/0",
            "JWT_SECRET_KEY": "test-secret-key-for-testing-32chars"
        }
    
        # Test single origin
        with patch.dict(os.environ, {**base_env, "CORS_ORIGINS": "http://localhost:3000"}, clear=True):
&gt;           settings = Settings()

tests/test_app/test_config/test_settings.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), kwargs = {}

    def __init__(self, **kwargs):
        """Initialize settings with production overrides."""
&gt;       super().__init__(**kwargs)

app/config/settings.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

__pydantic_self__ = Settings(), _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.'), _env_file_encoding = None
_env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None, _cli_prog_name = None
_cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None, _cli_enforce_required = None
_cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None, _cli_ignore_unknown_args = None
_cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None, values = {}

    def __init__(
        __pydantic_self__,
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = ENV_FILE_SENTINEL,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
        **values: Any,
    ) -&gt; None:
        super().__init__(
&gt;           **__pydantic_self__._settings_build_values(
                values,
                _case_sensitive=_case_sensitive,
                _nested_model_default_partial_update=_nested_model_default_partial_update,
                _env_prefix=_env_prefix,
                _env_file=_env_file,
                _env_file_encoding=_env_file_encoding,
                _env_ignore_empty=_env_ignore_empty,
                _env_nested_delimiter=_env_nested_delimiter,
                _env_nested_max_split=_env_nested_max_split,
                _env_parse_none_str=_env_parse_none_str,
                _env_parse_enums=_env_parse_enums,
                _cli_prog_name=_cli_prog_name,
                _cli_parse_args=_cli_parse_args,
                _cli_settings_source=_cli_settings_source,
                _cli_parse_none_str=_cli_parse_none_str,
                _cli_hide_none_type=_cli_hide_none_type,
                _cli_avoid_json=_cli_avoid_json,
                _cli_enforce_required=_cli_enforce_required,
                _cli_use_class_docs_for_groups=_cli_use_class_docs_for_groups,
                _cli_exit_on_error=_cli_exit_on_error,
                _cli_prefix=_cli_prefix,
                _cli_flag_prefix_char=_cli_flag_prefix_char,
                _cli_implicit_flags=_cli_implicit_flags,
                _cli_ignore_unknown_args=_cli_ignore_unknown_args,
                _cli_kebab_case=_cli_kebab_case,
                _cli_shortcuts=_cli_shortcuts,
                _secrets_dir=_secrets_dir,
            )
        )

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), init_kwargs = {}, _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.')
_env_file_encoding = None, _env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None
_cli_prog_name = None, _cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None
_cli_enforce_required = None, _cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None
_cli_ignore_unknown_args = None, _cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None

    def _settings_build_values(
        self,
        init_kwargs: dict[str, Any],
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = None,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
    ) -&gt; dict[str, Any]:
        # Determine settings config values
        case_sensitive = _case_sensitive if _case_sensitive is not None else self.model_config.get('case_sensitive')
        env_prefix = _env_prefix if _env_prefix is not None else self.model_config.get('env_prefix')
        nested_model_default_partial_update = (
            _nested_model_default_partial_update
            if _nested_model_default_partial_update is not None
            else self.model_config.get('nested_model_default_partial_update')
        )
        env_file = _env_file if _env_file != ENV_FILE_SENTINEL else self.model_config.get('env_file')
        env_file_encoding = (
            _env_file_encoding if _env_file_encoding is not None else self.model_config.get('env_file_encoding')
        )
        env_ignore_empty = (
            _env_ignore_empty if _env_ignore_empty is not None else self.model_config.get('env_ignore_empty')
        )
        env_nested_delimiter = (
            _env_nested_delimiter
            if _env_nested_delimiter is not None
            else self.model_config.get('env_nested_delimiter')
        )
        env_nested_max_split = (
            _env_nested_max_split
            if _env_nested_max_split is not None
            else self.model_config.get('env_nested_max_split')
        )
        env_parse_none_str = (
            _env_parse_none_str if _env_parse_none_str is not None else self.model_config.get('env_parse_none_str')
        )
        env_parse_enums = _env_parse_enums if _env_parse_enums is not None else self.model_config.get('env_parse_enums')
    
        cli_prog_name = _cli_prog_name if _cli_prog_name is not None else self.model_config.get('cli_prog_name')
        cli_parse_args = _cli_parse_args if _cli_parse_args is not None else self.model_config.get('cli_parse_args')
        cli_settings_source = (
            _cli_settings_source if _cli_settings_source is not None else self.model_config.get('cli_settings_source')
        )
        cli_parse_none_str = (
            _cli_parse_none_str if _cli_parse_none_str is not None else self.model_config.get('cli_parse_none_str')
        )
        cli_parse_none_str = cli_parse_none_str if not env_parse_none_str else env_parse_none_str
        cli_hide_none_type = (
            _cli_hide_none_type if _cli_hide_none_type is not None else self.model_config.get('cli_hide_none_type')
        )
        cli_avoid_json = _cli_avoid_json if _cli_avoid_json is not None else self.model_config.get('cli_avoid_json')
        cli_enforce_required = (
            _cli_enforce_required
            if _cli_enforce_required is not None
            else self.model_config.get('cli_enforce_required')
        )
        cli_use_class_docs_for_groups = (
            _cli_use_class_docs_for_groups
            if _cli_use_class_docs_for_groups is not None
            else self.model_config.get('cli_use_class_docs_for_groups')
        )
        cli_exit_on_error = (
            _cli_exit_on_error if _cli_exit_on_error is not None else self.model_config.get('cli_exit_on_error')
        )
        cli_prefix = _cli_prefix if _cli_prefix is not None else self.model_config.get('cli_prefix')
        cli_flag_prefix_char = (
            _cli_flag_prefix_char
            if _cli_flag_prefix_char is not None
            else self.model_config.get('cli_flag_prefix_char')
        )
        cli_implicit_flags = (
            _cli_implicit_flags if _cli_implicit_flags is not None else self.model_config.get('cli_implicit_flags')
        )
        cli_ignore_unknown_args = (
            _cli_ignore_unknown_args
            if _cli_ignore_unknown_args is not None
            else self.model_config.get('cli_ignore_unknown_args')
        )
        cli_kebab_case = _cli_kebab_case if _cli_kebab_case is not None else self.model_config.get('cli_kebab_case')
        cli_shortcuts = _cli_shortcuts if _cli_shortcuts is not None else self.model_config.get('cli_shortcuts')
    
        secrets_dir = _secrets_dir if _secrets_dir is not None else self.model_config.get('secrets_dir')
    
        # Configure built-in sources
        default_settings = DefaultSettingsSource(
            self.__class__, nested_model_default_partial_update=nested_model_default_partial_update
        )
        init_settings = InitSettingsSource(
            self.__class__,
            init_kwargs=init_kwargs,
            nested_model_default_partial_update=nested_model_default_partial_update,
        )
        env_settings = EnvSettingsSource(
            self.__class__,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
        dotenv_settings = DotEnvSettingsSource(
            self.__class__,
            env_file=env_file,
            env_file_encoding=env_file_encoding,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
    
        file_secret_settings = SecretsSettingsSource(
            self.__class__, secrets_dir=secrets_dir, case_sensitive=case_sensitive, env_prefix=env_prefix
        )
        # Provide a hook to set built-in sources priority and add / remove sources
        sources = self.settings_customise_sources(
            self.__class__,
            init_settings=init_settings,
            env_settings=env_settings,
            dotenv_settings=dotenv_settings,
            file_secret_settings=file_secret_settings,
        ) + (default_settings,)
        if not any([source for source in sources if isinstance(source, CliSettingsSource)]):
            if isinstance(cli_settings_source, CliSettingsSource):
                sources = (cli_settings_source,) + sources
            elif cli_parse_args is not None:
                cli_settings = CliSettingsSource[Any](
                    self.__class__,
                    cli_prog_name=cli_prog_name,
                    cli_parse_args=cli_parse_args,
                    cli_parse_none_str=cli_parse_none_str,
                    cli_hide_none_type=cli_hide_none_type,
                    cli_avoid_json=cli_avoid_json,
                    cli_enforce_required=cli_enforce_required,
                    cli_use_class_docs_for_groups=cli_use_class_docs_for_groups,
                    cli_exit_on_error=cli_exit_on_error,
                    cli_prefix=cli_prefix,
                    cli_flag_prefix_char=cli_flag_prefix_char,
                    cli_implicit_flags=cli_implicit_flags,
                    cli_ignore_unknown_args=cli_ignore_unknown_args,
                    cli_kebab_case=cli_kebab_case,
                    cli_shortcuts=cli_shortcuts,
                    case_sensitive=case_sensitive,
                )
                sources = (cli_settings,) + sources
        if sources:
            state: dict[str, Any] = {}
            states: dict[str, dict[str, Any]] = {}
            for source in sources:
                if isinstance(source, PydanticBaseSettingsSource):
                    source._set_current_state(state)
                    source._set_settings_sources_data(states)
    
                source_name = source.__name__ if hasattr(source, '__name__') else type(source).__name__
&gt;               source_state = source()

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:424: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
                field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)
            except ValueError as e:
&gt;               raise SettingsError(
                    f'error parsing value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
E               pydantic_settings.exceptions.SettingsError: error parsing value for field "CORS_ORIGINS" from source "EnvSettingsSource"

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:492: SettingsError</failure></testcase><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_allowed_hosts_parsing" time="0.008"><failure message="pydantic_settings.exceptions.SettingsError: error parsing value for field &quot;ALLOWED_HOSTS&quot; from source &quot;EnvSettingsSource&quot;">self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
&gt;               field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
                    value = self.decode_complex_value(field_name, field, value)
                except ValueError as e:
                    if not allow_parse_failure:
&gt;                       raise e

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
&gt;                   value = self.decode_complex_value(field_name, field, value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'ALLOWED_HOSTS'
field = FieldInfo(annotation=List[str], required=False, default=['localhost', '127.0.0.1', '*']), value = 'localhost'

    def decode_complex_value(self, field_name: str, field: FieldInfo, value: Any) -&gt; Any:
        """
        Decode the value for a complex field
    
        Args:
            field_name: The field name.
            field: The field.
            value: The value of the field that has to be prepared.
    
        Returns:
            The decoded value for further preparation
        """
        if field and (
            NoDecode in field.metadata
            or (self.config.get('enable_decoding') is False and ForceDecode not in field.metadata)
        ):
            return value
    
&gt;       return json.loads(value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

s = 'localhost', cls = None, object_hook = None, parse_float = None, parse_int = None, parse_constant = None, object_pairs_hook = None, kw = {}

    def loads(s, *, cls=None, object_hook=None, parse_float=None,
            parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):
        """Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance
        containing a JSON document) to a Python object.
    
        ``object_hook`` is an optional function that will be called with the
        result of any object literal decode (a ``dict``). The return value of
        ``object_hook`` will be used instead of the ``dict``. This feature
        can be used to implement custom decoders (e.g. JSON-RPC class hinting).
    
        ``object_pairs_hook`` is an optional function that will be called with the
        result of any object literal decoded with an ordered list of pairs.  The
        return value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.  If ``object_hook``
        is also defined, the ``object_pairs_hook`` takes priority.
    
        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).
    
        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).
    
        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.
    
        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
        kwarg; otherwise ``JSONDecoder`` is used.
        """
        if isinstance(s, str):
            if s.startswith('\ufeff'):
                raise JSONDecodeError("Unexpected UTF-8 BOM (decode using utf-8-sig)",
                                      s, 0)
        else:
            if not isinstance(s, (bytes, bytearray)):
                raise TypeError(f'the JSON object must be str, bytes or bytearray, '
                                f'not {s.__class__.__name__}')
            s = s.decode(detect_encoding(s), 'surrogatepass')
    
        if (cls is None and object_hook is None and
                parse_int is None and parse_float is None and
                parse_constant is None and object_pairs_hook is None and not kw):
&gt;           return _default_decoder.decode(s)

/usr/local/lib/python3.11/json/__init__.py:346: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'localhost', _w = &lt;built-in method match of re.Pattern object at 0x7e3b274c57d0&gt;

    def decode(self, s, _w=WHITESPACE.match):
        """Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).
    
        """
&gt;       obj, end = self.raw_decode(s, idx=_w(s, 0).end())

/usr/local/lib/python3.11/json/decoder.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'localhost', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
&gt;           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

/usr/local/lib/python3.11/json/decoder.py:355: JSONDecodeError

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_config.test_settings.TestSettingsValidation object at 0x7e3b22fbf550&gt;

    def test_settings_allowed_hosts_parsing(self):
        """Test allowed hosts parsing."""
        base_env = {
            "DATABASE_URL": "postgresql://test:test@localhost/test",
            "REDIS_URL": "redis://localhost:6379/0",
            "JWT_SECRET_KEY": "test-secret-key-for-testing-32chars"
        }
    
        # Test single host
        with patch.dict(os.environ, {**base_env, "ALLOWED_HOSTS": "localhost"}, clear=True):
&gt;           settings = Settings()

tests/test_app/test_config/test_settings.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), kwargs = {}

    def __init__(self, **kwargs):
        """Initialize settings with production overrides."""
&gt;       super().__init__(**kwargs)

app/config/settings.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

__pydantic_self__ = Settings(), _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.'), _env_file_encoding = None
_env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None, _cli_prog_name = None
_cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None, _cli_enforce_required = None
_cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None, _cli_ignore_unknown_args = None
_cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None, values = {}

    def __init__(
        __pydantic_self__,
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = ENV_FILE_SENTINEL,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
        **values: Any,
    ) -&gt; None:
        super().__init__(
&gt;           **__pydantic_self__._settings_build_values(
                values,
                _case_sensitive=_case_sensitive,
                _nested_model_default_partial_update=_nested_model_default_partial_update,
                _env_prefix=_env_prefix,
                _env_file=_env_file,
                _env_file_encoding=_env_file_encoding,
                _env_ignore_empty=_env_ignore_empty,
                _env_nested_delimiter=_env_nested_delimiter,
                _env_nested_max_split=_env_nested_max_split,
                _env_parse_none_str=_env_parse_none_str,
                _env_parse_enums=_env_parse_enums,
                _cli_prog_name=_cli_prog_name,
                _cli_parse_args=_cli_parse_args,
                _cli_settings_source=_cli_settings_source,
                _cli_parse_none_str=_cli_parse_none_str,
                _cli_hide_none_type=_cli_hide_none_type,
                _cli_avoid_json=_cli_avoid_json,
                _cli_enforce_required=_cli_enforce_required,
                _cli_use_class_docs_for_groups=_cli_use_class_docs_for_groups,
                _cli_exit_on_error=_cli_exit_on_error,
                _cli_prefix=_cli_prefix,
                _cli_flag_prefix_char=_cli_flag_prefix_char,
                _cli_implicit_flags=_cli_implicit_flags,
                _cli_ignore_unknown_args=_cli_ignore_unknown_args,
                _cli_kebab_case=_cli_kebab_case,
                _cli_shortcuts=_cli_shortcuts,
                _secrets_dir=_secrets_dir,
            )
        )

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), init_kwargs = {}, _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.')
_env_file_encoding = None, _env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None
_cli_prog_name = None, _cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None
_cli_enforce_required = None, _cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None
_cli_ignore_unknown_args = None, _cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None

    def _settings_build_values(
        self,
        init_kwargs: dict[str, Any],
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = None,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
    ) -&gt; dict[str, Any]:
        # Determine settings config values
        case_sensitive = _case_sensitive if _case_sensitive is not None else self.model_config.get('case_sensitive')
        env_prefix = _env_prefix if _env_prefix is not None else self.model_config.get('env_prefix')
        nested_model_default_partial_update = (
            _nested_model_default_partial_update
            if _nested_model_default_partial_update is not None
            else self.model_config.get('nested_model_default_partial_update')
        )
        env_file = _env_file if _env_file != ENV_FILE_SENTINEL else self.model_config.get('env_file')
        env_file_encoding = (
            _env_file_encoding if _env_file_encoding is not None else self.model_config.get('env_file_encoding')
        )
        env_ignore_empty = (
            _env_ignore_empty if _env_ignore_empty is not None else self.model_config.get('env_ignore_empty')
        )
        env_nested_delimiter = (
            _env_nested_delimiter
            if _env_nested_delimiter is not None
            else self.model_config.get('env_nested_delimiter')
        )
        env_nested_max_split = (
            _env_nested_max_split
            if _env_nested_max_split is not None
            else self.model_config.get('env_nested_max_split')
        )
        env_parse_none_str = (
            _env_parse_none_str if _env_parse_none_str is not None else self.model_config.get('env_parse_none_str')
        )
        env_parse_enums = _env_parse_enums if _env_parse_enums is not None else self.model_config.get('env_parse_enums')
    
        cli_prog_name = _cli_prog_name if _cli_prog_name is not None else self.model_config.get('cli_prog_name')
        cli_parse_args = _cli_parse_args if _cli_parse_args is not None else self.model_config.get('cli_parse_args')
        cli_settings_source = (
            _cli_settings_source if _cli_settings_source is not None else self.model_config.get('cli_settings_source')
        )
        cli_parse_none_str = (
            _cli_parse_none_str if _cli_parse_none_str is not None else self.model_config.get('cli_parse_none_str')
        )
        cli_parse_none_str = cli_parse_none_str if not env_parse_none_str else env_parse_none_str
        cli_hide_none_type = (
            _cli_hide_none_type if _cli_hide_none_type is not None else self.model_config.get('cli_hide_none_type')
        )
        cli_avoid_json = _cli_avoid_json if _cli_avoid_json is not None else self.model_config.get('cli_avoid_json')
        cli_enforce_required = (
            _cli_enforce_required
            if _cli_enforce_required is not None
            else self.model_config.get('cli_enforce_required')
        )
        cli_use_class_docs_for_groups = (
            _cli_use_class_docs_for_groups
            if _cli_use_class_docs_for_groups is not None
            else self.model_config.get('cli_use_class_docs_for_groups')
        )
        cli_exit_on_error = (
            _cli_exit_on_error if _cli_exit_on_error is not None else self.model_config.get('cli_exit_on_error')
        )
        cli_prefix = _cli_prefix if _cli_prefix is not None else self.model_config.get('cli_prefix')
        cli_flag_prefix_char = (
            _cli_flag_prefix_char
            if _cli_flag_prefix_char is not None
            else self.model_config.get('cli_flag_prefix_char')
        )
        cli_implicit_flags = (
            _cli_implicit_flags if _cli_implicit_flags is not None else self.model_config.get('cli_implicit_flags')
        )
        cli_ignore_unknown_args = (
            _cli_ignore_unknown_args
            if _cli_ignore_unknown_args is not None
            else self.model_config.get('cli_ignore_unknown_args')
        )
        cli_kebab_case = _cli_kebab_case if _cli_kebab_case is not None else self.model_config.get('cli_kebab_case')
        cli_shortcuts = _cli_shortcuts if _cli_shortcuts is not None else self.model_config.get('cli_shortcuts')
    
        secrets_dir = _secrets_dir if _secrets_dir is not None else self.model_config.get('secrets_dir')
    
        # Configure built-in sources
        default_settings = DefaultSettingsSource(
            self.__class__, nested_model_default_partial_update=nested_model_default_partial_update
        )
        init_settings = InitSettingsSource(
            self.__class__,
            init_kwargs=init_kwargs,
            nested_model_default_partial_update=nested_model_default_partial_update,
        )
        env_settings = EnvSettingsSource(
            self.__class__,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
        dotenv_settings = DotEnvSettingsSource(
            self.__class__,
            env_file=env_file,
            env_file_encoding=env_file_encoding,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
    
        file_secret_settings = SecretsSettingsSource(
            self.__class__, secrets_dir=secrets_dir, case_sensitive=case_sensitive, env_prefix=env_prefix
        )
        # Provide a hook to set built-in sources priority and add / remove sources
        sources = self.settings_customise_sources(
            self.__class__,
            init_settings=init_settings,
            env_settings=env_settings,
            dotenv_settings=dotenv_settings,
            file_secret_settings=file_secret_settings,
        ) + (default_settings,)
        if not any([source for source in sources if isinstance(source, CliSettingsSource)]):
            if isinstance(cli_settings_source, CliSettingsSource):
                sources = (cli_settings_source,) + sources
            elif cli_parse_args is not None:
                cli_settings = CliSettingsSource[Any](
                    self.__class__,
                    cli_prog_name=cli_prog_name,
                    cli_parse_args=cli_parse_args,
                    cli_parse_none_str=cli_parse_none_str,
                    cli_hide_none_type=cli_hide_none_type,
                    cli_avoid_json=cli_avoid_json,
                    cli_enforce_required=cli_enforce_required,
                    cli_use_class_docs_for_groups=cli_use_class_docs_for_groups,
                    cli_exit_on_error=cli_exit_on_error,
                    cli_prefix=cli_prefix,
                    cli_flag_prefix_char=cli_flag_prefix_char,
                    cli_implicit_flags=cli_implicit_flags,
                    cli_ignore_unknown_args=cli_ignore_unknown_args,
                    cli_kebab_case=cli_kebab_case,
                    cli_shortcuts=cli_shortcuts,
                    case_sensitive=case_sensitive,
                )
                sources = (cli_settings,) + sources
        if sources:
            state: dict[str, Any] = {}
            states: dict[str, dict[str, Any]] = {}
            for source in sources:
                if isinstance(source, PydanticBaseSettingsSource):
                    source._set_current_state(state)
                    source._set_settings_sources_data(states)
    
                source_name = source.__name__ if hasattr(source, '__name__') else type(source).__name__
&gt;               source_state = source()

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:424: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
                field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)
            except ValueError as e:
&gt;               raise SettingsError(
                    f'error parsing value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
E               pydantic_settings.exceptions.SettingsError: error parsing value for field "ALLOWED_HOSTS" from source "EnvSettingsSource"

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:492: SettingsError</failure></testcase><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_database_url_parsing" time="0.011" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_redis_url_parsing" time="0.011" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsValidation" name="test_settings_environment_specific_defaults" time="0.013" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsProperties" name="test_settings_is_development" time="0.011" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsProperties" name="test_settings_is_testing" time="0.009" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsProperties" name="test_settings_database_config" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsProperties" name="test_settings_redis_config" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestGetSettings" name="test_get_settings_returns_settings_instance" time="0.006" /><testcase classname="tests.test_app.test_config.test_settings.TestGetSettings" name="test_get_settings_caching" time="0.009" /><testcase classname="tests.test_app.test_config.test_settings.TestGetSettings" name="test_get_settings_cache_clear" time="0.007" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_with_fastapi_app" time="0.009"><failure message="pydantic_settings.exceptions.SettingsError: error parsing value for field &quot;CORS_ORIGINS&quot; from source &quot;EnvSettingsSource&quot;">self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
&gt;               field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
                    value = self.decode_complex_value(field_name, field, value)
                except ValueError as e:
                    if not allow_parse_failure:
&gt;                       raise e

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000', value_is_complex = False

    def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:
        """
        Prepare value for the field.
    
        * Extract value for nested field.
        * Deserialize value to python object for complex field.
    
        Args:
            field: The field.
            field_name: The field name.
    
        Returns:
            A tuple contains prepared value for the field.
    
        Raises:
            ValuesError: When There is an error in deserializing value for complex field.
        """
        is_complex, allow_parse_failure = self._field_is_complex(field)
        if self.env_parse_enums:
            enum_val = _annotation_enum_name_to_val(field.annotation, value)
            value = value if enum_val is None else enum_val
    
        if is_complex or value_is_complex:
            if isinstance(value, EnvNoneType):
                return value
            elif value is None:
                # field is complex but no value found so far, try explode_env_vars
                env_val_built = self.explode_env_vars(field_name, field, self.env_vars)
                if env_val_built:
                    return env_val_built
            else:
                # field is complex and there's a value, decode that as JSON, then add explode_env_vars
                try:
&gt;                   value = self.decode_complex_value(field_name, field, value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/providers/env.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0), field_name = 'CORS_ORIGINS'
field = FieldInfo(annotation=List[str], required=False, default=['http://localhost:3000', 'http://localhost:8080']), value = 'http://localhost:3000'

    def decode_complex_value(self, field_name: str, field: FieldInfo, value: Any) -&gt; Any:
        """
        Decode the value for a complex field
    
        Args:
            field_name: The field name.
            field: The field.
            value: The value of the field that has to be prepared.
    
        Returns:
            The decoded value for further preparation
        """
        if field and (
            NoDecode in field.metadata
            or (self.config.get('enable_decoding') is False and ForceDecode not in field.metadata)
        ):
            return value
    
&gt;       return json.loads(value)

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

s = 'http://localhost:3000', cls = None, object_hook = None, parse_float = None, parse_int = None, parse_constant = None, object_pairs_hook = None, kw = {}

    def loads(s, *, cls=None, object_hook=None, parse_float=None,
            parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):
        """Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance
        containing a JSON document) to a Python object.
    
        ``object_hook`` is an optional function that will be called with the
        result of any object literal decode (a ``dict``). The return value of
        ``object_hook`` will be used instead of the ``dict``. This feature
        can be used to implement custom decoders (e.g. JSON-RPC class hinting).
    
        ``object_pairs_hook`` is an optional function that will be called with the
        result of any object literal decoded with an ordered list of pairs.  The
        return value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.  If ``object_hook``
        is also defined, the ``object_pairs_hook`` takes priority.
    
        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).
    
        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).
    
        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.
    
        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
        kwarg; otherwise ``JSONDecoder`` is used.
        """
        if isinstance(s, str):
            if s.startswith('\ufeff'):
                raise JSONDecodeError("Unexpected UTF-8 BOM (decode using utf-8-sig)",
                                      s, 0)
        else:
            if not isinstance(s, (bytes, bytearray)):
                raise TypeError(f'the JSON object must be str, bytes or bytearray, '
                                f'not {s.__class__.__name__}')
            s = s.decode(detect_encoding(s), 'surrogatepass')
    
        if (cls is None and object_hook is None and
                parse_int is None and parse_float is None and
                parse_constant is None and object_pairs_hook is None and not kw):
&gt;           return _default_decoder.decode(s)

/usr/local/lib/python3.11/json/__init__.py:346: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'http://localhost:3000', _w = &lt;built-in method match of re.Pattern object at 0x7e3b274c57d0&gt;

    def decode(self, s, _w=WHITESPACE.match):
        """Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).
    
        """
&gt;       obj, end = self.raw_decode(s, idx=_w(s, 0).end())

/usr/local/lib/python3.11/json/decoder.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;json.decoder.JSONDecoder object at 0x7e3b273f6850&gt;, s = 'http://localhost:3000', idx = 0

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.
    
        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.
    
        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration as err:
&gt;           raise JSONDecodeError("Expecting value", s, err.value) from None
E           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

/usr/local/lib/python3.11/json/decoder.py:355: JSONDecodeError

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_config.test_settings.TestSettingsIntegration object at 0x7e3b22ea3190&gt;

    def test_settings_with_fastapi_app(self):
        """Test settings integration with FastAPI application."""
        with patch.dict(os.environ, {
            "DATABASE_URL": "postgresql://test:test@localhost/test",
            "REDIS_URL": "redis://localhost:6379/0",
            "JWT_SECRET_KEY": "test-secret-key-for-testing-32chars",
            "DEBUG": "true",
            "CORS_ORIGINS": "http://localhost:3000"
        }, clear=True):
&gt;           settings = Settings()

tests/test_app/test_config/test_settings.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), kwargs = {}

    def __init__(self, **kwargs):
        """Initialize settings with production overrides."""
&gt;       super().__init__(**kwargs)

app/config/settings.py:171: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

__pydantic_self__ = Settings(), _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.'), _env_file_encoding = None
_env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None, _cli_prog_name = None
_cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None, _cli_enforce_required = None
_cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None, _cli_ignore_unknown_args = None
_cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None, values = {}

    def __init__(
        __pydantic_self__,
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = ENV_FILE_SENTINEL,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
        **values: Any,
    ) -&gt; None:
        super().__init__(
&gt;           **__pydantic_self__._settings_build_values(
                values,
                _case_sensitive=_case_sensitive,
                _nested_model_default_partial_update=_nested_model_default_partial_update,
                _env_prefix=_env_prefix,
                _env_file=_env_file,
                _env_file_encoding=_env_file_encoding,
                _env_ignore_empty=_env_ignore_empty,
                _env_nested_delimiter=_env_nested_delimiter,
                _env_nested_max_split=_env_nested_max_split,
                _env_parse_none_str=_env_parse_none_str,
                _env_parse_enums=_env_parse_enums,
                _cli_prog_name=_cli_prog_name,
                _cli_parse_args=_cli_parse_args,
                _cli_settings_source=_cli_settings_source,
                _cli_parse_none_str=_cli_parse_none_str,
                _cli_hide_none_type=_cli_hide_none_type,
                _cli_avoid_json=_cli_avoid_json,
                _cli_enforce_required=_cli_enforce_required,
                _cli_use_class_docs_for_groups=_cli_use_class_docs_for_groups,
                _cli_exit_on_error=_cli_exit_on_error,
                _cli_prefix=_cli_prefix,
                _cli_flag_prefix_char=_cli_flag_prefix_char,
                _cli_implicit_flags=_cli_implicit_flags,
                _cli_ignore_unknown_args=_cli_ignore_unknown_args,
                _cli_kebab_case=_cli_kebab_case,
                _cli_shortcuts=_cli_shortcuts,
                _secrets_dir=_secrets_dir,
            )
        )

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Settings(), init_kwargs = {}, _case_sensitive = None, _nested_model_default_partial_update = None, _env_prefix = None, _env_file = PosixPath('.')
_env_file_encoding = None, _env_ignore_empty = None, _env_nested_delimiter = None, _env_nested_max_split = None, _env_parse_none_str = None, _env_parse_enums = None
_cli_prog_name = None, _cli_parse_args = None, _cli_settings_source = None, _cli_parse_none_str = None, _cli_hide_none_type = None, _cli_avoid_json = None
_cli_enforce_required = None, _cli_use_class_docs_for_groups = None, _cli_exit_on_error = None, _cli_prefix = None, _cli_flag_prefix_char = None, _cli_implicit_flags = None
_cli_ignore_unknown_args = None, _cli_kebab_case = None, _cli_shortcuts = None, _secrets_dir = None

    def _settings_build_values(
        self,
        init_kwargs: dict[str, Any],
        _case_sensitive: bool | None = None,
        _nested_model_default_partial_update: bool | None = None,
        _env_prefix: str | None = None,
        _env_file: DotenvType | None = None,
        _env_file_encoding: str | None = None,
        _env_ignore_empty: bool | None = None,
        _env_nested_delimiter: str | None = None,
        _env_nested_max_split: int | None = None,
        _env_parse_none_str: str | None = None,
        _env_parse_enums: bool | None = None,
        _cli_prog_name: str | None = None,
        _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,
        _cli_settings_source: CliSettingsSource[Any] | None = None,
        _cli_parse_none_str: str | None = None,
        _cli_hide_none_type: bool | None = None,
        _cli_avoid_json: bool | None = None,
        _cli_enforce_required: bool | None = None,
        _cli_use_class_docs_for_groups: bool | None = None,
        _cli_exit_on_error: bool | None = None,
        _cli_prefix: str | None = None,
        _cli_flag_prefix_char: str | None = None,
        _cli_implicit_flags: bool | None = None,
        _cli_ignore_unknown_args: bool | None = None,
        _cli_kebab_case: bool | None = None,
        _cli_shortcuts: Mapping[str, str | list[str]] | None = None,
        _secrets_dir: PathType | None = None,
    ) -&gt; dict[str, Any]:
        # Determine settings config values
        case_sensitive = _case_sensitive if _case_sensitive is not None else self.model_config.get('case_sensitive')
        env_prefix = _env_prefix if _env_prefix is not None else self.model_config.get('env_prefix')
        nested_model_default_partial_update = (
            _nested_model_default_partial_update
            if _nested_model_default_partial_update is not None
            else self.model_config.get('nested_model_default_partial_update')
        )
        env_file = _env_file if _env_file != ENV_FILE_SENTINEL else self.model_config.get('env_file')
        env_file_encoding = (
            _env_file_encoding if _env_file_encoding is not None else self.model_config.get('env_file_encoding')
        )
        env_ignore_empty = (
            _env_ignore_empty if _env_ignore_empty is not None else self.model_config.get('env_ignore_empty')
        )
        env_nested_delimiter = (
            _env_nested_delimiter
            if _env_nested_delimiter is not None
            else self.model_config.get('env_nested_delimiter')
        )
        env_nested_max_split = (
            _env_nested_max_split
            if _env_nested_max_split is not None
            else self.model_config.get('env_nested_max_split')
        )
        env_parse_none_str = (
            _env_parse_none_str if _env_parse_none_str is not None else self.model_config.get('env_parse_none_str')
        )
        env_parse_enums = _env_parse_enums if _env_parse_enums is not None else self.model_config.get('env_parse_enums')
    
        cli_prog_name = _cli_prog_name if _cli_prog_name is not None else self.model_config.get('cli_prog_name')
        cli_parse_args = _cli_parse_args if _cli_parse_args is not None else self.model_config.get('cli_parse_args')
        cli_settings_source = (
            _cli_settings_source if _cli_settings_source is not None else self.model_config.get('cli_settings_source')
        )
        cli_parse_none_str = (
            _cli_parse_none_str if _cli_parse_none_str is not None else self.model_config.get('cli_parse_none_str')
        )
        cli_parse_none_str = cli_parse_none_str if not env_parse_none_str else env_parse_none_str
        cli_hide_none_type = (
            _cli_hide_none_type if _cli_hide_none_type is not None else self.model_config.get('cli_hide_none_type')
        )
        cli_avoid_json = _cli_avoid_json if _cli_avoid_json is not None else self.model_config.get('cli_avoid_json')
        cli_enforce_required = (
            _cli_enforce_required
            if _cli_enforce_required is not None
            else self.model_config.get('cli_enforce_required')
        )
        cli_use_class_docs_for_groups = (
            _cli_use_class_docs_for_groups
            if _cli_use_class_docs_for_groups is not None
            else self.model_config.get('cli_use_class_docs_for_groups')
        )
        cli_exit_on_error = (
            _cli_exit_on_error if _cli_exit_on_error is not None else self.model_config.get('cli_exit_on_error')
        )
        cli_prefix = _cli_prefix if _cli_prefix is not None else self.model_config.get('cli_prefix')
        cli_flag_prefix_char = (
            _cli_flag_prefix_char
            if _cli_flag_prefix_char is not None
            else self.model_config.get('cli_flag_prefix_char')
        )
        cli_implicit_flags = (
            _cli_implicit_flags if _cli_implicit_flags is not None else self.model_config.get('cli_implicit_flags')
        )
        cli_ignore_unknown_args = (
            _cli_ignore_unknown_args
            if _cli_ignore_unknown_args is not None
            else self.model_config.get('cli_ignore_unknown_args')
        )
        cli_kebab_case = _cli_kebab_case if _cli_kebab_case is not None else self.model_config.get('cli_kebab_case')
        cli_shortcuts = _cli_shortcuts if _cli_shortcuts is not None else self.model_config.get('cli_shortcuts')
    
        secrets_dir = _secrets_dir if _secrets_dir is not None else self.model_config.get('secrets_dir')
    
        # Configure built-in sources
        default_settings = DefaultSettingsSource(
            self.__class__, nested_model_default_partial_update=nested_model_default_partial_update
        )
        init_settings = InitSettingsSource(
            self.__class__,
            init_kwargs=init_kwargs,
            nested_model_default_partial_update=nested_model_default_partial_update,
        )
        env_settings = EnvSettingsSource(
            self.__class__,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
        dotenv_settings = DotEnvSettingsSource(
            self.__class__,
            env_file=env_file,
            env_file_encoding=env_file_encoding,
            case_sensitive=case_sensitive,
            env_prefix=env_prefix,
            env_nested_delimiter=env_nested_delimiter,
            env_nested_max_split=env_nested_max_split,
            env_ignore_empty=env_ignore_empty,
            env_parse_none_str=env_parse_none_str,
            env_parse_enums=env_parse_enums,
        )
    
        file_secret_settings = SecretsSettingsSource(
            self.__class__, secrets_dir=secrets_dir, case_sensitive=case_sensitive, env_prefix=env_prefix
        )
        # Provide a hook to set built-in sources priority and add / remove sources
        sources = self.settings_customise_sources(
            self.__class__,
            init_settings=init_settings,
            env_settings=env_settings,
            dotenv_settings=dotenv_settings,
            file_secret_settings=file_secret_settings,
        ) + (default_settings,)
        if not any([source for source in sources if isinstance(source, CliSettingsSource)]):
            if isinstance(cli_settings_source, CliSettingsSource):
                sources = (cli_settings_source,) + sources
            elif cli_parse_args is not None:
                cli_settings = CliSettingsSource[Any](
                    self.__class__,
                    cli_prog_name=cli_prog_name,
                    cli_parse_args=cli_parse_args,
                    cli_parse_none_str=cli_parse_none_str,
                    cli_hide_none_type=cli_hide_none_type,
                    cli_avoid_json=cli_avoid_json,
                    cli_enforce_required=cli_enforce_required,
                    cli_use_class_docs_for_groups=cli_use_class_docs_for_groups,
                    cli_exit_on_error=cli_exit_on_error,
                    cli_prefix=cli_prefix,
                    cli_flag_prefix_char=cli_flag_prefix_char,
                    cli_implicit_flags=cli_implicit_flags,
                    cli_ignore_unknown_args=cli_ignore_unknown_args,
                    cli_kebab_case=cli_kebab_case,
                    cli_shortcuts=cli_shortcuts,
                    case_sensitive=case_sensitive,
                )
                sources = (cli_settings,) + sources
        if sources:
            state: dict[str, Any] = {}
            states: dict[str, dict[str, Any]] = {}
            for source in sources:
                if isinstance(source, PydanticBaseSettingsSource):
                    source._set_current_state(state)
                    source._set_settings_sources_data(states)
    
                source_name = source.__name__ if hasattr(source, '__name__') else type(source).__name__
&gt;               source_state = source()

.venv/lib/python3.11/site-packages/pydantic_settings/main.py:424: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnvSettingsSource(env_nested_delimiter=None, env_prefix_len=0)

    def __call__(self) -&gt; dict[str, Any]:
        data: dict[str, Any] = {}
    
        for field_name, field in self.settings_cls.model_fields.items():
            try:
                field_value, field_key, value_is_complex = self._get_resolved_field_value(field, field_name)
            except Exception as e:
                raise SettingsError(
                    f'error getting value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
    
            try:
                field_value = self.prepare_field_value(field_name, field, field_value, value_is_complex)
            except ValueError as e:
&gt;               raise SettingsError(
                    f'error parsing value for field "{field_name}" from source "{self.__class__.__name__}"'
                ) from e
E               pydantic_settings.exceptions.SettingsError: error parsing value for field "CORS_ORIGINS" from source "EnvSettingsSource"

.venv/lib/python3.11/site-packages/pydantic_settings/sources/base.py:492: SettingsError</failure></testcase><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_security_configuration" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_token_configuration" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_environment_detection[development-True]" time="0.007" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_environment_detection[testing-False]" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsIntegration" name="test_settings_environment_detection[production-False]" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsErrorHandling" name="test_settings_validation_error_messages" time="0.007" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsErrorHandling" name="test_settings_type_conversion_errors" time="0.008" /><testcase classname="tests.test_app.test_config.test_settings.TestSettingsErrorHandling" name="test_settings_url_validation_errors" time="0.012"><failure message="Failed: DID NOT RAISE &lt;class 'pydantic_core._pydantic_core.ValidationError'&gt;">self = &lt;tests.test_app.test_config.test_settings.TestSettingsErrorHandling object at 0x7e3b22c0c610&gt;

    def test_settings_url_validation_errors(self):
        """Test URL validation error handling."""
        base_env = {
            "REDIS_URL": "redis://localhost:6379/0",
            "JWT_SECRET_KEY": "test-secret-key-for-testing-32chars"
        }
    
        # Test invalid database URL
        with patch.dict(os.environ, {**base_env, "DATABASE_URL": "not-a-valid-url"}, clear=True):
&gt;           with pytest.raises(ValidationError) as exc_info:
E           Failed: DID NOT RAISE &lt;class 'pydantic_core._pydantic_core.ValidationError'&gt;

tests/test_app/test_config/test_settings.py:509: Failed</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_creation" time="0.028" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_creation_minimal" time="0.014" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_unique_name_constraint" time="0.013" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_string_representation" time="0.006" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_string_representation_no_description" time="0.006" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_scope_relationship" time="0.025" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_user_relationship" time="0.213"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22bc4c90&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b21fd79d0&gt;

    @pytest.mark.unit
    async def test_role_user_relationship(self, db_session: AsyncSession):
        """Test role-user many-to-many relationship."""
        # Create role and users
        role = Role(name="moderator", description="Moderator role")
        user1 = User(
            username="mod1",
            email="mod1@example.com",
            password_hash=hash_password("ModPassword123!")
        )
        user2 = User(
            username="mod2",
            email="mod2@example.com",
            password_hash=hash_password("ModPassword123!")
        )
    
        db_session.add_all([role, user1, user2])
        await db_session.commit()
        await db_session.refresh(role)
    
        # Assign role to users
&gt;       user1.roles.append(role)

tests/test_app/test_models/test_role.py:133: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b232fac00&gt;
instance = &lt;User(id=e626fffb-5f42-4baa-8c45-c7a1e4a036ac, username='mod1', email='mod1@example.com')&gt;, owner = &lt;class 'app.models.user.User'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4eae0&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;, 'created_at': datetime.datetime(... 7, 27, 11, 20, 3, 679796, tzinfo=datetime.timezone.utc), 'email': 'mod1@example.com', 'failed_login_attempts': 0, ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4eae0&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;, key = 'roles'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22eae500&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22eae500&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b21fd5550&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b21fd5550&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;
params = {'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b21fd5550&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;
params = {'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
        conn = self._connection_for_bind(bind)
    
        if _scalar_result and not compile_state_cls:
            if TYPE_CHECKING:
                params = cast(_CoreSingleExecuteParams, params)
            return conn.scalar(
                statement, params or {}, execution_options=execution_options
            )
    
        if compile_state_cls:
&gt;           result: Result[Any] = compile_state_cls.orm_execute_statement(
                self,
                statement,
                params or {},
                execution_options,
                bind_arguments,
                conn,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.orm.context.ORMSelectCompileState'&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b21fd5550&gt;
statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;, params = {'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;), '_result_disable_adapt_to_context': True})
bind_arguments = {'clause': &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;, 'mapper': &lt;Mapper at 0x7e3b24342650; Role&gt;}
conn = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;

    @classmethod
    def orm_execute_statement(
        cls,
        session,
        statement,
        params,
        execution_options,
        bind_arguments,
        conn,
    ) -&gt; Result:
&gt;       result = conn.execute(
            statement, params or {}, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/context.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;
parameters = {'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -&gt; CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
&gt;           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1415: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;, connection = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;
distilled_params = [{'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;), '_result_disable_adapt_to_context': True})

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
&gt;           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:523: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;, elem = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21d48450&gt;
distilled_parameters = [{'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;), '_result_disable_adapt_to_context': True})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) &gt; 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
&gt;       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
constructor = &lt;bound method DefaultExecutionContext._init_compiled of &lt;class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'&gt;&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22e68c90&gt;
parameters = [{'%(138792451552080 param)s': UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3dd0&gt;), '_result_disable_adapt_to_context': True})
args = (&lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22e68c90&gt;, [{'%(138792451552080 param)s': ...selectable.Select object at 0x7e3b21d48450&gt;, [AnnotatedBindParameter('%(138792451552080 param)s', None, type_=UUID())])
kw = {'cache_hit': &lt;CacheStats.CACHE_HIT: 0&gt;}, yp = None, conn = &lt;sqlalchemy.pool.base._ConnectionFairy object at 0x7e3b20fc12b0&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21d496d0&gt;

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -&gt; CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
&gt;           return self._exec_single_context(
                dialect, context, statement, parameters
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1842: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21d496d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22e68c90&gt;, parameters = [(UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
&gt;           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;
e = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
statement = 'SELECT roles.name AS roles_name, roles.description AS roles_description, roles.id AS roles_id, roles.created_at AS ro...t AS roles_updated_at \nFROM roles, user_roles \nWHERE $1::UUID = user_roles.user_id AND roles.id = user_roles.role_id'
parameters = (UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac'),), cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fc0e20&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21d496d0&gt;, is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -&gt; NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-&gt; test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
                raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
            else:
                assert exc_info[1] is not None
&gt;               raise exc_info[1].with_traceback(exc_info[2])

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21190a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21d496d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22e68c90&gt;, parameters = [(UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fc0e20&gt;
statement = 'SELECT roles.name AS roles_name, roles.description AS roles_description, roles.id AS roles_id, roles.created_at AS ro...t AS roles_updated_at \nFROM roles, user_roles \nWHERE $1::UUID = user_roles.user_id AND roles.id = user_roles.role_id'
parameters = (UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac'),), context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21d496d0&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fc0e20&gt;
operation = 'SELECT roles.name AS roles_name, roles.description AS roles_description, roles.id AS roles_id, roles.created_at AS ro...t AS roles_updated_at \nFROM roles, user_roles \nWHERE $1::UUID = user_roles.user_id AND roles.id = user_roles.role_id'
parameters = (UUID('e626fffb-5f42-4baa-8c45-c7a1e4a036ac'),)

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21f0bd00&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_cascade_behavior" time="0.162"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22bc5b10&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b22a89c10&gt;

    @pytest.mark.unit
    async def test_role_cascade_behavior(self, db_session: AsyncSession):
        """Test role cascade behavior with relationships."""
        # Create role with scopes and users
        role = Role(name="temp_role", description="Temporary role")
        scope = Scope(name="temp:scope", description="Temporary scope", resource="temp")
        user = User(
            username="tempuser",
            email="temp@example.com",
            password_hash=hash_password("TempPassword123!")
        )
    
        db_session.add_all([role, scope, user])
        await db_session.commit()
    
        # Create relationships
&gt;       role.scopes.append(scope)

tests/test_app/test_models/test_role.py:160: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='temp_role', description='Temporary role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;, 'created_at': datetime.datetime(...zinfo=datetime.timezone.utc), 'description': 'Temporary role', 'id': UUID('9180ea9b-d088-44b5-94c8-0205ed328267'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22a89210&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e96270&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22a89210&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20bddad0&gt;
params = {'%(138792450297040 param)s': UUID('9180ea9b-d088-44b5-94c8-0205ed328267')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22a89210&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20bddad0&gt;
params = {'%(138792450297040 param)s': UUID('9180ea9b-d088-44b5-94c8-0205ed328267')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22a89210&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21f916d0&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21f916d0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21f916d0&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21f916d0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20bdfe90&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b20909870&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1ad40&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1ad40&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1ad40&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1ad40&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1ad40&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ebf5a0&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_to_dict" time="0.006" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_get_scope_names" time="0.045"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22eb1850&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b207cf010&gt;

    @pytest.mark.unit
    async def test_role_get_scope_names(self, db_session: AsyncSession):
        """Test getting scope names from role."""
        role = Role(name="content_manager", description="Content manager role")
        scope1 = Scope(name="read:content", description="Read content", resource="content")
        scope2 = Scope(name="write:content", description="Write content", resource="content")
        scope3 = Scope(name="publish:content", description="Publish content", resource="content")
    
        db_session.add_all([role, scope1, scope2, scope3])
        await db_session.commit()
    
        # Add scopes to role
&gt;       role.scopes.extend([scope1, scope2, scope3])

tests/test_app/test_models/test_role.py:207: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='content_manager', description='Content manager role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;, 'created_at': datetime.datetime(...datetime.timezone.utc), 'description': 'Content manager role', 'id': UUID('9892a82b-9dd2-40fa-aad6-1d53243e2e1d'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b207cfcd0&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20c5c590&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b207cfcd0&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b207cce90&gt;
params = {'%(138792450297040 param)s': UUID('9892a82b-9dd2-40fa-aad6-1d53243e2e1d')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b207cfcd0&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b207cce90&gt;
params = {'%(138792450297040 param)s': UUID('9892a82b-9dd2-40fa-aad6-1d53243e2e1d')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b207cfcd0&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b201e0870&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b201e0870&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b201e0870&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b201e0870&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b207cdb50&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b20256c20&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22b97c40&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22b97c40&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22b97c40&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22b97c40&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22b97c40&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21cdf680&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_has_scope" time="0.040"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22eb12d0&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b20946410&gt;

    @pytest.mark.unit
    async def test_role_has_scope(self, db_session: AsyncSession):
        """Test checking if role has specific scope."""
        role = Role(name="reviewer", description="Reviewer role")
        read_scope = Scope(name="read:reviews", description="Read reviews", resource="reviews")
        write_scope = Scope(name="write:reviews", description="Write reviews", resource="reviews")
        admin_scope = Scope(name="admin:reviews", description="Admin reviews", resource="reviews")
    
        db_session.add_all([role, read_scope, write_scope, admin_scope])
        await db_session.commit()
    
        # Add only read and write scopes
&gt;       role.scopes.extend([read_scope, write_scope])

tests/test_app/test_models/test_role.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='reviewer', description='Reviewer role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;, 'created_at': datetime.datetime(...tzinfo=datetime.timezone.utc), 'description': 'Reviewer role', 'id': UUID('03a40c00-7760-4839-b691-8001ad57408f'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20944a90&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b2292d4f0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20944a90&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20945c90&gt;
params = {'%(138792450297040 param)s': UUID('03a40c00-7760-4839-b691-8001ad57408f')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20944a90&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20945c90&gt;
params = {'%(138792450297040 param)s': UUID('03a40c00-7760-4839-b691-8001ad57408f')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20944a90&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024c80&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024c80&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024c80&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024c80&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20944e50&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b209ccc40&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f20d60&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f20d60&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f20d60&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f20d60&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f20d60&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ef1460&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_get_permissions" time="0.042"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22eb1450&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b20c06f50&gt;

    @pytest.mark.unit
    async def test_role_get_permissions(self, db_session: AsyncSession):
        """Test getting all permissions from role scopes."""
        role = Role(name="manager", description="Manager role")
    
        # Create scopes with different resources and actions
        scopes = [
            Scope(name="read:users", description="Read users", resource="users"),
            Scope(name="write:users", description="Write users", resource="users"),
            Scope(name="read:reports", description="Read reports", resource="reports"),
            Scope(name="admin:settings", description="Admin settings", resource="settings")
        ]
    
        db_session.add_all([role] + scopes)
        await db_session.commit()
    
&gt;       role.scopes.extend(scopes)

tests/test_app/test_models/test_role.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='manager', description='Manager role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;, 'created_at': datetime.datetime(... tzinfo=datetime.timezone.utc), 'description': 'Manager role', 'id': UUID('567a87c7-bc55-4269-b657-55568791aaa8'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20c06d50&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fc3290&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20c06d50&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20c06790&gt;
params = {'%(138792450297040 param)s': UUID('567a87c7-bc55-4269-b657-55568791aaa8')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20c06d50&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b20c06790&gt;
params = {'%(138792450297040 param)s': UUID('567a87c7-bc55-4269-b657-55568791aaa8')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20c06d50&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21e45ef0&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21e45ef0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21e45ef0&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21e45ef0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c04a90&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b1b8d5900&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227fb970&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227fb970&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227fb970&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227fb970&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227fb970&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ef09e0&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_can_access_resource" time="0.040"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b22eb33d0&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1b8520d0&gt;

    @pytest.mark.unit
    async def test_role_can_access_resource(self, db_session: AsyncSession):
        """Test checking resource access permissions."""
        role = Role(name="support", description="Support role")
    
        scopes = [
            Scope(name="read:tickets", description="Read tickets", resource="tickets"),
            Scope(name="write:tickets", description="Write tickets", resource="tickets"),
            Scope(name="read:users", description="Read users", resource="users")
        ]
    
        db_session.add_all([role] + scopes)
        await db_session.commit()
    
&gt;       role.scopes.extend(scopes)

tests/test_app/test_models/test_role.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='support', description='Support role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;, 'created_at': datetime.datetime(... tzinfo=datetime.timezone.utc), 'description': 'Support role', 'id': UUID('973dc25d-abaa-4dd0-bcd4-9c5c3418c312'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b851fd0&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20e950d0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b851fd0&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1b852510&gt;
params = {'%(138792450297040 param)s': UUID('973dc25d-abaa-4dd0-bcd4-9c5c3418c312')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b851fd0&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1b852510&gt;
params = {'%(138792450297040 param)s': UUID('973dc25d-abaa-4dd0-bcd4-9c5c3418c312')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b851fd0&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024ff0&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024ff0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024ff0&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21024ff0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1b851650&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b2028a260&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227f97b0&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227f97b0&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227f97b0&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227f97b0&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b227f97b0&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ef1d20&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_hierarchy_support" time="0.038"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b229e9610&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b202b5c90&gt;

    @pytest.mark.unit
    async def test_role_hierarchy_support(self, db_session: AsyncSession):
        """Test role hierarchy functionality."""
        # Create parent and child roles
        admin_role = Role(name="admin", description="Administrator role")
        manager_role = Role(name="manager", description="Manager role")
        user_role = Role(name="user", description="User role")
    
        # Create scopes for different levels
        admin_scope = Scope(name="admin:system", description="System admin", resource="system")
        manager_scope = Scope(name="manage:users", description="Manage users", resource="users")
        user_scope = Scope(name="read:profile", description="Read profile", resource="profile")
    
        db_session.add_all([admin_role, manager_role, user_role, admin_scope, manager_scope, user_scope])
        await db_session.commit()
    
        # Set up hierarchy: admin &gt; manager &gt; user
&gt;       admin_role.scopes.extend([admin_scope, manager_scope, user_scope])

tests/test_app/test_models/test_role.py:312: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='admin', description='Administrator role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;, 'created_at': datetime.datetime(...o=datetime.timezone.utc), 'description': 'Administrator role', 'id': UUID('be0a3773-87c4-481b-8fbe-f45f43a48709'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b202b6f10&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20cea0f0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b202b6f10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b202b5010&gt;
params = {'%(138792450297040 param)s': UUID('be0a3773-87c4-481b-8fbe-f45f43a48709')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b202b6f10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b202b5010&gt;
params = {'%(138792450297040 param)s': UUID('be0a3773-87c4-481b-8fbe-f45f43a48709')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b202b6f10&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21026850&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21026850&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21026850&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b21026850&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b202b5250&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b207291b0&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22ab7c40&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22ab7c40&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22ab7c40&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22ab7c40&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22ab7c40&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ebf5a0&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_query_methods" time="0.025" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_validation" time="0.007" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_equality" time="0.006" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_hash" time="0.007" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_audit_fields" time="0.036" /><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_soft_delete" time="0.019"><failure message="sqlalchemy.exc.DBAPIError: (sqlalchemy.dialects.postgresql.asyncpg.Error) &lt;class 'asyncpg.exceptions.StringDataRightTruncationError'&gt;: value too long for type character varying(50)&#10;[SQL: UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID]&#10;[parameters: ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))]&#10;(Background on this error at: https://sqlalche.me/e/20/dbapi)">self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
operation = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
&gt;                   self._rows = deque(await prepared_stmt.fetch(*parameters))

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b20da1d50&gt;, timeout = None
args = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    @connresource.guarded
    async def fetch(self, *args, timeout=None):
        r"""Execute the statement and return a list of :class:`Record` objects.
    
        :param str query: Query text
        :param args: Query arguments
        :param float timeout: Optional timeout value in seconds.
    
        :return: A list of :class:`Record` instances.
        """
&gt;       data = await self.__bind_execute(args, 0, timeout)

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b20da1d50&gt;
args = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646')), limit = 0, timeout = None

    async def __bind_execute(self, args, limit, timeout):
&gt;       data, status, _ = await self.__do_execute(
            lambda protocol: protocol.bind_execute(
                self._state, args, '', limit, True, timeout))

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b20da1d50&gt;, executor = &lt;function PreparedStatement.__bind_execute.&lt;locals&gt;.&lt;lambda&gt; at 0x7e3b20cf62a0&gt;

    async def __do_execute(self, executor):
        protocol = self._connection._protocol
        try:
&gt;           return await executor(protocol)

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

&gt;   ???
E   asyncpg.exceptions.StringDataRightTruncationError: value too long for type character varying(50)

asyncpg/protocol/protocol.pyx:207: StringDataRightTruncationError

The above exception was the direct cause of the following exception:

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b20c16d10&gt;
parameters = [('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
statement = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
operation = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21da9000&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
&gt;       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b21ceff40 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b20a45220&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
&gt;               value = await result

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
operation = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
&gt;               self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:558: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
error = StringDataRightTruncationError('value too long for type character varying(50)')

    def _handle_exception(self, error):
&gt;       self._adapt_connection._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;, error = StringDataRightTruncationError('value too long for type character varying(50)')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
&gt;                   raise translated_error from error
E                   sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.Error: &lt;class 'asyncpg.exceptions.StringDataRightTruncationError'&gt;: value too long for type character varying(50)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:792: Error

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b229e9e10&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b21d0c490&gt;

    @pytest.mark.unit
    async def test_role_soft_delete(self, db_session: AsyncSession):
        """Test role soft delete functionality if implemented."""
        role = Role(name="deletable_role", description="Role to be deleted")
    
        db_session.add(role)
        await db_session.commit()
        await db_session.refresh(role)
    
        role_id = role.id
    
        # Soft delete
        role.soft_delete()
&gt;       await db_session.commit()

tests/test_app/test_models/test_role.py:458: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b21d0c490&gt;

    async def commit(self) -&gt; None:
        """Commit the current transaction in progress.
    
        .. seealso::
    
            :meth:`_orm.Session.commit` - main documentation for
            "commit"
        """
&gt;       await greenlet_spawn(self.sync_session.commit)

.venv/lib/python3.11/site-packages/sqlalchemy/ext/asyncio/session.py:1014: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b21ceff40 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b20a45220&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
                result = context.throw(*sys.exc_info())
            else:
&gt;               result = context.switch(value)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;

    def commit(self) -&gt; None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
&gt;       trans.commit(_to_root=True)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2032: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;, _to_root = True

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction.commit at 0x7e3b254d3ce0&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;, arg = (), kw = {'_to_root': True}
current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;, next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.CLOSED: 5&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;, _to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -&gt; None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
&gt;               self._prepare_impl()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._prepare_impl at 0x7e3b254d3b00&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;, arg = (), kw = {}
current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;, next_state = &lt;SessionTransactionState.PREPARED: 2&gt;, existing_fn = &lt;function SessionTransaction.commit at 0x7e3b254d3ce0&gt;
expect_state = &lt;SessionTransactionState.PREPARED: 2&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b20da0cd0&gt;

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -&gt; None:
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
&gt;               self.session.flush()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1288: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -&gt; None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
&gt;           self._flush(objects)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -&gt; None:
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
&gt;           with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4480: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b20634490&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -&gt; None:
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
&gt;               flush_context.execute()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4441: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b21cef710&gt;

    def execute(self) -&gt; None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
&gt;               rec.execute(self)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = SaveUpdateAll(Mapper[Role(roles)]), uow = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b21cef710&gt;

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
&gt;       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:642: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

base_mapper = &lt;Mapper at 0x7e3b24342650; Role&gt;, states = &lt;generator object UOWTransaction.states_for_mapper_hierarchy at 0x7e3b21f3c940&gt;
uowtransaction = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b21cef710&gt;, single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
&gt;           _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

base_mapper = &lt;Mapper at 0x7e3b24342650; Role&gt;, uowtransaction = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b21cef710&gt;, mapper = &lt;Mapper at 0x7e3b24342650; Role&gt;
table = Table('roles', MetaData(), Column('name', String(length=50), table=&lt;roles&gt;, nullable=False, comment="Unique role name ...), server_default=DefaultClause(&lt;sqlalchemy.sql.functions.now at 0x7e3b2343c2d0; now&gt;, for_update=False)), schema=None)
update = &lt;generator object _collect_update_commands at 0x7e3b21d165c0&gt;

    def _emit_update_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        update,
        *,
        bookkeeping=True,
        use_orm_update_stmt=None,
        enable_check_rowcount=True,
    ):
        """Emit UPDATE statements corresponding to value lists collected
        by _collect_update_commands()."""
    
        needs_version_id = (
            mapper.version_id_col is not None
            and mapper.version_id_col in mapper._cols_by_table[table]
        )
    
        execution_options = {"compiled_cache": base_mapper._compiled_cache}
    
        def update_stmt(existing_stmt=None):
            clauses = BooleanClauseList._construct_raw(operators.and_)
    
            for col in mapper._pks_by_table[table]:
                clauses._append_inplace(
                    col == sql.bindparam(col._label, type_=col.type)
                )
    
            if needs_version_id:
                clauses._append_inplace(
                    mapper.version_id_col
                    == sql.bindparam(
                        mapper.version_id_col._label,
                        type_=mapper.version_id_col.type,
                    )
                )
    
            if existing_stmt is not None:
                stmt = existing_stmt.where(clauses)
            else:
                stmt = table.update().where(clauses)
            return stmt
    
        if use_orm_update_stmt is not None:
            cached_stmt = update_stmt(use_orm_update_stmt)
    
        else:
            cached_stmt = base_mapper._memo(("update", table), update_stmt)
    
        for (
            (connection, paramkeys, hasvalue, has_all_defaults, has_all_pks),
            records,
        ) in groupby(
            update,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # set of parameter keys
                bool(rec[5]),  # whether or not we have "value" parameters
                rec[6],  # has_all_defaults
                rec[7],  # has all pks
            ),
        ):
            rows = 0
            records = list(records)
    
            statement = cached_stmt
    
            if use_orm_update_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_update_table": table,
                        "_emit_update_mapper": mapper,
                    }
                )
    
            return_defaults = False
    
            if not has_all_pks:
                statement = statement.return_defaults(*mapper._pks_by_table[table])
                return_defaults = True
    
            if (
                bookkeeping
                and not has_all_defaults
                and mapper.base_mapper.eager_defaults is True
                # change as of #8889 - if RETURNING is not going to be used anyway,
                # (applies to MySQL, MariaDB which lack UPDATE RETURNING) ensure
                # we can do an executemany UPDATE which is more efficient
                and table.implicit_returning
                and connection.dialect.update_returning
            ):
                statement = statement.return_defaults(
                    *mapper._server_onupdate_default_cols[table]
                )
                return_defaults = True
    
            if mapper._version_id_has_server_side_value:
                statement = statement.return_defaults(mapper.version_id_col)
                return_defaults = True
    
            assert_singlerow = connection.dialect.supports_sane_rowcount
    
            assert_multirow = (
                assert_singlerow
                and connection.dialect.supports_sane_multi_rowcount
            )
    
            # change as of #8889 - if RETURNING is not going to be used anyway,
            # (applies to MySQL, MariaDB which lack UPDATE RETURNING) ensure
            # we can do an executemany UPDATE which is more efficient
            allow_executemany = not return_defaults and not needs_version_id
    
            if hasvalue:
                for (
                    state,
                    state_dict,
                    params,
                    mapper,
                    connection,
                    value_params,
                    has_all_defaults,
                    has_all_pks,
                ) in records:
                    c = connection.execute(
                        statement.values(value_params),
                        params,
                        execution_options=execution_options,
                    )
                    if bookkeeping:
                        _postfetch(
                            mapper,
                            uowtransaction,
                            table,
                            state,
                            state_dict,
                            c,
                            c.context.compiled_parameters[0],
                            value_params,
                            True,
                            c.returned_defaults,
                        )
                    rows += c.rowcount
                    check_rowcount = enable_check_rowcount and assert_singlerow
            else:
                if not allow_executemany:
                    check_rowcount = enable_check_rowcount and assert_singlerow
                    for (
                        state,
                        state_dict,
                        params,
                        mapper,
                        connection,
                        value_params,
                        has_all_defaults,
                        has_all_pks,
                    ) in records:
                        c = connection.execute(
                            statement, params, execution_options=execution_options
                        )
    
                        # TODO: why with bookkeeping=False?
                        if bookkeeping:
                            _postfetch(
                                mapper,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                c,
                                c.context.compiled_parameters[0],
                                value_params,
                                True,
                                c.returned_defaults,
                            )
                        rows += c.rowcount
                else:
                    multiparams = [rec[2] for rec in records]
    
                    check_rowcount = enable_check_rowcount and (
                        assert_multirow
                        or (assert_singlerow and len(multiparams) == 1)
                    )
    
&gt;                   c = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:912: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, statement = &lt;sqlalchemy.sql.dml.Update object at 0x7e3b22803950&gt;
parameters = [{'name': 'deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', 'roles_id': UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646')}]

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -&gt; CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
&gt;           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1415: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.sql.dml.Update object at 0x7e3b22803950&gt;, connection = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;
distilled_params = [{'name': 'deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', 'roles_id': UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646')}]
execution_options = {'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22be7290&gt;}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
&gt;           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:523: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, elem = &lt;sqlalchemy.sql.dml.Update object at 0x7e3b22803950&gt;
distilled_parameters = [{'name': 'deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', 'roles_id': UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646')}]
execution_options = immutabledict({'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22be7290&gt;})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) &gt; 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
&gt;       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
constructor = &lt;bound method DefaultExecutionContext._init_compiled of &lt;class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'&gt;&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b20c16d10&gt;
parameters = [{'name': 'deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', 'roles_id': UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646')}]
execution_options = immutabledict({'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22be7290&gt;})
args = (&lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b20c16d10&gt;, [{'name': 'deleted_deletable_ro...2479d09d646')}], &lt;sqlalchemy.sql.dml.Update object at 0x7e3b22803950&gt;, [BindParameter('roles_id', None, type_=UUID())])
kw = {'cache_hit': &lt;CacheStats.CACHE_MISS: 1&gt;}, yp = None, conn = &lt;sqlalchemy.pool.base._ConnectionFairy object at 0x7e3b20d1c1d0&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -&gt; CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
&gt;           return self._exec_single_context(
                dialect, context, statement, parameters
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1842: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b20c16d10&gt;
parameters = [('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
&gt;           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;
e = Error("&lt;class 'asyncpg.exceptions.StringDataRightTruncationError'&gt;: value too long for type character varying(50)")
statement = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;, is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -&gt; NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-&gt; test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
&gt;               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b20c16d90&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b20c16d10&gt;
parameters = [('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
statement = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b20c161d0&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
operation = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21da9000&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
&gt;       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b22b5ced0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b21ceff40 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b20a45220&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
&gt;               value = await result

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
operation = 'UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID'
parameters = ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
&gt;               self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:558: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20d98820&gt;
error = StringDataRightTruncationError('value too long for type character varying(50)')

    def _handle_exception(self, error):
&gt;       self._adapt_connection._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;, error = StringDataRightTruncationError('value too long for type character varying(50)')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
&gt;                   raise translated_error from error
E                   sqlalchemy.exc.DBAPIError: (sqlalchemy.dialects.postgresql.asyncpg.Error) &lt;class 'asyncpg.exceptions.StringDataRightTruncationError'&gt;: value too long for type character varying(50)
E                   [SQL: UPDATE roles SET name=$1::VARCHAR, updated_at=now() WHERE roles.id = $2::UUID]
E                   [parameters: ('deleted_deletable_role_8f73e8af-dcdf-4bc5-86ff-d2479d09d646', UUID('8f73e8af-dcdf-4bc5-86ff-d2479d09d646'))]
E                   (Background on this error at: https://sqlalche.me/e/20/dbapi)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:792: DBAPIError</failure></testcase><testcase classname="tests.test_app.test_models.test_role.TestRoleModel" name="test_role_complex_queries" time="0.011"><failure message="sqlalchemy.exc.IntegrityError: (sqlalchemy.dialects.postgresql.asyncpg.IntegrityError) &lt;class 'asyncpg.exceptions.UniqueViolationError'&gt;: duplicate key value violates unique constraint &quot;ix_scopes_name&quot;&#10;DETAIL:  Key (name)=(read:content) already exists.&#10;[SQL: INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::VARCHAR, $6::VARCHAR, $7::VARCHAR, $8::UUID), ($9::VARCHAR, $10::VARCHAR, $11::VARCHAR, $12::UUID), ($13::VARCHAR, $14::VARCHAR, $15::VARCHAR, $16::UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id]&#10;[parameters: ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', 'system', UUID('27b1d287-3f54-413e-b2c3-cad36de73081'), 'write:content', 'Write content', 'content', UUID('28000023-9faa-4ca5-98b1-eca1aa826509'), 'read:content', 'Read content', 'content', UUID('24941490-c1a4-40e7-b9f3-de624d539b78'), 'read:content', 'Read content', 'content', UUID('d652c55b-47f1-41ea-bf4d-6d81377e88a3'))]&#10;(Background on this error at: https://sqlalche.me/e/20/gkpj)">self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
operation = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
&gt;                   self._rows = deque(await prepared_stmt.fetch(*parameters))

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b21126660&gt;, timeout = None
args = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    @connresource.guarded
    async def fetch(self, *args, timeout=None):
        r"""Execute the statement and return a list of :class:`Record` objects.
    
        :param str query: Query text
        :param args: Query arguments
        :param float timeout: Optional timeout value in seconds.
    
        :return: A list of :class:`Record` instances.
        """
&gt;       data = await self.__bind_execute(args, 0, timeout)

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b21126660&gt;
args = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...), limit = 0, timeout = None

    async def __bind_execute(self, args, limit, timeout):
&gt;       data, status, _ = await self.__do_execute(
            lambda protocol: protocol.bind_execute(
                self._state, args, '', limit, True, timeout))

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;asyncpg.prepared_stmt.PreparedStatement object at 0x7e3b21126660&gt;, executor = &lt;function PreparedStatement.__bind_execute.&lt;locals&gt;.&lt;lambda&gt; at 0x7e3b20cf5940&gt;

    async def __do_execute(self, executor):
        protocol = self._connection._protocol
        try:
&gt;           return await executor(protocol)

.venv/lib/python3.11/site-packages/asyncpg/prepared_stmt.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

&gt;   ???
E   asyncpg.exceptions.UniqueViolationError: duplicate key value violates unique constraint "ix_scopes_name"
E   DETAIL:  Key (name)=(read:content) already exists.

asyncpg/protocol/protocol.pyx:207: UniqueViolationError

The above exception was the direct cause of the following exception:

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def _exec_insertmany_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for an "insertmanyvalues"
        operation, which will invoke DBAPI
        cursor.execute() one or more times with individual log and
        event hook calls.
    
        """
    
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
        else:
            generic_setinputsizes = None
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters = parameters
    
        engine_events = self._has_events or self.engine._has_events
        if self.dialect._has_events:
            do_execute_dispatch: Iterable[Any] = (
                self.dialect.dispatch.do_execute
            )
        else:
            do_execute_dispatch = ()
    
        if self._echo:
            stats = context._get_cache_stats() + " (insertmanyvalues)"
    
        preserve_rowcount = context.execution_options.get(
            "preserve_rowcount", False
        )
        rowcount = 0
    
        for imv_batch in dialect._deliver_insertmanyvalues_batches(
            self,
            cursor,
            str_statement,
            effective_parameters,
            generic_setinputsizes,
            context,
        ):
            if imv_batch.processed_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor,
                        imv_batch.processed_setinputsizes,
                        context,
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e,
                        sql_util._long_statement(imv_batch.replaced_statement),
                        imv_batch.replaced_parameters,
                        None,
                        context,
                        is_sub_exec=True,
                    )
    
            sub_stmt = imv_batch.replaced_statement
            sub_params = imv_batch.replaced_parameters
    
            if engine_events:
                for fn in self.dispatch.before_cursor_execute:
                    sub_stmt, sub_params = fn(
                        self,
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                        True,
                    )
    
            if self._echo:
                self._log_info(sql_util._long_statement(sub_stmt))
    
                imv_stats = f""" {imv_batch.batchnum}/{
                            imv_batch.total_batches
                } ({
                    'ordered'
                    if imv_batch.rows_sorted else 'unordered'
                }{
                    '; batch not supported'
                    if imv_batch.is_downgraded
                    else ''
                })"""
    
                if imv_batch.batchnum == 1:
                    stats += imv_stats
                else:
                    stats = f"insertmanyvalues{imv_stats}"
    
                if not self.engine.hide_parameters:
                    self._log_info(
                        "[%s] %r",
                        stats,
                        sql_util._repr_params(
                            sub_params,
                            batches=10,
                            ismulti=False,
                        ),
                    )
                else:
                    self._log_info(
                        "[%s] [SQL parameters hidden due to "
                        "hide_parameters=True]",
                        stats,
                    )
    
            try:
                for fn in do_execute_dispatch:
                    if fn(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    ):
                        break
                else:
&gt;                   dialect.do_execute(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
statement = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
operation = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21f0b760&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
&gt;       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b1bec5a00 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b2058a8e0&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
&gt;               value = await result

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
operation = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
&gt;               self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:558: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
error = UniqueViolationError('duplicate key value violates unique constraint "ix_scopes_name"')

    def _handle_exception(self, error):
&gt;       self._adapt_connection._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;
error = UniqueViolationError('duplicate key value violates unique constraint "ix_scopes_name"')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
&gt;                   raise translated_error from error
E                   sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi.IntegrityError: &lt;class 'asyncpg.exceptions.UniqueViolationError'&gt;: duplicate key value violates unique constraint "ix_scopes_name"
E                   DETAIL:  Key (name)=(read:content) already exists.

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:792: IntegrityError

The above exception was the direct cause of the following exception:

self = &lt;tests.test_app.test_models.test_role.TestRoleModel object at 0x7e3b229ea550&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1bec6910&gt;

    @pytest.mark.unit
    async def test_role_complex_queries(self, db_session: AsyncSession):
        """Test complex role queries."""
        # Create roles with different scope patterns
        admin_role = Role(name="admin", description="Admin role")
        editor_role = Role(name="editor", description="Editor role")
        viewer_role = Role(name="viewer", description="Viewer role")
    
        # Create scopes
        admin_scopes = [
            Scope(name="admin:users", description="Manage users", resource="users"),
            Scope(name="admin:system", description="System admin", resource="system")
        ]
        editor_scopes = [
            Scope(name="write:content", description="Write content", resource="content"),
            Scope(name="read:content", description="Read content", resource="content")
        ]
        viewer_scopes = [
            Scope(name="read:content", description="Read content", resource="content")
        ]
    
        db_session.add_all([admin_role, editor_role, viewer_role] + admin_scopes + editor_scopes + viewer_scopes)
&gt;       await db_session.commit()

tests/test_app/test_models/test_role.py:492: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1bec6910&gt;

    async def commit(self) -&gt; None:
        """Commit the current transaction in progress.
    
        .. seealso::
    
            :meth:`_orm.Session.commit` - main documentation for
            "commit"
        """
&gt;       await greenlet_spawn(self.sync_session.commit)

.venv/lib/python3.11/site-packages/sqlalchemy/ext/asyncio/session.py:1014: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b1bec5a00 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b2058a8e0&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
                result = context.throw(*sys.exc_info())
            else:
&gt;               result = context.switch(value)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;

    def commit(self) -&gt; None:
        """Flush pending changes and commit the current transaction.
    
        When the COMMIT operation is complete, all objects are fully
        :term:`expired`, erasing their internal contents, which will be
        automatically re-loaded when the objects are next accessed. In the
        interim, these objects are in an expired state and will not function if
        they are :term:`detached` from the :class:`.Session`. Additionally,
        this re-load operation is not supported when using asyncio-oriented
        APIs. The :paramref:`.Session.expire_on_commit` parameter may be used
        to disable this behavior.
    
        When there is no transaction in place for the :class:`.Session`,
        indicating that no operations were invoked on this :class:`.Session`
        since the previous call to :meth:`.Session.commit`, the method will
        begin and commit an internal-only "logical" transaction, that does not
        normally affect the database unless pending flush changes were
        detected, but will still invoke event handlers and object expiration
        rules.
    
        The outermost database transaction is committed unconditionally,
        automatically releasing any SAVEPOINTs in effect.
    
        .. seealso::
    
            :ref:`session_committing`
    
            :ref:`unitofwork_transaction`
    
            :ref:`asyncio_orm_avoid_lazyloads`
    
        """
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
    
&gt;       trans.commit(_to_root=True)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2032: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;, _to_root = True

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction.commit at 0x7e3b254d3ce0&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;, arg = (), kw = {'_to_root': True}
current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;, next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.CLOSED: 5&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;, _to_root = True

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE, SessionTransactionState.PREPARED),
        SessionTransactionState.CLOSED,
    )
    def commit(self, _to_root: bool = False) -&gt; None:
        if self._state is not SessionTransactionState.PREPARED:
            with self._expect_state(SessionTransactionState.PREPARED):
&gt;               self._prepare_impl()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1313: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._prepare_impl at 0x7e3b254d3b00&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;, arg = (), kw = {}
current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;, next_state = &lt;SessionTransactionState.PREPARED: 2&gt;, existing_fn = &lt;function SessionTransaction.commit at 0x7e3b254d3ce0&gt;
expect_state = &lt;SessionTransactionState.PREPARED: 2&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b87c3c0&gt;

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), SessionTransactionState.PREPARED
    )
    def _prepare_impl(self) -&gt; None:
        if self._parent is None or self.nested:
            self.session.dispatch.before_commit(self.session)
    
        stx = self.session._transaction
        assert stx is not None
        if stx is not self:
            for subtransaction in stx._iterate_self_and_parents(upto=self):
                subtransaction.commit()
    
        if not self.session._flushing:
            for _flush_guard in range(100):
                if self.session._is_clean():
                    break
&gt;               self.session.flush()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1288: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -&gt; None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
            raise sa_exc.InvalidRequestError("Session is already flushing")
    
        if self._is_clean():
            return
        try:
            self._flushing = True
&gt;           self._flush(objects)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4345: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -&gt; None:
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
                flush_context.execute()
            finally:
                self._warn_on_events = False
    
            self.dispatch.after_flush(self, flush_context)
    
            flush_context.finalize_flush_changes()
    
            if not objects and self.identity_map._modified:
                len_ = len(self.identity_map._modified)
    
                statelib.InstanceState._commit_all_states(
                    [
                        (state, state.dict)
                        for state in self.identity_map._modified
                    ],
                    instance_dict=self.identity_map,
                )
                util.warn(
                    "Attribute history events accumulated on %d "
                    "previously clean instances "
                    "within inner-flush event handlers have been "
                    "reset, and will not result in database updates. "
                    "Consider using set_committed_value() within "
                    "inner-flush event handlers to avoid this warning." % len_
                )
    
            # useful assertions:
            # if not objects:
            #    assert not self.identity_map._modified
            # else:
            #    assert self.identity_map._modified == \
            #            self.identity_map._modified.difference(objects)
    
            self.dispatch.after_flush_postexec(self, flush_context)
    
            transaction.commit()
    
        except:
&gt;           with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4480: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b210e4040&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;, objects = None

    def _flush(self, objects: Optional[Sequence[object]] = None) -&gt; None:
        dirty = self._dirty_states
        if not dirty and not self._deleted and not self._new:
            self.identity_map._modified.clear()
            return
    
        flush_context = UOWTransaction(self)
    
        if self.dispatch.before_flush:
            self.dispatch.before_flush(self, flush_context, objects)
            # re-establish "dirty states" in case the listeners
            # added
            dirty = self._dirty_states
    
        deleted = set(self._deleted)
        new = set(self._new)
    
        dirty = set(dirty).difference(deleted)
    
        # create the set of all objects we want to operate upon
        if objects:
            # specific list passed in
            objset = set()
            for o in objects:
                try:
                    state = attributes.instance_state(o)
    
                except exc.NO_STATE as err:
                    raise exc.UnmappedInstanceError(o) from err
                objset.add(state)
        else:
            objset = None
    
        # store objects whose fate has been decided
        processed = set()
    
        # put all saves/updates into the flush context.  detect top-level
        # orphans and throw them into deleted.
        if objset:
            proc = new.union(dirty).intersection(objset).difference(deleted)
        else:
            proc = new.union(dirty).difference(deleted)
    
        for state in proc:
            is_orphan = _state_mapper(state)._is_orphan(state)
    
            is_persistent_orphan = is_orphan and state.has_identity
    
            if (
                is_orphan
                and not is_persistent_orphan
                and state._orphaned_outside_of_session
            ):
                self._expunge_states([state])
            else:
                _reg = flush_context.register_object(
                    state, isdelete=is_persistent_orphan
                )
                assert _reg, "Failed to add object to the flush context!"
                processed.add(state)
    
        # put all remaining deletes into the flush context.
        if objset:
            proc = deleted.intersection(objset).difference(processed)
        else:
            proc = deleted.difference(processed)
        for state in proc:
            _reg = flush_context.register_object(state, isdelete=True)
            assert _reg, "Failed to add object to the flush context!"
    
        if not flush_context.has_work:
            return
    
        flush_context.transaction = transaction = self._autobegin_t()._begin()
        try:
            self._warn_on_events = True
            try:
&gt;               flush_context.execute()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:4441: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b1bec7f90&gt;

    def execute(self) -&gt; None:
        postsort_actions = self._generate_actions()
    
        postsort_actions = sorted(
            postsort_actions,
            key=lambda item: item.sort_key,
        )
        # sort = topological.sort(self.dependencies, postsort_actions)
        # print "--------------"
        # print "\ndependencies:", self.dependencies
        # print "\ncycles:", self.cycles
        # print "\nsort:", list(sort)
        # print "\nCOUNT OF POSTSORT ACTIONS", len(postsort_actions)
    
        # execute
        if self.cycles:
            for subset in topological.sort_as_subsets(
                self.dependencies, postsort_actions
            ):
                set_ = set(subset)
                while set_:
                    n = set_.pop()
                    n.execute_aggregate(self, set_)
        else:
            for rec in topological.sort(self.dependencies, postsort_actions):
&gt;               rec.execute(self)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:466: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = SaveUpdateAll(Mapper[Scope(scopes)]), uow = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b1bec7f90&gt;

    @util.preload_module("sqlalchemy.orm.persistence")
    def execute(self, uow):
&gt;       util.preloaded.orm_persistence.save_obj(
            self.mapper,
            uow.states_for_mapper_hierarchy(self.mapper, False, False),
            uow,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:642: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

base_mapper = &lt;Mapper at 0x7e3b234ccb10; Scope&gt;, states = &lt;generator object UOWTransaction.states_for_mapper_hierarchy at 0x7e3b21f3f640&gt;
uowtransaction = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b1bec7f90&gt;, single = False

    def save_obj(base_mapper, states, uowtransaction, single=False):
        """Issue ``INSERT`` and/or ``UPDATE`` statements for a list
        of objects.
    
        This is called within the context of a UOWTransaction during a
        flush operation, given a list of states to be flushed.  The
        base mapper in an inheritance hierarchy handles the inserts/
        updates for all descendant mappers.
    
        """
    
        # if batch=false, call _save_obj separately for each object
        if not single and not base_mapper.batch:
            for state in _sort_states(base_mapper, states):
                save_obj(base_mapper, [state], uowtransaction, single=True)
            return
    
        states_to_update = []
        states_to_insert = []
    
        for (
            state,
            dict_,
            mapper,
            connection,
            has_identity,
            row_switch,
            update_version_id,
        ) in _organize_states_for_save(base_mapper, states, uowtransaction):
            if has_identity or row_switch:
                states_to_update.append(
                    (state, dict_, mapper, connection, update_version_id)
                )
            else:
                states_to_insert.append((state, dict_, mapper, connection))
    
        for table, mapper in base_mapper._sorted_tables.items():
            if table not in mapper._pks_by_table:
                continue
            insert = _collect_insert_commands(table, states_to_insert)
    
            update = _collect_update_commands(
                uowtransaction, table, states_to_update
            )
    
            _emit_update_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                update,
            )
    
&gt;           _emit_insert_statements(
                base_mapper,
                uowtransaction,
                mapper,
                table,
                insert,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:93: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

base_mapper = &lt;Mapper at 0x7e3b234ccb10; Scope&gt;, uowtransaction = &lt;sqlalchemy.orm.unitofwork.UOWTransaction object at 0x7e3b1bec7f90&gt;, mapper = &lt;Mapper at 0x7e3b234ccb10; Scope&gt;
table = Table('scopes', MetaData(), Column('name', String(length=100), table=&lt;scopes&gt;, nullable=False, comment="Unique scope n...), server_default=DefaultClause(&lt;sqlalchemy.sql.functions.now at 0x7e3b2343c2d0; now&gt;, for_update=False)), schema=None)
insert = &lt;generator object _collect_insert_commands at 0x7e3b213897b0&gt;

    def _emit_insert_statements(
        base_mapper,
        uowtransaction,
        mapper,
        table,
        insert,
        *,
        bookkeeping=True,
        use_orm_insert_stmt=None,
        execution_options=None,
    ):
        """Emit INSERT statements corresponding to value lists collected
        by _collect_insert_commands()."""
    
        if use_orm_insert_stmt is not None:
            cached_stmt = use_orm_insert_stmt
            exec_opt = util.EMPTY_DICT
    
            # if a user query with RETURNING was passed, we definitely need
            # to use RETURNING.
            returning_is_required_anyway = bool(use_orm_insert_stmt._returning)
            deterministic_results_reqd = (
                returning_is_required_anyway
                and use_orm_insert_stmt._sort_by_parameter_order
            ) or bookkeeping
        else:
            returning_is_required_anyway = False
            deterministic_results_reqd = bookkeeping
            cached_stmt = base_mapper._memo(("insert", table), table.insert)
            exec_opt = {"compiled_cache": base_mapper._compiled_cache}
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                exec_opt, execution_options
            )
        else:
            execution_options = exec_opt
    
        return_result = None
    
        for (
            (connection, _, hasvalue, has_all_pks, has_all_defaults),
            records,
        ) in groupby(
            insert,
            lambda rec: (
                rec[4],  # connection
                set(rec[2]),  # parameter keys
                bool(rec[5]),  # whether we have "value" parameters
                rec[6],
                rec[7],
            ),
        ):
            statement = cached_stmt
    
            if use_orm_insert_stmt is not None:
                statement = statement._annotate(
                    {
                        "_emit_insert_table": table,
                        "_emit_insert_mapper": mapper,
                    }
                )
    
            if (
                (
                    not bookkeeping
                    or (
                        has_all_defaults
                        or not base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                        or not table.implicit_returning
                        or not connection.dialect.insert_returning
                    )
                )
                and not returning_is_required_anyway
                and has_all_pks
                and not hasvalue
            ):
                # the "we don't need newly generated values back" section.
                # here we have all the PKs, all the defaults or we don't want
                # to fetch them, or the dialect doesn't support RETURNING at all
                # so we have to post-fetch / use lastrowid anyway.
                records = list(records)
                multiparams = [rec[2] for rec in records]
    
                result = connection.execute(
                    statement, multiparams, execution_options=execution_options
                )
                if bookkeeping:
                    for (
                        (
                            state,
                            state_dict,
                            params,
                            mapper_rec,
                            conn,
                            value_params,
                            has_all_pks,
                            has_all_defaults,
                        ),
                        last_inserted_params,
                    ) in zip(records, result.context.compiled_parameters):
                        if state:
                            _postfetch(
                                mapper_rec,
                                uowtransaction,
                                table,
                                state,
                                state_dict,
                                result,
                                last_inserted_params,
                                value_params,
                                False,
                                (
                                    result.returned_defaults
                                    if not result.context.executemany
                                    else None
                                ),
                            )
                        else:
                            _postfetch_bulk_save(mapper_rec, state_dict, table)
    
            else:
                # here, we need defaults and/or pk values back or we otherwise
                # know that we are using RETURNING in any case
    
                records = list(records)
    
                if returning_is_required_anyway or (
                    table.implicit_returning and not hasvalue and len(records) &gt; 1
                ):
                    if (
                        deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning_sort_by_parameter_order  # noqa: E501
                    ) or (
                        not deterministic_results_reqd
                        and connection.dialect.insert_executemany_returning
                    ):
                        do_executemany = True
                    elif returning_is_required_anyway:
                        if deterministic_results_reqd:
                            dt = " with RETURNING and sort by parameter order"
                        else:
                            dt = " with RETURNING"
                        raise sa_exc.InvalidRequestError(
                            f"Can't use explicit RETURNING for bulk INSERT "
                            f"operation with "
                            f"{connection.dialect.dialect_description} backend; "
                            f"executemany{dt} is not enabled for this dialect."
                        )
                    else:
                        do_executemany = False
                else:
                    do_executemany = False
    
                if use_orm_insert_stmt is None:
                    if (
                        not has_all_defaults
                        and base_mapper._prefer_eager_defaults(
                            connection.dialect, table
                        )
                    ):
                        statement = statement.return_defaults(
                            *mapper._server_default_cols[table],
                            sort_by_parameter_order=bookkeeping,
                        )
    
                if mapper.version_id_col is not None:
                    statement = statement.return_defaults(
                        mapper.version_id_col,
                        sort_by_parameter_order=bookkeeping,
                    )
                elif do_executemany:
                    statement = statement.return_defaults(
                        *table.primary_key, sort_by_parameter_order=bookkeeping
                    )
    
                if do_executemany:
                    multiparams = [rec[2] for rec in records]
    
&gt;                   result = connection.execute(
                        statement, multiparams, execution_options=execution_options
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:1143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, statement = &lt;sqlalchemy.sql.dml.Insert object at 0x7e3b1ba68a50&gt;
parameters = [{'description': 'Manage users', 'name': 'admin:users', 'resource': 'users'}, {'description': 'System admin', 'name': ...'read:content', 'resource': 'content'}, {'description': 'Read content', 'name': 'read:content', 'resource': 'content'}]

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -&gt; CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
&gt;           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1415: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.sql.dml.Insert object at 0x7e3b1ba68a50&gt;, connection = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;
distilled_params = [{'description': 'Manage users', 'name': 'admin:users', 'resource': 'users'}, {'description': 'System admin', 'name': ...'read:content', 'resource': 'content'}, {'description': 'Read content', 'name': 'read:content', 'resource': 'content'}]
execution_options = {'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22c281d0&gt;}

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
&gt;           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:523: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, elem = &lt;sqlalchemy.sql.dml.Insert object at 0x7e3b1ba68a50&gt;
distilled_parameters = [{'description': 'Manage users', 'name': 'admin:users', 'resource': 'users'}, {'description': 'System admin', 'name': ...'read:content', 'resource': 'content'}, {'description': 'Read content', 'name': 'read:content', 'resource': 'content'}]
execution_options = immutabledict({'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22c281d0&gt;})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) &gt; 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
&gt;       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
constructor = &lt;bound method DefaultExecutionContext._init_compiled of &lt;class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'&gt;&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22af5050&gt;
parameters = [{'description': 'Manage users', 'name': 'admin:users', 'resource': 'users'}, {'description': 'System admin', 'name': ...'read:content', 'resource': 'content'}, {'description': 'Read content', 'name': 'read:content', 'resource': 'content'}]
execution_options = immutabledict({'compiled_cache': &lt;sqlalchemy.util._collections.LRUCache object at 0x7e3b22c281d0&gt;})
args = (&lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22af5050&gt;, [{'description': 'Manage users'...ad content', 'name': 'read:content', 'resource': 'content'}], &lt;sqlalchemy.sql.dml.Insert object at 0x7e3b1ba68a50&gt;, [])
kw = {'cache_hit': &lt;CacheStats.CACHE_HIT: 0&gt;}, yp = None, conn = &lt;sqlalchemy.pool.base._ConnectionFairy object at 0x7e3b2113fef0&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -&gt; CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
&gt;           return self._exec_insertmany_context(dialect, context)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def _exec_insertmany_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for an "insertmanyvalues"
        operation, which will invoke DBAPI
        cursor.execute() one or more times with individual log and
        event hook calls.
    
        """
    
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
        else:
            generic_setinputsizes = None
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters = parameters
    
        engine_events = self._has_events or self.engine._has_events
        if self.dialect._has_events:
            do_execute_dispatch: Iterable[Any] = (
                self.dialect.dispatch.do_execute
            )
        else:
            do_execute_dispatch = ()
    
        if self._echo:
            stats = context._get_cache_stats() + " (insertmanyvalues)"
    
        preserve_rowcount = context.execution_options.get(
            "preserve_rowcount", False
        )
        rowcount = 0
    
        for imv_batch in dialect._deliver_insertmanyvalues_batches(
            self,
            cursor,
            str_statement,
            effective_parameters,
            generic_setinputsizes,
            context,
        ):
            if imv_batch.processed_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor,
                        imv_batch.processed_setinputsizes,
                        context,
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e,
                        sql_util._long_statement(imv_batch.replaced_statement),
                        imv_batch.replaced_parameters,
                        None,
                        context,
                        is_sub_exec=True,
                    )
    
            sub_stmt = imv_batch.replaced_statement
            sub_params = imv_batch.replaced_parameters
    
            if engine_events:
                for fn in self.dispatch.before_cursor_execute:
                    sub_stmt, sub_params = fn(
                        self,
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                        True,
                    )
    
            if self._echo:
                self._log_info(sql_util._long_statement(sub_stmt))
    
                imv_stats = f""" {imv_batch.batchnum}/{
                            imv_batch.total_batches
                } ({
                    'ordered'
                    if imv_batch.rows_sorted else 'unordered'
                }{
                    '; batch not supported'
                    if imv_batch.is_downgraded
                    else ''
                })"""
    
                if imv_batch.batchnum == 1:
                    stats += imv_stats
                else:
                    stats = f"insertmanyvalues{imv_stats}"
    
                if not self.engine.hide_parameters:
                    self._log_info(
                        "[%s] %r",
                        stats,
                        sql_util._repr_params(
                            sub_params,
                            batches=10,
                            ismulti=False,
                        ),
                    )
                else:
                    self._log_info(
                        "[%s] [SQL parameters hidden due to "
                        "hide_parameters=True]",
                        stats,
                    )
    
            try:
                for fn in do_execute_dispatch:
                    if fn(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    ):
                        break
                else:
                    dialect.do_execute(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    )
    
            except BaseException as e:
&gt;               self._handle_dbapi_exception(
                    e,
                    sql_util._long_statement(sub_stmt),
                    sub_params,
                    cursor,
                    context,
                    is_sub_exec=True,
                )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;
e = IntegrityError('&lt;class \'asyncpg.exceptions.UniqueViolationError\'&gt;: duplicate key value violates unique constraint "ix_scopes_name"\nDETAIL:  Key (name)=(read:content) already exists.')
statement = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;, is_sub_exec = True

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -&gt; NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-&gt; test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
&gt;               raise sqlalchemy_exception.with_traceback(exc_info[2]) from e

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2351: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1bec4a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def _exec_insertmany_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for an "insertmanyvalues"
        operation, which will invoke DBAPI
        cursor.execute() one or more times with individual log and
        event hook calls.
    
        """
    
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
        else:
            generic_setinputsizes = None
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters = parameters
    
        engine_events = self._has_events or self.engine._has_events
        if self.dialect._has_events:
            do_execute_dispatch: Iterable[Any] = (
                self.dialect.dispatch.do_execute
            )
        else:
            do_execute_dispatch = ()
    
        if self._echo:
            stats = context._get_cache_stats() + " (insertmanyvalues)"
    
        preserve_rowcount = context.execution_options.get(
            "preserve_rowcount", False
        )
        rowcount = 0
    
        for imv_batch in dialect._deliver_insertmanyvalues_batches(
            self,
            cursor,
            str_statement,
            effective_parameters,
            generic_setinputsizes,
            context,
        ):
            if imv_batch.processed_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor,
                        imv_batch.processed_setinputsizes,
                        context,
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e,
                        sql_util._long_statement(imv_batch.replaced_statement),
                        imv_batch.replaced_parameters,
                        None,
                        context,
                        is_sub_exec=True,
                    )
    
            sub_stmt = imv_batch.replaced_statement
            sub_params = imv_batch.replaced_parameters
    
            if engine_events:
                for fn in self.dispatch.before_cursor_execute:
                    sub_stmt, sub_params = fn(
                        self,
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                        True,
                    )
    
            if self._echo:
                self._log_info(sql_util._long_statement(sub_stmt))
    
                imv_stats = f""" {imv_batch.batchnum}/{
                            imv_batch.total_batches
                } ({
                    'ordered'
                    if imv_batch.rows_sorted else 'unordered'
                }{
                    '; batch not supported'
                    if imv_batch.is_downgraded
                    else ''
                })"""
    
                if imv_batch.batchnum == 1:
                    stats += imv_stats
                else:
                    stats = f"insertmanyvalues{imv_stats}"
    
                if not self.engine.hide_parameters:
                    self._log_info(
                        "[%s] %r",
                        stats,
                        sql_util._repr_params(
                            sub_params,
                            batches=10,
                            ismulti=False,
                        ),
                    )
                else:
                    self._log_info(
                        "[%s] [SQL parameters hidden due to "
                        "hide_parameters=True]",
                        stats,
                    )
    
            try:
                for fn in do_execute_dispatch:
                    if fn(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    ):
                        break
                else:
&gt;                   dialect.do_execute(
                        cursor,
                        sub_stmt,
                        sub_params,
                        context,
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
statement = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b1ba68690&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
operation = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21f0b760&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
&gt;       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;bound method Session.commit of &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec57d0&gt;&gt;, _require_await = False, args = (), kwargs = {}
context = &lt;_AsyncIoGreenlet object at 0x7e3b1bec5a00 (otid=0x7e3b27b1e310) dead&gt;, switch_occurred = True
result = &lt;coroutine object AsyncAdapt_asyncpg_connection._rollback_and_discard at 0x7e3b2058a8e0&gt;, value = None

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -&gt; _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
&gt;               value = await result

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
operation = 'INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::V...UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id'
parameters = ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', ...)

    async def _prepare_and_execute(self, operation, parameters):
        adapt_connection = self._adapt_connection
    
        async with adapt_connection._execute_mutex:
            if not adapt_connection._started:
                await adapt_connection._start_transaction()
    
            if parameters is None:
                parameters = ()
    
            try:
                prepared_stmt, attributes = await adapt_connection._prepare(
                    operation, self._invalidate_schema_cache_asof
                )
    
                if attributes:
                    self.description = [
                        (
                            attr.name,
                            attr.type.oid,
                            None,
                            None,
                            None,
                            None,
                            None,
                        )
                        for attr in attributes
                    ]
                else:
                    self.description = None
    
                if self.server_side:
                    self._cursor = await prepared_stmt.cursor(*parameters)
                    self.rowcount = -1
                else:
                    self._rows = deque(await prepared_stmt.fetch(*parameters))
                    status = prepared_stmt.get_statusmsg()
    
                    reg = re.match(
                        r"(?:SELECT|UPDATE|DELETE|INSERT \d+) (\d+)",
                        status or "",
                    )
                    if reg:
                        self.rowcount = int(reg.group(1))
                    else:
                        self.rowcount = -1
    
            except Exception as error:
&gt;               self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:558: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2105b820&gt;
error = UniqueViolationError('duplicate key value violates unique constraint "ix_scopes_name"')

    def _handle_exception(self, error):
&gt;       self._adapt_connection._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:508: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;
error = UniqueViolationError('duplicate key value violates unique constraint "ix_scopes_name"')

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
&gt;                   raise translated_error from error
E                   sqlalchemy.exc.IntegrityError: (sqlalchemy.dialects.postgresql.asyncpg.IntegrityError) &lt;class 'asyncpg.exceptions.UniqueViolationError'&gt;: duplicate key value violates unique constraint "ix_scopes_name"
E                   DETAIL:  Key (name)=(read:content) already exists.
E                   [SQL: INSERT INTO scopes (name, description, resource, id) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::UUID), ($5::VARCHAR, $6::VARCHAR, $7::VARCHAR, $8::UUID), ($9::VARCHAR, $10::VARCHAR, $11::VARCHAR, $12::UUID), ($13::VARCHAR, $14::VARCHAR, $15::VARCHAR, $16::UUID), ($17::VARCHAR, $18::VARCHAR, $19::VARCHAR, $20::UUID) RETURNING scopes.created_at, scopes.updated_at, scopes.id]
E                   [parameters: ('admin:users', 'Manage users', 'users', UUID('adac89c8-8e9e-4798-a24f-05f354b90307'), 'admin:system', 'System admin', 'system', UUID('27b1d287-3f54-413e-b2c3-cad36de73081'), 'write:content', 'Write content', 'content', UUID('28000023-9faa-4ca5-98b1-eca1aa826509'), 'read:content', 'Read content', 'content', UUID('24941490-c1a4-40e7-b9f3-de624d539b78'), 'read:content', 'Read content', 'content', UUID('d652c55b-47f1-41ea-bf4d-6d81377e88a3'))]
E                   (Background on this error at: https://sqlalche.me/e/20/gkpj)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:792: IntegrityError</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_creation" time="0.021" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_creation_minimal" time="0.015" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_unique_name_constraint" time="0.014" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_string_representation" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_string_representation_no_resource" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_role_relationship" time="0.020"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b228e7c50&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b204833d0&gt;

    @pytest.mark.unit
    async def test_scope_role_relationship(self, db_session: AsyncSession):
        """Test scope-role many-to-many relationship."""
        # Create scope and roles
        scope = Scope(
            name="manage:users",
            description="Manage users permission",
            resource="users"
        )
        role1 = Role(name="admin", description="Administrator role")
        role2 = Role(name="manager", description="Manager role")
        role3 = Role(name="user", description="Regular user role")
    
        db_session.add_all([scope, role1, role2, role3])
        await db_session.commit()
        await db_session.refresh(scope)
    
        # Add scope to roles
&gt;       role1.scopes.append(scope)

tests/test_app/test_models/test_scope.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='admin', description='Administrator role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;, 'created_at': datetime.datetime(...o=datetime.timezone.utc), 'description': 'Administrator role', 'id': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20483c10&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20483c10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;
params = {'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20483c10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;
params = {'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
        conn = self._connection_for_bind(bind)
    
        if _scalar_result and not compile_state_cls:
            if TYPE_CHECKING:
                params = cast(_CoreSingleExecuteParams, params)
            return conn.scalar(
                statement, params or {}, execution_options=execution_options
            )
    
        if compile_state_cls:
&gt;           result: Result[Any] = compile_state_cls.orm_execute_statement(
                self,
                statement,
                params or {},
                execution_options,
                bind_arguments,
                conn,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.orm.context.ORMSelectCompileState'&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20483c10&gt;
statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;, params = {'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;), '_result_disable_adapt_to_context': True})
bind_arguments = {'clause': &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;, 'mapper': &lt;Mapper at 0x7e3b234ccb10; Scope&gt;}
conn = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;

    @classmethod
    def orm_execute_statement(
        cls,
        session,
        statement,
        params,
        execution_options,
        bind_arguments,
        conn,
    ) -&gt; Result:
&gt;       result = conn.execute(
            statement, params or {}, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/context.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;
parameters = {'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -&gt; CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
&gt;           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1415: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;, connection = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;
distilled_params = [{'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;), '_result_disable_adapt_to_context': True})

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
&gt;           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:523: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;, elem = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1bd14d50&gt;
distilled_parameters = [{'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;), '_result_disable_adapt_to_context': True})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) &gt; 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
&gt;       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
constructor = &lt;bound method DefaultExecutionContext._init_compiled of &lt;class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'&gt;&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b2296ae10&gt;
parameters = [{'%(138792450297040 param)s': UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd610&gt;), '_result_disable_adapt_to_context': True})
args = (&lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b2296ae10&gt;, [{'%(138792450297040 param)s': ...selectable.Select object at 0x7e3b1bd14d50&gt;, [AnnotatedBindParameter('%(138792450297040 param)s', None, type_=UUID())])
kw = {'cache_hit': &lt;CacheStats.CACHE_HIT: 0&gt;}, yp = None, conn = &lt;sqlalchemy.pool.base._ConnectionFairy object at 0x7e3b2107d6d0&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21f398d0&gt;

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -&gt; CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
&gt;           return self._exec_single_context(
                dialect, context, statement, parameters
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1842: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21f398d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b2296ae10&gt;, parameters = [(UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
&gt;           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;
e = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
statement = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...opes_updated_at \nFROM scopes, role_scopes \nWHERE $1::UUID = role_scopes.role_id AND scopes.id = role_scopes.scope_id'
parameters = (UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'),), cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2119dde0&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21f398d0&gt;, is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -&gt; NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-&gt; test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
                raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
            else:
                assert exc_info[1] is not None
&gt;               raise exc_info[1].with_traceback(exc_info[2])

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baee050&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21f398d0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b2296ae10&gt;, parameters = [(UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2119dde0&gt;
statement = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...opes_updated_at \nFROM scopes, role_scopes \nWHERE $1::UUID = role_scopes.role_id AND scopes.id = role_scopes.scope_id'
parameters = (UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'),), context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21f398d0&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b2119dde0&gt;
operation = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...opes_updated_at \nFROM scopes, role_scopes \nWHERE $1::UUID = role_scopes.role_id AND scopes.id = role_scopes.scope_id'
parameters = (UUID('959c7bad-cb7d-4e8d-aa1d-a44b3f60c6c9'),)

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21dab640&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_service_client_relationship" time="0.245"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b228f0890&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1bec5950&gt;

    @pytest.mark.unit
    async def test_scope_service_client_relationship(self, db_session: AsyncSession):
        """Test scope-service client many-to-many relationship."""
        # Create scope and service clients
        scope = Scope(
            name="api:access",
            description="API access permission",
            resource="api"
        )
        client1 = ServiceClient(
            client_id="web-app",
            client_secret_hash=hash_password("web-secret"),
            name="Web Application"
        )
        client2 = ServiceClient(
            client_id="mobile-app",
            client_secret_hash=hash_password("mobile-secret"),
            name="Mobile Application"
        )
    
        db_session.add_all([scope, client1, client2])
        await db_session.commit()
        await db_session.refresh(scope)
    
        # Add scope to clients
&gt;       client1.scopes.append(scope)

tests/test_app/test_models/test_scope.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c7ec0&gt;
instance = &lt;ServiceClient(id=8a025f56-a06c-4752-bc22-f7804704aabd, client_id='web-app', name='Web Application')&gt;, owner = &lt;class 'app.models.service_client.ServiceClient'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e8d0&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;, 'access_token_lifetime': 3600, '...secret_hash': '$argon2id$v=19$m=65536,t=3,p=1$SQmBcC5lLCWktNaaE6L0vg$S6WwuWPff5VVy1xrYFZ5wJpzB1YnQw8PfLoEtsG5ONY', ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e8d0&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b23308740&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b23308740&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec7150&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec7150&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;
params = {'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec7150&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;
params = {'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
        conn = self._connection_for_bind(bind)
    
        if _scalar_result and not compile_state_cls:
            if TYPE_CHECKING:
                params = cast(_CoreSingleExecuteParams, params)
            return conn.scalar(
                statement, params or {}, execution_options=execution_options
            )
    
        if compile_state_cls:
&gt;           result: Result[Any] = compile_state_cls.orm_execute_statement(
                self,
                statement,
                params or {},
                execution_options,
                bind_arguments,
                conn,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.orm.context.ORMSelectCompileState'&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1bec7150&gt;
statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;, params = {'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;), '_result_disable_adapt_to_context': True})
bind_arguments = {'clause': &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;, 'mapper': &lt;Mapper at 0x7e3b234ccb10; Scope&gt;}
conn = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;

    @classmethod
    def orm_execute_statement(
        cls,
        session,
        statement,
        params,
        execution_options,
        bind_arguments,
        conn,
    ) -&gt; Result:
&gt;       result = conn.execute(
            statement, params or {}, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/context.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;
parameters = {'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -&gt; CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
&gt;           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1415: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;, connection = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;
distilled_params = [{'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;), '_result_disable_adapt_to_context': True})

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
&gt;           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:523: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;, elem = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b21f9e550&gt;
distilled_parameters = [{'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;), '_result_disable_adapt_to_context': True})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -&gt; CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) &gt; 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
&gt;       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1637: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
constructor = &lt;bound method DefaultExecutionContext._init_compiled of &lt;class 'sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg'&gt;&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22cec510&gt;
parameters = [{'%(138792451941776 param)s': UUID('8a025f56-a06c-4752-bc22-f7804704aabd')}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b20fdc5f0&gt;), '_result_disable_adapt_to_context': True})
args = (&lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22cec510&gt;, [{'%(138792451941776 param)s': ...selectable.Select object at 0x7e3b21f9e550&gt;, [AnnotatedBindParameter('%(138792451941776 param)s', None, type_=UUID())])
kw = {'cache_hit': &lt;CacheStats.CACHE_HIT: 0&gt;}, yp = None, conn = &lt;sqlalchemy.pool.base._ConnectionFairy object at 0x7e3b20fdf470&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21ce3dd0&gt;

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -&gt; CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
&gt;           return self._exec_single_context(
                dialect, context, statement, parameters
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1842: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21ce3dd0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22cec510&gt;, parameters = [(UUID('8a025f56-a06c-4752-bc22-f7804704aabd'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
&gt;           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1982: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;
e = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
statement = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...lient_scopes \nWHERE $1::UUID = service_client_scopes.service_client_id AND scopes.id = service_client_scopes.scope_id'
parameters = (UUID('8a025f56-a06c-4752-bc22-f7804704aabd'),), cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fdfa60&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21ce3dd0&gt;, is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -&gt; NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-&gt; test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
                raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
            else:
                assert exc_info[1] is not None
&gt;               raise exc_info[1].with_traceback(exc_info[2])

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2354: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b21ce3a10&gt;, dialect = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21ce3dd0&gt;
statement = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGCompiler_asyncpg object at 0x7e3b22cec510&gt;, parameters = [(UUID('8a025f56-a06c-4752-bc22-f7804704aabd'),)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -&gt; CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
&gt;                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1963: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
cursor = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fdfa60&gt;
statement = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...lient_scopes \nWHERE $1::UUID = service_client_scopes.service_client_id AND scopes.id = service_client_scopes.scope_id'
parameters = (UUID('8a025f56-a06c-4752-bc22-f7804704aabd'),), context = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGExecutionContext_asyncpg object at 0x7e3b21ce3dd0&gt;

    def do_execute(self, cursor, statement, parameters, context=None):
&gt;       cursor.execute(statement, parameters)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:943: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_cursor object at 0x7e3b20fdfa60&gt;
operation = 'SELECT scopes.name AS scopes_name, scopes.description AS scopes_description, scopes.resource AS scopes_resource, scop...lient_scopes \nWHERE $1::UUID = service_client_scopes.service_client_id AND scopes.id = service_client_scopes.scope_id'
parameters = (UUID('8a025f56-a06c-4752-bc22-f7804704aabd'),)

    def execute(self, operation, parameters=None):
&gt;       self._adapt_connection.await_(
            self._prepare_and_execute(operation, parameters)
        )

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:580: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_cursor._prepare_and_execute at 0x7e3b21da8b80&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_cascade_behavior" time="0.153"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b228f0650&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1b505450&gt;

    @pytest.mark.unit
    async def test_scope_cascade_behavior(self, db_session: AsyncSession):
        """Test scope cascade behavior with relationships."""
        # Create scope with roles and service clients
        scope = Scope(
            name="temp:scope",
            description="Temporary scope",
            resource="temp"
        )
        role = Role(name="temp_role", description="Temporary role")
        client = ServiceClient(
            client_id="temp-client",
            client_secret_hash=hash_password("temp-secret"),
            name="Temporary Client"
        )
    
        db_session.add_all([scope, role, client])
        await db_session.commit()
    
        # Create relationships
&gt;       role.scopes.append(scope)

tests/test_app/test_models/test_scope.py:176: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='temp_role', description='Temporary role')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;, 'created_at': datetime.datetime(...zinfo=datetime.timezone.utc), 'description': 'Temporary role', 'id': UUID('a26d4a8f-80c3-47b5-acd0-5ce8306a6592'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b505310&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210bd430&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b505310&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1b505d90&gt;
params = {'%(138792450297040 param)s': UUID('a26d4a8f-80c3-47b5-acd0-5ce8306a6592')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b505310&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1b505d90&gt;
params = {'%(138792450297040 param)s': UUID('a26d4a8f-80c3-47b5-acd0-5ce8306a6592')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b1b505310&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b2107b2f0&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b2107b2f0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b2107b2f0&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b2107b2f0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1b505b50&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b1bfef280&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b22f225c0&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b21ebfbc0&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_to_dict" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_parse_name" time="0.012"><failure message="AssertionError: assert 'action' == 'read'&#10;  - read&#10;  + action">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b228f16d0&gt;

    @pytest.mark.unit
    def test_scope_parse_name(self):
        """Test parsing scope name into action and resource."""
        # Test standard format
        scope = Scope(name="read:users")
        action, resource = scope.parse_name()
&gt;       assert action == "read"
E       AssertionError: assert 'action' == 'read'
E         - read
E         + action

tests/test_app/test_models/test_scope.py:219: AssertionError</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_get_action" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_get_resource" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_matches_pattern" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_implies" time="0.006"><failure message="AssertionError: assert False is True&#10; +  where False = &lt;bound method Scope.implies of &lt;Scope(name='write:users', resource='users')&gt;&gt;(&lt;Scope(name='read:users', resource='users')&gt;)&#10; +    where &lt;bound method Scope.implies of &lt;Scope(name='write:users', resource='users')&gt;&gt; = &lt;Scope(name='write:users', resource='users')&gt;.implies">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b228f3690&gt;

    @pytest.mark.unit
    def test_scope_implies(self):
        """Test scope implication logic."""
        # Admin scope should imply read/write scopes
        admin_scope = Scope(name="admin:users", resource="users")
        read_scope = Scope(name="read:users", resource="users")
        write_scope = Scope(name="write:users", resource="users")
        delete_scope = Scope(name="delete:users", resource="users")
    
        assert admin_scope.implies(read_scope) is True
        assert admin_scope.implies(write_scope) is True
        assert admin_scope.implies(delete_scope) is True
    
        # Write scope should imply read scope
&gt;       assert write_scope.implies(read_scope) is True
E       AssertionError: assert False is True
E        +  where False = &lt;bound method Scope.implies of &lt;Scope(name='write:users', resource='users')&gt;&gt;(&lt;Scope(name='read:users', resource='users')&gt;)
E        +    where &lt;bound method Scope.implies of &lt;Scope(name='write:users', resource='users')&gt;&gt; = &lt;Scope(name='write:users', resource='users')&gt;.implies

tests/test_app/test_models/test_scope.py:302: AssertionError</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_query_methods" time="0.032" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_validation" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_equality" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_hash" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_ordering" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_audit_fields" time="0.034" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_permission_levels" time="0.006"><failure message="TypeError: '&gt;=' not supported between instances of 'int' and 'Scope'">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b22ac4bd0&gt;

    @pytest.mark.unit
    def test_scope_permission_levels(self):
        """Test scope permission level hierarchy."""
        # Define permission levels
        read_scope = Scope(name="read:data", resource="data")
        write_scope = Scope(name="write:data", resource="data")
        admin_scope = Scope(name="admin:data", resource="data")
    
        # Test permission level comparison
        assert read_scope.get_permission_level() == 1
        assert write_scope.get_permission_level() == 2
        assert admin_scope.get_permission_level() == 3
    
        # Test permission hierarchy
&gt;       assert admin_scope.has_permission_level_of(write_scope) is True

tests/test_app/test_models/test_scope.py:462: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;Scope(name='admin:data', resource='data')&gt;, level = &lt;Scope(name='write:data', resource='data')&gt;

    def has_permission_level_of(self, level: int) -&gt; bool:
        """
        Check if scope has at least the specified permission level.
    
        Args:
            level: Minimum permission level required
    
        Returns:
            True if scope has at least the specified permission level
        """
&gt;       return self.get_permission_level() &gt;= level
E       TypeError: '&gt;=' not supported between instances of 'int' and 'Scope'

app/models/scope.py:437: TypeError</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_usage_tracking" time="0.142"><failure message="sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b22ac4e50&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b20711910&gt;

    @pytest.mark.unit
    async def test_scope_usage_tracking(self, db_session: AsyncSession):
        """Test scope usage tracking."""
        scope = Scope(name="tracked:scope", resource="tracked")
        role = Role(name="tracking_role", description="Role for tracking")
        client = ServiceClient(
            client_id="tracking-client",
            client_secret_hash=hash_password("tracking-secret"),
            name="Tracking Client"
        )
    
        db_session.add_all([scope, role, client])
        await db_session.commit()
    
        # Assign scope to role and client
&gt;       role.scopes.append(scope)

tests/test_app/test_models/test_scope.py:482: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x7e3b234c40e0&gt;, instance = &lt;Role(name='tracking_role', description='Role for tracking')&gt;
owner = &lt;class 'app.models.role.Role'&gt;

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -&gt; Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
&gt;           return self.impl.get(state, dict_)  # type: ignore[no-any-return]

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:566: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;
dict_ = {'_sa_instance_state': &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;, 'created_at': datetime.datetime(...fo=datetime.timezone.utc), 'description': 'Role for tracking', 'id': UUID('e1d32587-b253-4bcc-a001-4b53e7abae32'), ...}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -&gt; Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive &amp; CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
&gt;               value = self._fire_loader_callables(state, key, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1086: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x7e3b22e4e350&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;, key = 'scopes'
passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -&gt; Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
&gt;           return self.callable_(state, passive)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/attributes.py:1121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;, passive = symbol('PASSIVE_OFF')
loadopt = None, extra_criteria = (), extra_options = (), alternate_effective_path = None, execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive &amp; PassiveFlag.SQL_OK and not use_get) or (
            not passive &amp; attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive &amp; PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive &amp; PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive &amp; PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive &amp; PassiveFlag.SQL_OK
                or not passive &amp; PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
&gt;       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.strategies.LazyLoader object at 0x7e3b22a50660&gt;, session = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20712c10&gt;
state = &lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;, primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=&lt;sqlalchemy.orm.state.InstanceState object at 0x7e3b210ec3b0&gt;)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive &amp; attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive &amp; PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive &amp; PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
&gt;       result = session.execute(
            stmt, params, execution_options=execution_options
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20712c10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1baee410&gt;
params = {'%(138792450297040 param)s': UUID('e1d32587-b253-4bcc-a001-4b53e7abae32')}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -&gt; Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
&gt;       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20712c10&gt;, statement = &lt;sqlalchemy.sql.selectable.Select object at 0x7e3b1baee410&gt;
params = {'%(138792450297040 param)s': UUID('e1d32587-b253-4bcc-a001-4b53e7abae32')}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -&gt; Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
&gt;       conn = self._connection_for_bind(bind)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.Session object at 0x7e3b20712c10&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None, kw = {}, trans = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b8bdea0&gt;

    def _connection_for_bind(
        self,
        engine: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
        **kw: Any,
    ) -&gt; Connection:
        TransactionalContext._trans_ctx_check(self)
    
        trans = self._transaction
        if trans is None:
            trans = self._autobegin_t()
&gt;       return trans._connection_for_bind(engine, execution_options)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b8bdea0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

&gt;   ???

&lt;string&gt;:2: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

fn = &lt;function SessionTransaction._connection_for_bind at 0x7e3b254d3880&gt;, self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b8bdea0&gt;
arg = (Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), None), kw = {}, current_state = &lt;SessionTransactionState.ACTIVE: 1&gt;
next_state = &lt;_StateChangeStates.ANY: 1&gt;, existing_fn = None, expect_state = &lt;SessionTransactionState.ACTIVE: 1&gt;

    @util.decorator
    def _go(fn: _F, self: Any, *arg: Any, **kw: Any) -&gt; Any:
        current_state = self._state
    
        if (
            has_prerequisite_states
            and current_state not in prerequisite_state_collection
        ):
            self._raise_for_prerequisite_state(fn.__name__, current_state)
    
        next_state = self._next_state
        existing_fn = self._current_fn
        expect_state = moves_to if expect_state_change else current_state
    
        if (
            # destination states are restricted
            next_state is not _StateChangeStates.ANY
            # method seeks to change state
            and expect_state_change
            # destination state incorrect
            and next_state is not expect_state
        ):
            if existing_fn and next_state in (
                _StateChangeStates.NO_CHANGE,
                _StateChangeStates.CHANGE_IN_PROGRESS,
            ):
                raise sa_exc.IllegalStateChangeError(
                    f"Method '{fn.__name__}()' can't be called here; "
                    f"method '{existing_fn.__name__}()' is already "
                    f"in progress and this would cause an unexpected "
                    f"state change to {moves_to!r}",
                    code="isce",
                )
            else:
                raise sa_exc.IllegalStateChangeError(
                    f"Cant run operation '{fn.__name__}()' here; "
                    f"will move to state {moves_to!r} where we are "
                    f"expecting {next_state!r}",
                    code="isce",
                )
    
        self._current_fn = fn
        self._next_state = _StateChangeStates.CHANGE_IN_PROGRESS
        try:
&gt;           ret_value = fn(self, *arg, **kw)

.venv/lib/python3.11/site-packages/sqlalchemy/orm/state_changes.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.orm.session.SessionTransaction object at 0x7e3b1b8bdea0&gt;, bind = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)
execution_options = None

    @_StateChange.declare_states(
        (SessionTransactionState.ACTIVE,), _StateChangeStates.NO_CHANGE
    )
    def _connection_for_bind(
        self,
        bind: _SessionBind,
        execution_options: Optional[CoreExecuteOptionsParameter],
    ) -&gt; Connection:
        if bind in self._connections:
            if execution_options:
                util.warn(
                    "Connection is already established for the "
                    "given bind; execution_options ignored"
                )
            return self._connections[bind][0]
    
        self._state = SessionTransactionState.PROVISIONING_CONNECTION
    
        local_connect = False
        should_commit = True
    
        try:
            if self._parent:
                conn = self._parent._connection_for_bind(
                    bind, execution_options
                )
                if not self.nested:
                    return conn
            else:
                if isinstance(bind, engine.Connection):
                    conn = bind
                    if conn.engine in self._connections:
                        raise sa_exc.InvalidRequestError(
                            "Session already has a Connection associated "
                            "for the given Connection's Engine"
                        )
                else:
&gt;                   conn = bind.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def connect(self) -&gt; Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
&gt;       return self._connection_cls(self)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.engine.base.Connection object at 0x7e3b1baec690&gt;, engine = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test), connection = None
_has_events = None, _allow_revalidate = True, _allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
&gt;               self._dbapi_connection = engine.raw_connection()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = Engine(postgresql+asyncpg://keystone_test:***@postgres-test:5432/keystone_test)

    def raw_connection(self) -&gt; PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
&gt;       return self.pool.connect()

.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:3297: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;

    def connect(self) -&gt; PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
&gt;       return _ConnectionFairy._checkout(self)

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:449: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
                        result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )
                        if not result:
                            if fairy._echo:
                                pool.logger.debug(
                                    "Pool pre-ping on connection %s failed, "
                                    "will invalidate pool",
                                    fairy.dbapi_connection,
                                )
                            raise exc.InvalidatePoolError()
                    elif fairy._echo:
                        pool.logger.debug(
                            "Connection %s is fresh, skipping pre-ping",
                            fairy.dbapi_connection,
                        )
    
                pool.dispatch.checkout(
                    fairy.dbapi_connection, fairy._connection_record, fairy
                )
                return fairy
            except exc.DisconnectionError as e:
                if e.invalidate_pool:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating all pooled connections prior to "
                        "current timestamp (reason: %r)",
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                    pool._invalidate(fairy, e, _checkin=False)
                else:
                    pool.logger.info(
                        "Disconnection detected on checkout, "
                        "invalidating individual connection %s (reason: %r)",
                        fairy.dbapi_connection,
                        e,
                    )
                    fairy._connection_record.invalidate(e)
                try:
                    fairy.dbapi_connection = (
                        fairy._connection_record.get_connection()
                    )
                except BaseException as err:
                    with util.safe_reraise():
                        fairy._connection_record._checkin_failed(
                            err,
                            _fairy_was_created=True,
                        )
    
                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
                        del fairy
    
                    # never called, this is for code linters
                    raise
    
                attempts -= 1
            except BaseException as be_outer:
&gt;               with util.safe_reraise():

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1363: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.util.langhelpers.safe_reraise object at 0x7e3b20ea6b90&gt;, type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -&gt; NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
&gt;           raise exc_value.with_traceback(exc_tb)

.venv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'sqlalchemy.pool.base._ConnectionFairy'&gt;, pool = &lt;sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7e3b22b80e90&gt;, threadconns = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -&gt; _ConnectionFairy:
        if not fairy:
            fairy = _ConnectionRecord.checkout(pool)
    
            if threadconns is not None:
                threadconns.current = weakref.ref(fairy)
    
        assert (
            fairy._connection_record is not None
        ), "can't 'checkout' a detached connection fairy"
        assert (
            fairy.dbapi_connection is not None
        ), "can't 'checkout' an invalidated connection fairy"
    
        fairy._counter += 1
        if (
            not pool.dispatch.checkout and not pool._pre_ping
        ) or fairy._counter != 1:
            return fairy
    
        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
    
        attempts = 2
    
        while attempts &gt; 0:
            connection_is_fresh = fairy._connection_record.fresh
            fairy._connection_record.fresh = False
            try:
                if pool._pre_ping:
                    if not connection_is_fresh:
                        if fairy._echo:
                            pool.logger.debug(
                                "Pool pre-ping on connection %s",
                                fairy.dbapi_connection,
                            )
&gt;                       result = pool._dialect._do_ping_w_event(
                            fairy.dbapi_connection
                        )

.venv/lib/python3.11/site-packages/sqlalchemy/pool/base.py:1301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1b4c0&gt;&gt;

    def _do_ping_w_event(self, dbapi_connection: DBAPIConnection) -&gt; bool:
        try:
&gt;           return self.do_ping(dbapi_connection)

.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:720: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7e3b22b83410&gt;
dbapi_connection = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1b4c0&gt;&gt;

    def do_ping(self, dbapi_connection):
&gt;       dbapi_connection.ping()

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:1163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1b4c0&gt;&gt;

    def ping(self):
        try:
            _ = self.await_(self._async_ping())
        except Exception as error:
&gt;           self._handle_exception(error)

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1b4c0&gt;&gt;
error = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")

    def _handle_exception(self, error):
        if self._connection.is_closed():
            self._transaction = None
            self._started = False
    
        if not isinstance(error, AsyncAdapt_asyncpg_dbapi.Error):
            exception_mapping = self.dbapi._asyncpg_error_translate
    
            for super_ in type(error).__mro__:
                if super_ in exception_mapping:
                    translated_error = exception_mapping[super_](
                        "%s: %s" % (type(error), error)
                    )
                    translated_error.pgcode = translated_error.sqlstate = (
                        getattr(error, "sqlstate", None)
                    )
                    raise translated_error from error
            else:
&gt;               raise error

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:794: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;AdaptedConnection &lt;asyncpg.connection.Connection object at 0x7e3b21f1b4c0&gt;&gt;

    def ping(self):
        try:
&gt;           _ = self.await_(self._async_ping())

.venv/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:811: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

awaitable = &lt;coroutine object AsyncAdapt_asyncpg_connection._async_ping at 0x7e3b211c42e0&gt;

    def await_only(awaitable: Awaitable[_T]) -&gt; _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
&gt;           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

.venv/lib/python3.11/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_complex_queries" time="0.021"><failure message="AssertionError: assert 'read:user_profiles' in []">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b22ac6290&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b227f3750&gt;

    @pytest.mark.unit
    async def test_scope_complex_queries(self, db_session: AsyncSession):
        """Test complex scope queries."""
        # Create scopes with different patterns
        scopes = [
            Scope(name="read:user_profiles", resource="user_profiles"),
            Scope(name="write:user_profiles", resource="user_profiles"),
            Scope(name="admin:user_profiles", resource="user_profiles"),
            Scope(name="read:system_logs", resource="system_logs"),
            Scope(name="admin:system_logs", resource="system_logs"),
            Scope(name="system:maintenance", resource="system")
        ]
    
        db_session.add_all(scopes)
        await db_session.commit()
    
        # Query scopes with admin action
        admin_scopes = await Scope.get_admin_scopes(db_session)
        admin_names = [scope.name for scope in admin_scopes]
        assert "admin:user_profiles" in admin_names
        assert "admin:system_logs" in admin_names
        assert "read:user_profiles" not in admin_names
    
        # Query scopes for specific resource pattern
        user_scopes = await Scope.get_scopes_for_resource_pattern(db_session, "user_*")
        user_scope_names = [scope.name for scope in user_scopes]
&gt;       assert "read:user_profiles" in user_scope_names
E       AssertionError: assert 'read:user_profiles' in []

tests/test_app/test_models/test_scope.py:525: AssertionError</failure></testcase><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_serialization" time="0.006" /><testcase classname="tests.test_app.test_models.test_scope.TestScopeModel" name="test_scope_security_classification" time="0.006"><failure message="AssertionError: assert 'public' == 'user'&#10;  - user&#10;  + public">self = &lt;tests.test_app.test_models.test_scope.TestScopeModel object at 0x7e3b22ac6490&gt;

    @pytest.mark.unit
    def test_scope_security_classification(self):
        """Test scope security classification."""
        # Test different security levels
        public_scope = Scope(name="read:public_info", resource="public_info")
        assert public_scope.get_security_level() == "public"
    
        user_scope = Scope(name="read:user_profile", resource="user_profile")
&gt;       assert user_scope.get_security_level() == "user"
E       AssertionError: assert 'public' == 'user'
E         - user
E         + public

tests/test_app/test_models/test_scope.py:575: AssertionError</failure></testcase><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_creation" time="0.129" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_full_name_property" time="0.007" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_can_login_property" time="0.007" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_is_locked_property" time="0.006" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_scope_methods" time="0.018" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_role_methods" time="0.020" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_admin_methods" time="0.006" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_resource_access" time="0.007" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_failed_login_methods" time="0.007" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_update_last_login" time="0.005" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_to_dict" time="0.007" /><testcase classname="tests.test_app.test_models.test_user.TestUserModel" name="test_user_class_methods" time="0.022" /><testcase classname="tests.unit.test_exceptions.TestAuthenticationExceptions" name="test_authentication_error_creation" time="0.015" /><testcase classname="tests.unit.test_exceptions.TestAuthenticationExceptions" name="test_authentication_error_with_details" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestAuthenticationExceptions" name="test_authentication_error_http_exception" time="0.005" /><testcase classname="tests.unit.test_exceptions.TestAuthorizationExceptions" name="test_authorization_error_creation" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestAuthorizationExceptions" name="test_insufficient_scope_error" time="0.005" /><testcase classname="tests.unit.test_exceptions.TestUserExceptions" name="test_user_not_found_error" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestUserExceptions" name="test_user_disabled_error" time="0.005" /><testcase classname="tests.unit.test_exceptions.TestUserExceptions" name="test_user_locked_error" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestServiceClientExceptions" name="test_service_client_not_found_error" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestServiceClientExceptions" name="test_service_client_disabled_error" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestTokenExceptions" name="test_invalid_token_error" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestTokenExceptions" name="test_expired_token_error" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestTokenExceptions" name="test_revoked_token_error" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestValidationExceptions" name="test_password_policy_error" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestValidationExceptions" name="test_validation_error" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestRateLimitExceptions" name="test_rate_limit_exceeded_error" time="0.005" /><testcase classname="tests.unit.test_exceptions.TestExceptionChaining" name="test_exception_chaining" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionChaining" name="test_exception_context_preservation" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionSerialization" name="test_exception_to_dict" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionSerialization" name="test_exception_json_serialization" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionLogging" name="test_exception_logging_data" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionLogging" name="test_exception_security_logging" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionHandlerIntegration" name="test_exception_handler_response_format" time="0.007" /><testcase classname="tests.unit.test_exceptions.TestExceptionHandlerIntegration" name="test_exception_handler_headers" time="0.006" /><testcase classname="tests.unit.test_exceptions.TestExceptionHandlerIntegration" name="test_rate_limit_exception_headers" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_access_token" time="0.005" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_access_token_with_optional_claims" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_refresh_token" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_service_token" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_decode_token_valid" time="0.005" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_decode_token_invalid" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_decode_token_expired" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_validate_token_valid" time="0.008" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_validate_token_wrong_type" time="0.005" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_validate_token_wrong_audience" time="0.007" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_validate_token_insufficient_scopes" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_extract_token_info" time="0.008" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_is_token_expired" time="0.005" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_get_token_remaining_time" time="0.008" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_refresh_access_token" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_refresh_access_token_invalid_refresh" time="0.007" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_token_response" time="0.005" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_create_token_response_minimal" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_custom_expiration_times" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTService" name="test_additional_claims" time="0.006" /><testcase classname="tests.unit.test_jwt.TestJWTClaims" name="test_jwt_claims_constants" time="0.005" /><testcase classname="tests.unit.test_jwt.TestTokenType" name="test_token_type_constants" time="0.006" /><testcase classname="tests.unit.test_jwt.TestGlobalJWTService" name="test_global_jwt_service_exists" time="0.005" /><testcase classname="tests.unit.test_jwt.TestGlobalJWTService" name="test_global_jwt_service_methods" time="0.008" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_creation" time="0.130" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_full_name_property" time="0.008" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_can_login_property" time="0.008" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_is_locked_property" time="0.008" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_scope_methods" time="0.020" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_role_methods" time="0.021" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_admin_methods" time="0.007" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_resource_access" time="0.008" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_failed_login_methods" time="0.005" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_update_last_login" time="0.007" /><testcase classname="tests.unit.test_models.TestUserModel" name="test_user_to_dict" time="0.008" /><testcase classname="tests.unit.test_models.TestRoleModel" name="test_role_creation" time="0.021" /><testcase classname="tests.unit.test_models.TestRoleModel" name="test_role_scope_methods" time="0.022"><failure message="TypeError: object bool can't be used in 'await' expression">self = &lt;tests.unit.test_models.TestRoleModel object at 0x7e3b2281a590&gt;, db_session = &lt;sqlalchemy.orm.session.AsyncSession object at 0x7e3b1b5077d0&gt;

    @pytest.mark.unit
    async def test_role_scope_methods(self, db_session: AsyncSession):
        """Test role scope management methods."""
        role = Role(name="test_role", description="Test role")
        scope1 = Scope(name="read:test", description="Read test")
        scope2 = Scope(name="write:test", description="Write test")
    
        db_session.add_all([role, scope1, scope2])
        await db_session.commit()
    
        # Test has_scope
        await db_session.refresh(role)
&gt;       assert await role.has_scope("read:test") is False
E       TypeError: object bool can't be used in 'await' expression

tests/unit/test_models.py:305: TypeError</failure></testcase><testcase classname="tests.unit.test_models.TestRoleModel" name="test_role_default_roles" time="0.007"><failure message="AssertionError: assert False&#10; +  where False = isinstance({'description': 'Standard user role', 'name': 'user'}, str)">self = &lt;tests.unit.test_models.TestRoleModel object at 0x7e3b2280fc10&gt;

    @pytest.mark.unit
    def test_role_default_roles(self):
        """Test default roles list."""
        default_roles = Role.get_default_roles()
    
        assert isinstance(default_roles, list)
        assert len(default_roles) &gt; 0
    
        # Check structure of default roles - they are just strings
        for role_name in default_roles:
&gt;           assert isinstance(role_name, str)
E           AssertionError: assert False
E            +  where False = isinstance({'description': 'Standard user role', 'name': 'user'}, str)

tests/unit/test_models.py:330: AssertionError</failure></testcase><testcase classname="tests.unit.test_models.TestRoleModel" name="test_role_to_dict" time="0.006" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_creation" time="0.016" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_properties" time="0.006" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_type_checks" time="0.006" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_default_scopes" time="0.005" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_parse_scope_string" time="0.006" /><testcase classname="tests.unit.test_models.TestScopeModel" name="test_scope_validate_format" time="0.005" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_creation" time="0.125" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_properties" time="0.006" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_scope_methods" time="0.006" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_resource_access" time="0.007" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_ip_validation" time="0.006" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_usage_tracking" time="0.008" /><testcase classname="tests.unit.test_models.TestServiceClientModel" name="test_service_client_default_clients" time="0.005" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_creation" time="0.020" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_properties" time="0.006" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_revocation" time="0.007" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_usage" time="0.008" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_expiry_extension" time="0.010" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_remaining_lifetime" time="0.014" /><testcase classname="tests.unit.test_models.TestRefreshTokenModel" name="test_refresh_token_near_expiry" time="0.014" /><testcase classname="tests.unit.test_password.TestPasswordHashing" name="test_hash_password" time="0.124" /><testcase classname="tests.unit.test_password.TestPasswordHashing" name="test_verify_password_correct" time="0.236" /><testcase classname="tests.unit.test_password.TestPasswordHashing" name="test_verify_password_incorrect" time="0.226" /><testcase classname="tests.unit.test_password.TestPasswordHashing" name="test_verify_password_invalid_hash" time="0.008" /><testcase classname="tests.unit.test_password.TestPasswordHashing" name="test_needs_rehash" time="0.117" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_valid_password" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_too_short" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_too_long" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_no_uppercase" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_no_lowercase" time="0.008" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_no_digits" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_no_special_chars" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_password_contains_username" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_common_password_patterns" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_empty_password" time="0.008" /><testcase classname="tests.unit.test_password.TestPasswordPolicy" name="test_none_password" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordStrength" name="test_strong_password_score" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordStrength" name="test_weak_password_score" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordStrength" name="test_medium_password_score" time="0.008" /><testcase classname="tests.unit.test_password.TestPasswordStrength" name="test_empty_password_score" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordGeneration" name="test_generate_secure_password_default_length" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordGeneration" name="test_generate_secure_password_custom_length" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordGeneration" name="test_generate_secure_password_contains_all_types" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordGeneration" name="test_generate_secure_password_uniqueness" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicyClass" name="test_password_policy_initialization" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordPolicyClass" name="test_calculate_strength_score_edge_cases" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordPolicyClass" name="test_repetitive_characters_detection" time="0.006" /><testcase classname="tests.unit.test_password.TestPasswordPolicyClass" name="test_common_pattern_detection" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicyClass" name="test_strength_labels" time="0.005" /><testcase classname="tests.unit.test_password.TestPasswordPolicyGlobal" name="test_global_password_policy_exists" time="0.007" /><testcase classname="tests.unit.test_password.TestPasswordPolicyGlobal" name="test_global_password_policy_methods" time="0.006" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_extract_bearer_token_valid" time="0.006" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_extract_bearer_token_none_credentials" time="0.006" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_extract_bearer_token_empty_credentials" time="0.006" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_is_token_revoked_true" time="0.009" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_is_token_revoked_false" time="0.007" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_is_token_revoked_redis_error" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_revoke_token_success" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_revoke_token_redis_error" time="0.007" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_user_by_id_success" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_user_by_id_not_found" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_user_by_id_disabled" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_user_by_id_locked" time="0.009" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_service_client_by_id_success" time="0.008" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_service_client_by_id_not_found" time="0.009" /><testcase classname="tests.unit.test_security.TestSecurityUtils" name="test_get_service_client_by_id_disabled" time="0.011" /><testcase classname="tests.unit.test_security.TestTokenPayloadDependency" name="test_get_current_token_payload_valid" time="0.012" /><testcase classname="tests.unit.test_security.TestTokenPayloadDependency" name="test_get_current_token_payload_revoked" time="0.012" /><testcase classname="tests.unit.test_security.TestTokenPayloadDependency" name="test_get_current_token_payload_no_credentials" time="0.010" /><testcase classname="tests.unit.test_security.TestCurrentUserDependency" name="test_get_current_user_success" time="0.011" /><testcase classname="tests.unit.test_security.TestCurrentUserDependency" name="test_get_current_user_service_token" time="0.011" /><testcase classname="tests.unit.test_security.TestCurrentUserDependency" name="test_get_current_user_missing_subject" time="0.011" /><testcase classname="tests.unit.test_security.TestCurrentServiceClientDependency" name="test_get_current_service_client_success" time="0.010" /><testcase classname="tests.unit.test_security.TestCurrentServiceClientDependency" name="test_get_current_service_client_user_token" time="0.009" /><testcase classname="tests.unit.test_security.TestScopeRequirements" name="test_require_scopes_success" time="0.008" /><testcase classname="tests.unit.test_security.TestScopeRequirements" name="test_require_scopes_insufficient" time="0.007" /><testcase classname="tests.unit.test_security.TestScopeRequirements" name="test_require_any_scope_success" time="0.009" /><testcase classname="tests.unit.test_security.TestScopeRequirements" name="test_require_any_scope_insufficient" time="0.009" /><testcase classname="tests.unit.test_security.TestRoleRequirements" name="test_require_roles_success" time="0.008" /><testcase classname="tests.unit.test_security.TestRoleRequirements" name="test_require_roles_insufficient" time="0.008" /><testcase classname="tests.unit.test_security.TestRoleRequirements" name="test_require_admin" time="0.009"><failure message="AssertionError: assert &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b2e0&gt; == &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b420&gt;&#10; +  where &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b420&gt; = require_roles(['admin'])">self = &lt;tests.unit.test_security.TestRoleRequirements object at 0x7e3b2290f210&gt;

    @pytest.mark.unit
    def test_require_admin(self):
        """Test admin requirement dependency."""
        admin_check = require_admin()
    
        # Should be equivalent to require_roles(["admin"])
&gt;       assert admin_check == require_roles(["admin"])
E       AssertionError: assert &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b2e0&gt; == &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b420&gt;
E        +  where &lt;function require_roles.&lt;locals&gt;.check_roles at 0x7e3b1b85b420&gt; = require_roles(['admin'])

tests/unit/test_security.py:539: AssertionError</failure></testcase><testcase classname="tests.unit.test_security.TestOptionalAuthentication" name="test_get_optional_current_user_with_token" time="0.013" /><testcase classname="tests.unit.test_security.TestOptionalAuthentication" name="test_get_optional_current_user_no_token" time="0.010" /><testcase classname="tests.unit.test_security.TestOptionalAuthentication" name="test_get_optional_current_user_invalid_token" time="0.009" /><testcase classname="tests.unit.test_security.TestOptionalAuthentication" name="test_get_optional_current_user_service_token" time="0.010" /><testcase classname="tests.unit.test_security.TestSecurityIntegration" name="test_convenience_dependencies_exist" time="0.012" /><testcase classname="tests.unit.test_security.TestSecurityIntegration" name="test_security_scheme_configuration" time="0.062" /></testsuite></testsuites>